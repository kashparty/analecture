ID: 8f2eda63-13b0-4ed8-9f2a-adbe010bc5c8
Title: Recursion
Category: Haskell
Lecturer: Anthony Field
Date: 11/10/2021
Hamza, you've got a hand up already and I haven't started. I raise it because I could hear you and I'm like, Oh, that's great.
0:11
Thank you very much. That's great. So welcome back, everybody.
0:18
And I'm not going to do an awful lot today. I'm going to go a little bit slow today because this is when it starts getting a bit.
0:23
Why do you have is it an old hand or do you want to ask me a question? So that's yeah, that's good.
0:29
All right. Yeah, so I'm not going to cover an enormous amount today because it's it's this is the
0:37
first ad where it gets a bit tricky where you have to do a little bit of thinking.
0:42
So what I'd encourage you to do, having watched the lecture, if you if you haven't really done so,
0:46
is to start looking at the second part of the functions, exercises, the unassessed sheet.
0:51
There's plenty of little toy examples there to get you used to this idea of recursion which are going to be covering today.
0:58
So that's what we're going to do. Before I do that, I just want to go back and finish off where I got to.
1:04
Last time I realised that I didn't have in my exercise script this function f here,
1:09
I thought it might just be worth finishing this up and doing this before we run.
1:15
So what was the idea? Remember we were talking about evaluation orders and evaluation strategies and I told you that Haskell was lazy.
1:21
So Haskell will not compute anything unless it has to.
1:28
And here is an example of a function F if you look at the definition, if X is less than zero, we can return and zero without ever evaluating Y.
1:32
So if it is the case that X is zero less than zero, it matters not what I give.
1:41
What I get for y y will never be computed. It'll just terminate immediately and give me the answer.
1:49
Zero. It's only if X is positive or equal to zero that we actually require the value of Y, so you can contrive other examples to to show this.
1:53
So if I go to the script, I put this in the script. Now I've by the way, I've named it F probably.
2:02
Because we already have. Oh, no, hang on a minute.
2:09
What's gone wrong here? Oh, hang on a second.
2:14
It looks like my party crushed. The party says someone's someone's rebooted the machine just by winning a second.
2:25
We'll just turn the microphone momentarily. Can you still hear me on this other laptop because I'm having problems on my mind machine?
2:40
Yeah, yes. OK, here, thank you very much. Delightfully teams was also just crushed on the other laptops.
3:56
You are going to have to bear with me for a few minutes while I restarted all my devices. OK, I think we're back to where we were on.
4:02
I think I sorry, the. But we are now back to where we were, I think so you can still hear me, I guess nothing's gone.
6:08
I've got two devices here. That's great. Thank you, Daniel.
6:21
Well, I say let me let me start again.
6:25
So I've got the I've got the script here that I was showing you last time, which is go to the examples from the slides.
6:28
And I've got this function f which came from I think from slide 40 here,
6:34
which is one I've just been talking through, and I've just notes in the script.
6:41
I've renamed it to F Prime because just above it I've got a function which is I've just realised I use F twice in the notes.
6:45
So you should know by now if you have not discovered it, you can.
6:51
The Prime is a is a valid suffix on a function name or a variable identifier name in Haskell.
6:55
And this is really handy because quite often you've got you may have you may be using a variable like X and you've got three X's and you think,
7:01
why should I call them? Because they've got slightly different meanings than a local next 1x 2x three,
7:08
which is what you would do in, say, a Fortran programme or something in Haskell.
7:12
You have the option to call them X X by next double problem and so on. So problem is just considered.
7:15
Don't think this is the differential of F. That's something quite different.
7:20
This is just an just a just an alternative name for a function at Prime. OK, so here's the function from the notes.
7:26
What I was I started showing you last time. Hang on a second, something's just come up on my things, which is concerning me.
7:32
I think we're still OK yet if you, you know, OK,
7:44
so I've got a strange message just came up on my second laptop that I should just ignore, pretend it didn't happen.
7:48
Right. So if I go to jail. If I go to.
7:55
If I go to JHC now, what happens if I give this these are the examples I showed you last time,
8:02
so if X is less than zero, so on minus three and I give it, what does it matter?
8:11
I just get zero straight away if it's positive, like five, for example, I get the one hundred and ninety eight.
8:15
And it is interesting questions.
8:22
If I go back to the example with a negative first argument, I can put absolutely anything in this second argument position and I'm going to get zero.
8:24
So the example in the notes was something of a six divided by zero that would normally give me not a number because six zero is infinity.
8:32
So we would know just to show what I get. If this were positive, they are floating point number format, by the way, in case you're interested,
8:38
actually has a special representation for infinity, so actually knows it's a division by zero sum when it prints infinity for us very conveniently.
8:48
All right. So another way to to the point.
8:56
The point is here, if I got six divided by zero, that makes a negative number, which is the example right here.
8:59
Yeah, I can return zero without ever having to compute that thing that will go to infinity.
9:06
Now, what I showed you last time was this thing called undefined, which is actually really useful for all sorts of different reasons in Haskell.
9:10
So there's a thing called undefined in high school. And I think I lost my eye.
9:15
I asked you to think about what the type of that was and is anything.
9:20
So what this says is that absolutely every type in Haskell has an undefined element.
9:25
So boules have an undefined element. For example, I could say, oh, there's undefined, but what if I get if undefined?
9:30
He says, well, it's just an error.
9:37
But if I say, what's the type of undefined we say tonight and of course, you know that I can force the type of anything by using the double colons.
9:38
And very occasionally you might find this as well as actually,
9:47
I don't think apart from playing with examples on the come on, you won't need this in a programme anyway.
9:50
I can foresee and find to be the undefined bool value, in which case is the type isn't any more.
9:55
The type is bool, because you've told me that this undefined is a ball and define not and in turn define for example, which would be that.
10:00
Yeah. So every data type has an undefined element and that can be very useful in testing and exploring.
10:07
Things generally go back to my prime function so I can put an undefined in here.
10:16
We get zero, and if ever I hit the undefiled, we just see what happens.
10:23
We get an error because if I try to execute the undefined element, it's basically going to abort the programme and give me this this exception.
10:28
So Huskins lazy. So when I do something like this, we know what lazy evaluation means.
10:36
That means don't evaluate the arguments first and then get into the function.
10:42
That's what a C programme would do, or a potential job, a programme called by value in Haskell.
10:46
You invoke the rules for the function first, and that may or may not cause the the the evaluation of the X or the Y in this case to be triggered.
10:51
So the way to think about this undefined thing is it says it's just that poised for the kill.
11:00
Yeah. So don't touch me. Yeah. And so. Well, Ephriam says in this case.
11:04
Okay, I won't touch you. I'll just give you one.
11:08
But if, of course the first argument is non-negative and it has no choice because according to the rules of the function,
11:11
it has to return y which case it then has to poke the undefined and it's I gotcha.
11:18
I told you not to touch me and outcomes this exception.
11:22
Mr. Field, yeah, could you just explain the difference and how Python evaluates a function Haskell evaluates to function again?
11:27
Well, I mean, Haskell is really unusual. Haskell is pretty much the only mainstream language that I know of either.
11:36
I'm sure there must be other examples of something which has got this lazy evaluation concept.
11:41
So all or most of the programming languages evaluate the argument first and then apply the rules for the function.
11:46
Now, if you look at this thing, you can say in front of you that if I did call value, it wouldn't matter about these two guys.
11:53
It wouldn't matter the fact that X is less than zero.
12:00
I do not need the value of what it's too late because all the pre computed X, pre computed Y and then given those to the function.
12:02
And if I pre compute in this case, if I was the example, if I pre compute minus one, I get minus one.
12:08
If I pre undefined, it crushes the programme, the programme with an exception.
12:15
It's too late to say to see the difference. So that's what a Python programme would do.
12:21
That's what a job a programme would do. If I had if I were able to write executives in Java, for example,
12:25
and I we never we never invoked the rules for the function because it would be too late.
12:30
We just we would just have aborted the programme.
12:35
All right, so that's just wrapping it up, so let's now move on to the main topic of the day, which is this.
12:39
Oh, David, you've got a question. It's high school, it's high school, and then see high schools mostly written in high school.
12:45
Oh, OK. Yeah. Why did you ask why?
12:57
Because you were saying that like C would do something differently. It wouldn't evaluate the function.
13:02
First parameters from that with my application developing, my programme is thought if I were to see function and invoke it,
13:08
the compiled code will evaluate the arguments first and then invoke the function, right?
13:16
Yeah, Ben. Is undefined, as there now know what's what?
13:21
No, I don't know what the second is that no knowledge? Well, no, I know what knowledge in Haskell there is knowledge in high school is to remember,
13:28
we looked as though maybe we haven't looked at this yet this next week, actually.
13:39
In fact, we're doing this on Woodenness tomorrow. So no is actually a function on lists.
13:43
It's not and it's not it doesn't mean the null element in the same so undefined,
13:50
if you like, is going to the another element in some of the languages. Hashem.
13:54
Is there I can use was calling a function to. I'm very sorry I missed what you said.
14:02
Is there a flag you can use that can bypass the lazy evaluation of arguments?
14:08
No, there is no well, so there's no flag you can use to bypass the evaluation if you if you know your functions can safely.
14:12
If you know your function can be safely computed and that's what you want,
14:20
then there are various annotations you can put in and you're just going to look them up.
14:25
I'm not going to cover them in this course.
14:29
So if it's a way of optimising the programme because because evaluation is a little bit more expensive than other evaluation modes.
14:31
So there's a thing called the sanitation's.
14:38
You put exclamation mark in front of your arguments and we'll make sure that they're forced and evaluated before invoking the function.
14:42
There's all sorts of ways you can tune the way Haskell executes at runtime,
14:48
but it's pretty messy and advanced stuff and it's quite easy to get it wrong.
14:52
So I'm not going to be covering in this course.
14:56
But if you're interested, you can go and read some articles of papers on it through perhaps Haskell the org.
14:58
OK. Very good.
15:05
David is an old hand. It doesn't say my hand is up.
15:09
Oh, so it's probably better delay on team. Nothing, nothing surprises me.
15:17
All right, let's get back to the business then. So we're going to continue the story of functions.
15:22
What we what we did last week was really just the basic syntax of the language with basic types.
15:27
So, I mean, that was all to bring you up to speed with the basics. Now we're going to start trying to do some programming proper.
15:32
So let's look at a very simple example of programme requires what we call iteration or some sort of repeated computation of the compute computer.
15:38
The answer we want. So it's supposing I wanted to compute the square or the cable, the fourth power of a value.
15:47
Of course, I could write them in a way we know how to do.
15:55
Now, like I say, the square of X is X times X and so on.
15:58
But the trouble is, what about X to the end?
16:01
I might have to write down a right hand side which has as many modifications as is the size of N, which in a balance I don't know.
16:04
So I can't write then I suppose I can have any news programme with every possible value and power,
16:12
but it wouldn't be this not the way we want to do it. And what if I change the problem slightly?
16:18
So clearly what we want to be able to do is to multiply something by itself any time I tell you, and it just happens.
16:23
So the secret to doing this is to spot a recurrence relationship.
16:30
And so what I mean by relationship, if you if you write at the end, are shown here, it's just as well about algebraically.
16:34
You just get X multiplied by itself and Times Square N minus one multiplications because the multiplication sits inside the X.
16:42
As you might imagine, there's a times one on the right hand side if you want, but it's essentially the same thing.
16:48
We'll come back to that in just a minute and then you think, well, okay, supposing I were to cover up that first X, what am I left with.
16:53
Oh, that X minus one. So that is a recurrence relationship which relates X N to X and minus one.
17:00
And to get from X and minus one to excel, I simply multiply by X and that's a mathematical relationship.
17:08
And that's the secret to writing an iterative programme in high school.
17:13
It's actually I say iterative something. It goes again and again and again and again.
17:18
And then. So what's going to happen? I'm going to ask to complete action in terms of the chairman's one and how do I do that?
17:22
Oh, well, that's going to be X times X to the two and that's going to be so the agreement is actually a three and so on.
17:28
And that's the nature of the operation that's going to happen. So you think, okay, well, that's easy.
17:35
I can work. That is a high school programme. So let's think about types.
17:39
First of all, what is this is call it power politics, an X, which is, let's say a float or a double, whatever we want.
17:43
Let's assume that the power is integer for the time being and we can relax that perhaps later.
17:51
And it's going to pop X to the well. The fact is a float the next the end is a float.
17:56
Just for the time being. I'm going to assume the administration with zero. And you can think later about how you might adapt it then is right.
18:01
Well, let's just implement the recursion relationship, which says, well, look at this up here we go to the end.
18:10
Well, that's what I've got on the left hand side. Power X in means X to the end.
18:15
And on the right hand side, I've got the equivalent mathematically from then minus one.
18:18
Well, the extra one is just another indication of the power of one smaller power, just going to someone's making a lot of noise.
18:25
I was going to meet you. OK, right, so that is a recursive function,
18:34
recursive function is a function which invokes itself in order to achieve some
18:43
goal and that will go on ad infinitum until we come to that in just a moment.
18:47
Right now, they think, okay, that's muscular, actually, because it implements the mathematical definition isn't unfortunately.
18:56
Let me just say I'm actually going to reproduce on the magic whiteboard what's probably in the notes.
19:02
I'm not going to pick an example, which is probably the same I haven't got in front of me.
19:08
But let's suppose I've got power. Two, three, so I want to calculate the power through so I should get the answer eight, shouldn't I?
19:12
Well, all I'm going to do is I'm just going to invoke the rules for this function.
19:24
Which I've got so.
19:29
The rules for this function, which are. I've written on Slide 42.
19:35
So it says, well, whenever you see something of the form Power X in and think pattern matching now.
19:40
So if I come back to the magic whiteboard, this thing in here, essentially we just look down the script and see if we can find a rule that matches it.
19:47
And indeed. We come back to here, we say there is only one rule that matches it and, oh, well,
19:56
what you do is you have to replace that with extra barracks and mine as well. So by replacement, I'm going to use a little single arrow.
20:03
Don't confuse this with a typo. This is just this is just me showing you how the reduction would unfold runtime in your compilers programme.
20:09
So what we do, we replace that with if looking to slow 42.
20:18
If you've got that in front of you, we've replaced that with two, which is the X, and we're going to multiply that by the result of powering.
20:21
Just I'm just literally copying from here, copying from.
20:30
Groups. I'm just literally copying from this from the the the slide, which just we've just had in front of it.
20:36
So this becomes parallel. Well, the deck stays the same, but this becomes once more the end becomes once more from that mathematical relationship.
20:44
I notice that I've kind of I've kind of written out the expression three minus one as if the evaluation is going to take its course.
20:52
So what will actually happen here is nothing. Well, what will actually happen here is let's have a little look.
20:58
Can I evaluate that? No, I can't, because although the left an argument is a no, the right one isn't.
21:03
Therefore, I can't use the multiplication rule.
21:10
But what I can do, however, as I can remove the power again, and that is the evaluation will say, well, all I have to do now is to do the place.
21:13
This thing I'll put in brackets just to make it clear what I'm doing, I can replace that with.
21:23
Well, yet another indication all too with powering.
21:28
You should give me two times the power of. There's the ex again, and now what's this what would happen in here would be and minus one.
21:32
All right, so that will, of course, become three minus one, minus one, so all OK, I'll write this out.
21:45
This is three minus one, minus one. It's going to get quite tedious to write these numbers out.
21:50
And as we know, the three minus one is two and two, minus one is one.
21:55
I'm actually going to just actually from now on, I'm just going to. So this site has been thought two times.
21:59
So three minus one, minus one is one, isn't it? So I'll put that in brackets and OK.
22:10
Same thing applies. So, in fact, I'm sort of jumping ahead of the evaluation here a little bit by saying,
22:17
because I know that three minus one is two and three minus one, minus one is one. So lazy evaluation actually won't do anything.
22:21
Actually those expressions intact because it's lazy, but I know mathematically they mean the same in this case.
22:27
Three months, one month one is one. So I'm just going to say. But again and again and so on.
22:32
So this will give me two times. Two times. What is this?
22:38
Well, this is two times power. Two zero, I guess, and then and then this picture and then let's just do one more,
22:42
this is two times to sort of looks like it's doing the right thing, doesn't it?
22:52
Two times. And then I got a power to. Well, just according to my rule here, we have got.
22:56
In the in here, PAREXEL is St. Patrick's and one is one.
23:02
So back into here, this would just be two times.
23:09
Well, this becomes two times power, so they're a month away.
23:13
Oh dear, I've now got a minus one in the ones Windsor said we're going to finish.
23:19
It isn't it's going to go on indefinitely. Multiplying two by itself.
23:23
Many, many, many, many, many, many times. All right.
23:28
The problem is, although I've got the right recurrence relationship and thereby leading to the right.
23:32
The right sort of mathematical structure, if you like, in defining accent, in terms of accent minus one, I haven't told you where to stop,
23:42
but one thing I do know is that X to the zero is one, and that looking at my precondition,
23:48
I'm only ever required to think about values of being greater than or equal to zero. I'm not I don't worry about the goes negative.
23:54
So actually stopping it seems like it makes complete sense. So it's a complete the picture.
24:01
But I really need to do is add a rule that says, well,
24:06
the rule is that the end is that X times actually amount is one unless and equals zero, in which case I know I can immediately stop.
24:09
But this is called a base case. So if the base case went to zero, I know the answer immediately, and the point about that is I don't have to recurse.
24:16
I can tell the answer straightaway. So let me just convince you that that works now.
24:24
Plus, I'll do one little bit shorter. Let's come back to the whiteboard. So now I will do power.
24:31
So to say, right? So what happens first when I look at my rule?
24:40
So the first thing that happens, I look at N and I say is an equal zero.
24:46
No, it isn't any two. Therefore, like the otherwise case. And I simply replace it with.
24:50
Two times power. X and then N minus one, and I'm going to write one in there, although it was actually just just from our one proposal on.
24:56
Ambivalently. Perhaps I'll put in explicitly two minus one, because it's quite interesting to see when it does actually get computed.
25:11
So that's exactly what kind of happens inside the machine as at least as the programme is written.
25:23
And now we come back and say, right, how do I evaluate power to three minus one?
25:28
So what is this apply? The same will again take a look at end is a zero.
25:33
Now, in order to answer that question, it's got to evaluate n hasn't it.
25:38
Otherwise, I don't know whether that's going to be true or false. And that's the point at which this thing in here gets replaced with.
25:42
One, so it's the act of testing the guard, which forces the otherwise lazy expression lazily evaluate expression to minus one.
25:52
So now we can apply the rule says, oh, OK, now, thank you very much. I now know that anyone does it satisfy the base case?
26:03
No, it doesn't. So I've got to do it one more time. Keep going. So now the two turns while power to that becomes power.
26:09
Oh, excuse me. Doesn't. What becomes, too, I'll put this in brackets again, just to make sure two times and then what I've got now is power, too.
26:15
And so what I'm like is one minus one. Well, I'm just going to add one minus one to be zero now.
26:29
Because I know that one minus one is zero, although it must bear in mind that it would actually be passed in lazily and the Guard
26:34
the next time around would force the evaluation of one minus one to zero and say,
26:42
now, see what happens now on this allocation of power, hit the base case.
26:47
Because and is therefore, I know the power to zero in this case is one.
26:53
So in my evaluation sequence, this becomes two times brackets, two times one.
26:58
Yeah. And you can see now that it terminates and I get the four, which is right.
27:07
OK, so that's the sort of gory, tedious way of thinking about it,
27:14
which is to sort of worry about how GHC executes your programme and how it unfolds, the recursion and how it gets the real answer.
27:22
So it's quite useful to go through these natural sequences when you were learning this stuff.
27:31
But there comes a point when I want you to think about it differently and here's how I want you to think about it differently.
27:34
Let me just go back and. Just tidy this up, I'm just going to get rid of all that mess here because we know that two minus one was one.
27:41
So this was the point. We were at before we invoked the next production, which got me to the next line,
27:49
so I don't want you to think about the sequence of production to get to the answer.
27:58
What I want you to do is think about this mathematically and think about this thing
28:06
is think about the power and function being a specification for a power and function.
28:09
What are the X and what are whatever? And you give me, I promise you, to give you back X to the end.
28:13
I don't care what the act is, I don't care what the end is along, the end is greater than it was there, I will give you back then.
28:20
So when your reasoning about whether you've got the recursive programme right, you don't have to worry about all this stuff in here.
28:26
All you have to worry about is the fact that this thing here.
28:34
But just as I call it, the leap of faith is just how faith in your own ability to write the recursive function correctly.
28:39
So absolutely any absolutely any in Puerto Rico?
28:47
Zero, I promise to give you the answer. I know that this thing in here is going to give me two to the one, which is to.
28:51
Right. And I don't care about how it does it because I know I'm going to get my recursive function right.
28:59
So now this simplifies to to what in my head. I see this simplifies it two times too.
29:04
And I know that's four. So when reasoning of reasoning about the programme to establish what it's going to do the right thing,
29:09
in my mind's eye, I don't have to unfold every single redacts and every single evaluation step I can get to a point in.
29:14
After one rewriting, I say, right, I know power to one is two.
29:23
Therefore I'm left with two terms. And that's what I think. That's right. I've got it right.
29:27
And the other thing I have to be careful about is that I've got the right base case.
29:33
And quite often, having right base case means looking at things like preconditions.
29:37
We'll come back to some more examples in a minute. All right.
29:42
So I'll keep reinforcing this idea of this leap of faith for those of you.
29:46
I mean, all of you all of you I know have done induction at school and this sort of might ring a few bells and you think,
29:51
oh, wait a minute, I was inducted to our induction, says I proved some property for base case.
29:57
Then I assume some property and I prove it. Prove a K plus one.
30:02
If you think about it, that's just precaution backwards, because she says you start with a problem the size end,
30:07
you simplify back perhaps to minus one, you solve the minus one, and you just make sure you've got the base case right.
30:13
So induction goes from the base case up to KOKH plus one, recursion goes from Kapos, walk back down to the base case.
30:21
It's just about the weight. The way where you're going to learn about reasoning about Haskell or recursive programmes generally is to use induction.
30:30
And that's something you'll be studying later this term or next. Alex, you have a question.
30:38
I just have to be careful about how many calls you have to like, how many, what you have.
30:44
Let me just turn to. But can you say the question again?
30:51
Yes. Do you have to be careful about how many recursive calls you have to prevent like this from having to do too many?
30:57
Yes, this is a good point. Yes. I mean, so the point is that I may end up doing a calculation which basically fulfils a
31:07
thing called the stars are going to come kind of come back to that later today, actually.
31:14
So if you can perhaps ask that question again later on, we can answer it.
31:18
Yeah, it's a slightly involved story and we don't really get to the end of that story until we've looked at things called Hurghada functions,
31:21
which are going to be coming up in a couple of weeks time.
31:27
It's a good question, but I'll hopefully be partly, if not mostly answered by the end of today's session.
31:30
All right. OK, thanks. Very good. Right.
31:36
So just out of interest, Mossberg wasn't dwelling on this.
31:40
How many multiplications it take to compute to the end, which kind of, I guess partly answers your question as well.
31:43
Well. And minus one or N, in fact, it's going to be N, isn't it, was it going to be?
31:50
Because I said on the end here, you might imagine in addition to this, because they might be want multiplication by one on the end.
31:57
Do you think, OK, where does that come from. That comes from this base case.
32:03
In fact, just to show you on the magic whiteboard things, I still have it here, you see what I mean?
32:10
There it is. There's this magic monitor. Oh, excuse me, so there's an extra multiplication by one.
32:14
So, in fact, you took two multiplications to compute to to the two. So in general, to calculate the end, it's going to end McCutcheon's,
32:24
so that means that the cost of doing this is proportional to end if I double and it's going to take twice as long.
32:32
And so I could count function calls, as I've just hinted, a good way to calculate cost is to cut multiplications in this in this case,
32:41
because I know that every time I do an execution step, I'm going to introduce another multiplication.
32:49
And by the end of the day, just looking at example, you can see in general I can have any multiplications.
32:54
So whenever you whenever a computer scientist thinks about an algorithm for doing something is there are better algorithms, they'll often think.
32:59
So let's just see if we can come up with a better one. So here's a reminder before we do that about recursive structure.
33:07
So here's the test. First of all, work at your base case.
33:16
And that's often quite easy because often there's really only one sensible base case, so let's have a think about that.
33:20
You asked me to come to the end. The only thing I know unequivocally how to solve is actually to the zero because of the precondition.
33:26
So obviously will take my basic, I should say, X to the zero as one tick.
33:31
And I define the recursive case, which involves finding this magical mathematical recurrence.
33:36
Once once you found that, you just encode it and you make sure here's what I can say intuitive.
33:42
You make sure that the recursive call is to a simpler sub problem and by a simpler sub problem.
33:48
What I mean is it's one step closer to the base case and that's very much in inverted commas.
33:54
In fact, if I go back, can you see what's happened here? The base case has been an equal zero.
34:00
Am I recursive call reduces N by one, which takes me one item closer to zero than I was before.
34:07
And you think, well, why is that important, because if it doesn't do that, it's never going to terminate.
34:15
If I if I keep going and don't get close to the base case, I'm never going to turn it's going to diverge.
34:19
Could end up with an infinite computation. I'll show you an example of that in just a minute.
34:25
Now, in this case, it's really quite simple, because if I'm stuck, then then I would try to construct a simple cell problem.
34:30
In this case. It's just I just invoke the function on end minus one.
34:36
But in other cases, it could be quite different. It could be and plus one could be entitled to it could be a gift to you know,
34:41
there's all sorts of ways in which I can converge on the base because it isn't
34:47
always necessarily the case that we're algorithmically so mathematically,
34:50
numerically, if you like, going one smaller, one smaller, one smaller, until we had this case,
34:54
it could be that the whole thing's flipped the other way round so that maybe my base case is for some men and I start with zero zero one to up to end.
34:59
It could be that like ping pong back and forth, because maybe there's some numerical algorithm which which takes me plus minus,
35:07
plus minus and maybe maybe the magnitude of the difference with the distance and the bicycle is a convergent.
35:13
There's all sorts of ways in which we can have sensible recursive functions which which converge nicely.
35:20
So we'll see small examples of the best thing to practise and see what happens.
35:26
OK, so we solve those problems by recursion. You know, in this case, I solve it by invoking Power X and minus one.
35:30
And as a you can think about every single reduction step happening or you can say no, look, let's just reason about this.
35:37
I know for a fact that if this function is doing the right thing back will come to the end minus one.
35:42
I don't care how that game, I don't care how long it takes, it's going to give me the R minus one.
35:48
And if I multiply X by X and minus one, I'm going to get to the end, which is exactly what the function is designed to do,
35:53
something like when they write a recursive function and just try to add some rest.
36:01
So just so one step and back to self to finish the rest of the sound was very poor on your question, so I didn't quite get it all.
36:07
Then you just say once more. So if I can and I mean like they write to recursive function, it just sucks that rest.
36:18
They needed to. Detail can't hear anyone that Tony or muted.
36:39
Someone has made to me again, because I haven't set the I'll do the settings and I'll have a break in a minute, please don't meet me.
36:54
Thank you. So I said, I didn't hear that. I didn't hear the question.
37:02
So I think we'll have to put a pass on it and pick it up later, especially if it's not if the answer isn't clear.
37:05
By the time we get to the break, put something in the chat or whatever, or ask me after the break.
37:11
OK, so. So, yes, this is the structure, you solve the problems by recursion,
37:19
and then you combine them to get the answer and that's what I can bottom in this case just means and putting
37:25
this multiplication step in here to get me back to project their minus pointing towards the end of this case.
37:29
OK, now it's important that when you make the recursive call, the problem has to be simpler than the problem you started with.
37:36
Otherwise the programme diverge. So here's a very simple example. This looks like a perfectly well behaved function.
37:43
It's got very similar structure. The one before except the recursive step.
37:49
Invokes the looping function with exactly the same argument that it started with,
37:54
and if you unfold that you're going to get something like this I looking for,
37:59
I see it's one plus four, which is one plus one plus looking for and it's going to diverge.
38:03
So you've got to construct a simpler problem. So for the rest of today,
38:12
we'll look at some examples where the simplest problem has different structures depending upon the problem we're trying to solve.
38:16
Good. Right. I think that's what we'll do is I'll do it.
38:27
I'll just do the better version of power and then we'll have a break.
38:32
So this will take a few minutes to do so. This is go up to the original mathematical relationship.
38:36
This is a linear example in the sense that the multiplication is linear in in you might think, what can I do better?
38:42
So just looking at that.
38:50
So rather than picking off the first X and then just spotting the fact that there is X X minus one, supposing we split it in half.
38:52
So I take this expression here.
39:02
And I cut it in half and I get to some expressions it provided and is even I get to some it actually the same, aren't they?
39:05
They're both representative to the two. So if I multiply the two by itself, I get to the end.
39:13
So you might think, well, that should also work. Of course, I've got to worry about what happens if anything odd,
39:21
and the only difference is that if any is old, there's got to be a multiplication by X somewhere.
39:26
Otherwise, we get the wrong answer. So how about this? So his parents wanted the same type before, same preconditions before, same base cases before,
39:32
because I know that regardless of how I do it, it's to the end of the zero is one.
39:44
So we'll have to think about is how to encode the rule we've just seen, so what it says it says was right.
39:51
If I've got some positive value of knw, what I'm going to do is to compute X to the end div two.
39:57
So I'm going to divide it by two rather than subtracting one.
40:05
For example, I'm not going to name this K because what I'm going to name it because I going eat twice,
40:07
because I've got if I, if I need K to be X to the end of a two, I need to be able to square it or multiply it by itself.
40:12
I either will do in this case. I've chosen to multiply it by itself just to make the multiplications clear.
40:19
So you can see popping out on the plane. So if I recursively invoke X to the end of a two and call the result K.
40:23
In the event that rain is even ice simply returned to Times K, and if any is odd, I return Katie times this.
40:32
Faarax So just like well say so if if any three and one gets slightly.
40:40
But if it is five, I guess I want to divide the fight by two giving the two because it's integer division, no integer division stinkier.
40:47
So then I take something, what is say X squared multiplied by itself.
40:58
It gives me the four. Oh and I'm now missing an excited multiply the result by despair x and there are various ways you can encode this.
41:04
You could replace this line of code by that, or you could use housecalls squaring function and you could do that.
41:11
But I said I've chosen to do K times k just so you can see these multiplications popping out from what's about to follow.
41:19
OK, so now think, OK, what's the cost now in terms of the number of applications?
41:29
Well, let's have a look and see. See, it's quite a different computation structure there.
41:33
So I'm going to draw a little picture for you. Now, remember the end of the last lecture I showed you how to represent an expression by a graph.
41:40
Didn't I just remind you about that? What was the example of the example was something like.
41:47
What did I do? Double, wasn't it? I said something like double.
41:58
So the task of double X is X plus X. And I said that.
42:04
You can represent that graphically. By this.
42:15
And that was the trick to getting those evaluation to be efficient.
42:21
So I compute the facts once, but refer to it twice essentially.
42:26
So I can do the same trick here, right, so our problem here is we've got power in.
42:32
For an arbitrary and arbitrary and greater than or equal to zero and what I'm going to do,
42:40
I'm just just for the purposes of this diagram, I'm going to. I'm going to manufacture the case where we always hit this rule here.
42:45
Everywhere until the very end, so in other words, I want to pick a value X such that every time I divide it by two, I get an even.
42:57
I believe n every time I divide it by two, I get an even number.
43:06
So you think what sort of numbers have that property?
43:12
Can anybody think what sort of number has the propertied every time we actually get an even number?
43:16
So how about a pair of two, because a pair of two?
43:22
Looks like something like it was a one here and there's a whole bunch of zeros on the.
43:27
So if I take that number and divide it by two, dividing it by two is essentially the process of knocking off and throwing away that digit.
43:35
And I'm left with another number, which has got another zero in the end. Well, that must be an even number.
43:42
And if I throw that away, divide this by two. I've got another number which ends with a zero and so on.
43:47
So powers have to have the property that every time you divide by to end up with an even number.
43:52
Till I get to the very last digit one, I'm going to end up with the one because we're talking about binary representations here.
43:58
All right. So I'm going to pick for my end a pair of two just so that we kind of pick out the minimal case and of the number of modifications only.
44:04
And then we can think about what happens in the opposite case. But I get the worst case. We'll come back to that in just a minute.
44:15
So let's just get rid of that. We show you the reduction sequence we get now.
44:20
From this right, so that's going to get replaced by well, that's going to be I'm going to represent that by well, what does it get replaced?
44:27
Let's go back to the programme. And I see. So we generate K, which is X to the end of the two and then multiply K by itself.
44:35
So here comes the what are going to do here if I write down here.
44:44
The. Results of Power X and over two, and this is integer division,
44:49
so I'm going to use that little mathematical thing there to represent interested and divided by two.
44:55
So this becomes the multiplication of. Something with itself which had Coke and this something represents power and a bit too much.
45:00
Well, how do I calculate power and which I'm assuming at this point I haven't hit the base case.
45:11
Well, what do I do? I go when I calculate Power X, and then what if I'm starting with number two and divided by two?
45:16
Must have been over four months.
45:23
So the next time round, back to my diagram, I must end up with the multiplication of K with itself where this time K is power.
45:24
X and then over to the body, but she was an.
45:35
So each time I had a layer to my little graph, my little reduction tree, if you like, overreduced and by a factor of two,
45:40
every time I reduce them by a factor to the multiplication, to my tree, to my graph.
45:49
So this, of course, will go on and on and on. And eventually we're going to hit a base case which says, what happens when I get power X?
45:54
Well, eventually I must hit the coast, but I get a one down time.
46:05
Because even if I got to starting with an end is a to it's even even even even even eventually I get that one on the end.
46:11
And so I'm going to get this as a sort of base case. This is sort of intermediate base case.
46:19
And what I would do in that case are, OK, this case is no longer even.
46:23
So we don't use this rule now. We hit the old rule.
46:27
So the is are going to take the X and multiply it by times, Kennebec is extended to X and so back to the magic whiteboard this would give me so.
46:30
Dot, dot, dot, dot, dot, have these two arcs coming down to here.
46:39
And now I get the multiplication of X with the multiplication of K with itself.
46:44
With this time K is. There's my here when if I divide that by two, I get down to zero, so I've now got down here, I've got power.
46:50
X zero kitching, there's my base case. Yeah, what about you in the base case.
47:02
Our team one, so this thing. This thing gets replaced with one and then I pop back, so one times one is one.
47:08
Sometimes X is X, X times, X is X squared, X squared times X equals the fourth and so on.
47:21
So I pop back up to the tree and shown up out of the out of the end here becomes.
47:26
Does my ex the. Now, here's the interesting question, how many multiplication do I need now?
47:31
You know, this is like evaluation happening, but with this sharing, how many multiplications are in the street now?
47:38
For a given value in so this is seen in this case, the end is a power to can anybody tell me how many more there are in general as a function of an.
47:45
It's not linear anymore, is it? Look, look to him.
47:56
Very good. So the number of modifications I get.
48:00
Is look the base to them now, if you think about what we have before we had a we had an algorithm and we talk about his complexity,
48:05
perhaps we should talk about some simplicity.
48:16
We call it can be decided equals complexity, which is basically how the how the programme scales as I increase the size of the problem.
48:19
And we started with a pairing algorithm that scaled linearly.
48:27
So if you increase this, this is n if you like, and this is the time taken.
48:33
It's a complete access to the NSA with some it's some measure of time in this case it was the number of multiplications, wasn't it?
48:38
So, so so my number of modifications is a proxy for time in that is linear.
48:43
You give me an end that's twice as big text twice as long.
48:48
And amazingly, with the strategy of not replace that with something which grows much more slowly,
48:51
which is and this is this is because ordering these scales.
48:57
Scales linearly, and now we've ended up with an open approach with a logarithm. And if that's not bass, too, isn't it?
49:05
Because I'm splitting the problem in two. Why is it low base to its low base, too?
49:10
Because of that. And that's the that's the sort of great if you're not doing much computing.
49:15
That's the great art of programme. Our algorithm design is coming up with ever smarter algorithms which have better complexity.
49:24
And this is a good example. But just as a thought experiment, actually, perhaps if I saw how we got to log the log and Vista is not a good idea,
49:32
how we got to log and Vista is not required, is not required in what sense?
49:44
It should be like trying to figure out why that is. Oh no, this is very intuitive.
49:49
You're going to be studying algorithms in great detail next time,
49:54
but this will be formalised and you can actually derive these sorts of properties mathematically.
49:56
I'm kind of appealing a bit to intuition here.
50:00
How many times you divided them by two before we get to one and you say, oh, that's a again, you should know that.
50:02
So it's very much intuition and I'm going to do similar things in the coming lectures,
50:08
actually, but I'm not trying to, too, because that's something we'll be doing next to.
50:13
Good question. Well, let me just turn it off and just try so so what happens?
50:18
That's the best case, isn't it? Because we keep hitting the even case.
50:24
Well, the worst example I could get is I've got an end that goes in my home in my.
50:27
It's. But what happens if I got a number, which every time I divide by two end up in odd the odd case?
50:39
Well, that's a number that looks like this. Well, that turns out to be something of the form two to the N minus one.
50:48
You see, if you if you don't know what that is, then why are you in the next few weeks,
50:59
what with Hauber and hardware and logic and stuff, you know why?
51:04
So that would be the worst case. Well, all that happens now is if I start with something about Power X and.
51:09
Yeah. And I know I'm going to get some multiplication at the top of my tree.
51:16
Now, going back to my programme in the old case every time I know because I've got a spare X lying around, haven't I.
51:19
Otherwise it's exactly the same sort of structure. So back to the diagram.
51:24
I'm going to get X here, but I'm going to get the multiplication of something with itself.
51:28
And this thing in here will be Power X and two.
51:34
It's otherwise identical, apart from the. So now I would get if it's still odd,
51:39
I get in here and then I get a multiplication of something which itself and this will be power and so on, so forth.
51:43
So it's exactly the same as the previous diagram.
51:53
Except that having said that, having one multiplication here and here, I've got an extra one in here.
51:55
So it's actually of the order to log in is exactly twice as many.
52:00
But from the base case is twice as many than multiplication.
52:06
But the point is log in and to log and had the same sort of asymptotic property that both scale with log in the log in is the dominant function,
52:10
not the factor, too. Two. So we don't really care about constant multiplication factors which were reasoning about complexity
52:17
or we care about is the fact that the long term asymptotic behave the programme because as log in.
52:24
OK, so it matters not whether we hit the East Coast,
52:30
the East Coast or some arbitrary combination of the two, the algorithm is we say this is order logic.
52:33
Great, now that's good. So I'm going to pause and I'm going to set my room up again slightly differently,
52:41
I'm going to show you a couple of other ways to think about recursion. And so we're going to spend the second half just doing a few examples.
52:48
So how about we have a break until three o'clock? So you can have five minutes to stretch your legs and make some pretty.
52:54
Are you still with us? Can you hear me? It's all good, all good.
58:17
Excellent, right, let's carry on then.
58:23
So all I can do now is I'm going to go through some of this again from a slightly different perspective, because I know that this is for some people,
58:27
the the really the hardest part and understandably,
58:34
I guess so I hope there's plenty of exercises in the sheets and elsewhere that you can you can find and play with to get to get used to this.
58:37
But what am I going to convince you, hopefully in a very short space of time is actually really, really simple to get this right.
58:46
And the secret is, I think, to have this leap of faith and it's going to bring you back to the oh, hang on a second.
58:52
I'm not sharing my screen in my bed with me. What?
58:58
OK, good. So we're back on the whiteboard now. So the is a leap of faith and that's what we're going to try and drill into you now.
59:15
So if we go back to the original power and functions won't be the right.
59:21
At the beginning, we said, oh, well, the president says the next to the next to the anchor be expressed in terms as X times X and minus one.
59:24
We wrote a Haskell function to do that. We added the base case and I shall give a simple example.
59:31
And we unfolded the recursion step by step by step. And I said, I don't want you to think about that for now.
59:36
I think it's OK because you need to convince yourself it all works. But in general, I want you to use this leap of faith.
59:42
And so here's a slightly bigger example on this on the magic whiteboard here.
59:47
What if I've got power of two to some big number, like two 11? You don't really want to go unfolding 11 recursion steps you can escape.
59:52
Yes, I can only still see the power to to the 11 example.
1:00:03
And I'm going to be seeing a different example. That's the same example. So I'll just put in I make a little start here.
1:00:09
Can you see a little star? Yeah, I can see the stars. Just you're on the right. You're on the right.
1:00:14
You're in the right place. You. Yeah. So this is this is back to the original side up its way back.
1:00:17
It's like forty something I think. Right. Supposing Panopto to some big number.
1:00:22
I don't want to write out eleven reduction steps to convince myself I'm going to get the right answer.
1:00:26
What I want you to do is to think like a lesson. Let's invoke the rule once and we're invoking the rule once gets me from power to eleven.
1:00:31
So this expression here which is two times power to ten and at that point you should,
1:00:38
you should stop and think to yourself, wait a minute, I don't have to worry about how this is going to happen.
1:00:43
I know that if the power and function is correctly defined, it will give me back to to the power that recursive call will give me to the pattern.
1:00:47
And therefore, which I happen to know, by the way, is is one thousand twenty four.
1:00:58
And I don't have to care about how it does it or when it does it or how many steps it takes.
1:01:04
I have a memory it uses. It's going to give me one thousand twenty four.
1:01:09
And from what I've got on that, but what I do with that, as I multiply it by two and that should be the answer.
1:01:13
Well, if I multiply twenty twenty four by two, I get two thousand forty eight, which is due to the power of 11.
1:01:18
So I convinced myself, I've reasoned this, assuming, of course I've got my base case right and it doesn't determine it correctly.
1:01:23
The reason that I'm getting from power to eleven to twenty,
1:01:30
forty eight correctly and I haven't had to do it, but thinking about every single recursive unfolding,
1:01:33
hence this sort of leap of faith and it's terrifying at first if you're not recursive functions before because
1:01:40
you know you're writing a function and on the right hand side you're invoking the same function again.
1:01:46
And you think, how can this possibly work? How do you finish writing the code yet?
1:01:50
And I'm invoking the function that I haven't yet finished writing. And it's a terrifying sort of knot tying it to you get your brain into twist.
1:01:54
But actually, this is the way to think about through this loop right now.
1:02:02
I'm going to now go to I'm going to turn the camera on and I want you to tell me whether you can see.
1:02:06
You should be able to see me into the piles of paper with an M and an end, can you.
1:02:15
Is that is the camera about correctly poised for this? Yes.
1:02:20
Right now, if you go to the unassessed exercise, you will find that there is there is a.
1:02:26
Actually, let me. So I'm probably quite small at the bottom.
1:02:36
Let me let me just before we did, let me just take you to the other suspects. So nobody but second suspects associate.
1:02:42
I'll just explain what the problem is about it. So you are given two integers and we have to write a function to add them together.
1:02:47
So whilst I've got my main monitor up here, you might think, well, how would I write a function to add two numbers together?
1:02:55
Well, let's just think about the time to start with. So I'm trying to do something like this. Let's just sounds pretty simple and change the type.
1:03:03
And you think, how would I do that? Well, dir yes. Guess what, I'm gonna do something like this.
1:03:10
You think, well why is that an interesting function to write and.
1:03:18
Well it isn't really. Of course that's what you do. In fact, you'll learn very quickly in Haskell.
1:03:22
You can actually simplify this even more. You can just that and it will work.
1:03:26
But we'll come to that while that's much later in the course. So of course, that's the way.
1:03:31
Now, however, it's a game. We're going to play the game. So we're going to try and write this function.
1:03:36
But the rules of the game as follows. You can compare any of the either the two numbers you were given with zero.
1:03:41
And the only other thing you're allowed to do is to add one using perhaps the successive function
1:03:48
or plus one or subtract one from either the two or that's the only thing you're allowed to do.
1:03:52
So you can't write in plus in for an arbitrary m n you've got to try to piece together using plus or minus one and a comparison with zero.
1:03:57
That's all I'm going to let you do. So it's a game you would never watch it this way just to get you to think about the recursive problem
1:04:06
and how to get this leap of faith into your heads and trust yourself that it's doing the right thing.
1:04:12
So I come back to this in a minute. Now, the I aren't going to stop sharing my screen, which should give you now.
1:04:19
Can you see? Can you see me full screen? Yes, right, right.
1:04:28
So here's the problem as described set up on the desk here. So I've got two numbers.
1:04:36
Now, what I've got here are two big piles of paper. And the idea is that this represents the number one, but.
1:04:39
So that's two. So this is about 500 because it's a frame of pipe.
1:04:48
So I assume there's about five million sheets of paper in that.
1:04:51
So I can put the challenges to say here I've got two numbers represented by sheets of paper.
1:04:54
So this might be eight hundred and eleven and this might be two hundred and three or something.
1:05:01
And I'm trying to add these two together. So what I'm actually trying to do is to produce a number that looks like that.
1:05:06
Can you see so you get an arbitrary amount in. I want to get the sum of the two numbers.
1:05:11
That's just the total number of sheets of paper.
1:05:16
So in my analogy is that one sheet of paper represents number one and two represents two and so on, so forth.
1:05:18
And you can see that it's a pretty daunting task because there's an awful lot of sheets of paper. Right.
1:05:24
So how am I going to do it? So I'm only allowed to compare.
1:05:30
All of these but zero and I can only add and subtract one so I can subtract one by doing something like this and removing the sheet of paper,
1:05:34
or I can add one by checking this part of compiling a sheet of paper back on the top.
1:05:43
That's all I'm allowed to do. Right.
1:05:47
So how am I going to do so? OK, let's follow the rules based case.
1:05:51
When can I write down the answer straight away? How about this if I'm adding zero to something?
1:05:55
They also saw something in. Bingo.
1:06:05
So when I come back to the topic in just a minute, I'm going to write down things as ad and if I may zero, the answer is, hey, I'm done.
1:06:08
So all I'm going to think about now is the other case. Where AM isn't zero, where is some thumping great number like this one here.
1:06:18
What do I do. So you think about the one thing I can think of several strategies,
1:06:27
and I'll show you a couple of ways of doing this, and I deliberately want to start with this one here.
1:06:31
How about this? Supposing I take one sheet right now?
1:06:37
First thing I'm thinking is that's my base case. But time is zero. You.
1:06:41
So whatever I do, I've got to construct a simpler version of this problem that gets me one step closer to that base case
1:06:45
and here's how I can do I can take one sheet of paper and put it on the side for the time being.
1:06:52
Now, I can add that to that. Right, and then all they've got to do is.
1:06:58
Remember to put the sheet of paper back. Panopto, yeah.
1:07:06
So let's think about that again to add these two numbers together.
1:07:14
To get one step closer to the base case, I remove that and then I think, oh, how do I add that to that?
1:07:20
If only I had a function that would add that to that, I could just tip.
1:07:27
Well, I do. It's called add.
1:07:32
So that adds and minus one to N and that sticks the piece of paper back on the top and that reconstruct the answer for me.
1:07:33
So if I get that you're showing the screen, that's the type that in most fresh in our minds.
1:07:44
You should be able to now see the GHC. So let's see.
1:07:53
So what did I say? I got to examine and I said something like M zero.
1:08:00
Then the answer is, what did I say?
1:08:05
It's n isn't it? Because zero plus anything.
1:08:09
Otherwise it's missing my line.
1:08:14
What did I do? So I decided to subtract one from which allowed us to do and I wanted to add and minus one to N and
1:08:21
then I get the right one out because I remove one sheet of paper from a sheet of paper back again.
1:08:31
And there you go. So this is a way of adding two numbers, just using plus and minus one.
1:08:37
So if I save that coming here just to check this out, what is one?
1:08:43
Well, let's just check the base case. Good. And if I do, I want to I want to know when I get ten, I just convince myself.
1:08:48
I thought about it for a little while, but it doesn't get the right answer here. Problem solved.
1:09:00
Excuse me, sir. Yeah. What is the in this question?
1:09:04
Why do we even have to do minus one? Plus one? Can't we just do add that I told you at the beginning, but it's just a game.
1:09:09
We're not going to not let you do that. To deliberately control its problem, where you've got to get the same answer just using plus or minus one.
1:09:14
Of course, of course, if you were if you brought this picture of the of course,
1:09:28
you would just use am concerned, but I'm not going to let you because I want you to see the thing.
1:09:31
Now, I want to come back to the Arctic Ocean. Is this right in this example? There is no regulation in this example.
1:09:36
We're going to add that now. And excuse me, but there is recursion, this example.
1:09:41
Because this ad function here is using the ad function on the right hand side.
1:09:49
Yeah, OK. Yeah.
1:09:55
And the point is, I've constructed a simple problem because I know that it's a simpler problem because my first time it's gone down by one,
1:09:57
which takes me from one step in this case, one step closer.
1:10:03
There's more than one step closer to my base case, so I know it's going to terminate.
1:10:07
Andrew, you've got a question. Yeah. So you haven't Brexit and one.
1:10:12
So why would you impose one before doing so?
1:10:17
Let me put some brackets in. Just make this clear. So I've added my response to end and then I want the result.
1:10:22
What are the bits of paper that I saw myself?
1:10:34
So is it OK if I write and bracket at minus one and bracket and plus one?
1:10:44
Oh yeah, I'm going to come down in just a minute. There are other ways of solving this problem. This is just method number one.
1:10:54
I'm showing you this very deliberately, by the way. I want to come back to the camera, if I can.
1:10:58
So we got got this printed on your in-transit, so let me you should now be back.
1:11:06
You can you can see me full screen up. Yes, indeed, yes, we can.
1:11:14
Thank you very much. Right now, then, now let's think about so that this is the leap of faith, this thing in here just being.
1:11:22
Oh, I just don't know. Let me supposing I don't trust myself.
1:11:29
I don't trust this leap of faith. I want you to see something quite interesting. I mean, let's listen.
1:11:33
Let's just do this page by page. But I am on a clock.
1:11:36
Right. So what do we do? We said I've got to subtract one from em.
1:11:40
So I'm just going to put this piece of paper down on the desk there and they're going to put it there because later on,
1:11:46
I've got to put it back on the top yet.
1:11:51
So you might imagine I write on this piece of paper in case I forget, you know, when you're done, please put me back on the pile, OK?
1:11:53
Right. So I put that piece of paper lovingly down there and then just it's touching the table top.
1:12:02
So so we'll have to do now is add M minus one to end and then I'll put this back in.
1:12:07
I'm done. How do I then minus one to end I invoke the rule again. So I subtract one from this.
1:12:12
I say, well don't put me back yet. So I put this on top of the desk. Right.
1:12:17
How do I add that. I subtract one from this. Yeah. And write my thing and I put it back on the desk and can you see what's happening on this desk.
1:12:22
What do we call a structure that kind of works like this stack a stack?
1:12:32
Yeah, so what I'm building here is a stack of things to do later.
1:12:41
And this is what this is what ghc what I just thought this is what she's actually doing.
1:12:47
It's doing this. Oh remember to put this one of course is not a piece of paper it's doing in computers.
1:12:51
So some time later, some time later, quite a lot of time later.
1:12:56
This stuff has got to this point here and she's thinking for goodness sake, what is this guy doing?
1:13:02
Because I know I've hit the base case. Fantastic.
1:13:10
I know what to do. And plus, in his end, when a mesero so we kick in to the base case, you say, well, hey,
1:13:14
the answer is that except, of course, I've got this enormous stack of work left to do.
1:13:19
So I said, what was that? Oh, please give me to the top. So please give me to the top.
1:13:24
Please give me some time later. Yeah. We get all this added to the top and then that gets added to the top and then
1:13:30
this gets added and eventually the last sheet of paper gets added to the top. And guess what I've got.
1:13:38
And plus n and that's the way it works. Now, what would you rather do when your reasoning about what you've got this additional function?
1:13:45
Right. Would you rather think about this than I do this?
1:13:53
And no, you simply say I'll take one sheet of paper off the top one, just hold it.
1:13:56
And so far does the leap of faith. Let's think about that from the top Panopto.
1:14:02
Yeah. Now, there's another way to solve this problem, lots of ways to solve this problem.
1:14:09
Here's another way to do it again, just using plus and minus one. So this is how we're going to how to stack required a stack.
1:14:14
And the reason why required is stack, because this plus one that was on the end of the function, there is another way of doing it.
1:14:20
So same idea. I go one step closer to the same base case, one step closer to the base case.
1:14:26
But now instead of putting it on the stack, I say, well, why don't I just stick it on here?
1:14:31
Yeah, do you think, oh, I'll put it on there and then how do I add those two poles together?
1:14:36
Well, just in that and and nothing I'm done.
1:14:43
Yeah, so there's no stock, so I've managed to solve the problem in a similar way, but not using the stock.
1:14:50
Yeah, so there's the leap of faith. I just do that. The leap of faith was put on that and I'm done.
1:14:57
And the reason why it works is because here I'm subtracting one from in here I'm adding one to N,
1:15:02
and therefore the sum of the two must be the thing I'm looking for, which is the present. So Andrew, is it a question about this?
1:15:08
Yeah, yeah, I think we were doing this initially.
1:15:19
So what I did initially was to put this piece of paper onto a stack and then add this to this and then put this back.
1:15:24
Yeah, I realise now, but initially I wasn't sure. So.
1:15:35
I was going to turn this off. We're going to cut it up. So you just see the difference.
1:15:40
So what do we do with an almost screen sharing?
1:15:44
To bring you back to GHC, so now let's do this another way, so I'll call this ad Prime.
1:15:50
So it's got the same type, but I'm just targeting, again, something like that, so.
1:15:58
So. What did I say? Well, starting base case came to an end.
1:16:05
And then if anyone is defending zero, then the answer was n otherwise, what do I do?
1:16:09
Well, now do slightly differently. I now add and minus one. Oh.
1:16:22
I am minus one, two and plus one, and just to convince myself it's going to terminate.
1:16:31
Yeah, I am indeed getting one step closer to the base case with this.
1:16:40
The fact that the end is getting bigger doesn't matter because there's no mention of any in the biggest case.
1:16:43
So don't worry about that.
1:16:47
Let's just actually invoked the wrong functions is a very easy thing to do when you've got problems as you've picked the wrong one.
1:16:49
I think that's right now. OK, so let's try out in a prime now, so nine zero zero nine is benign and ad prions to big numbers.
1:16:54
I guess that's right. OK, now that's interesting, isn't it?
1:17:10
Like, I'm just one more time. Just come back to the let's come back to the two sheets of paper.
1:17:15
So this idea of fitting that it requires no stack.
1:17:20
And that's called a tale recursive function. We've been looking at this again, we'll come back to tell recursive functions later on.
1:17:26
But the thing about a recursive function is it can run to completion without using a stack.
1:17:34
Whereas if I if I got the spare plus one on the end, one last look at the code with that plus one, that means that when I'm done,
1:17:39
I still have to add added one back and have to add one as many times as there were pieces of paper on this block.
1:17:46
But this idea is just tabacco. So the only the only storage I need to do to solve the problem is, is just with these two bits of paper.
1:17:53
I don't need the support structure. So tell recursive functions are much more space efficient,
1:18:02
because what the situation I had was when I got near the end, I had not only two arguments today, which were integers.
1:18:09
I've also got this stack of work to do when eventually I get to bicycle's.
1:18:16
So I can avoid this extra step with all the memory involved in storing story if I just do this a little recursive fashion,
1:18:22
so that's got me turn the screen again.
1:18:28
So just coming back to the example,
1:18:35
it's this plus one which makes the first version Nantel Recursive is the fact that once it's is called Tell Recursive,
1:18:38
by the way, because the recursive invocation is just to the function itself, there's no other work involved when I request the same function.
1:18:46
I'm just tweaking its two parameters in this case in such a way that what pops out is the right answer.
1:18:55
There's no additional work to do.
1:18:59
Whereas here when I wrote the function recursively giving me back and minus one saying I've got to add one onto the end of it.
1:19:01
And that's what created the stock. I'm hey, you've got a question.
1:19:09
Hi, excuse me. So you mentioned something about this evaluation.
1:19:16
Does this evaluation cause the end plus one to actually stack up?
1:19:22
Oh, that's a brilliant question. Yeah, you're absolutely right.
1:19:27
Well spotted.
1:19:30
If you see this example in here, here on in their prime function, this N plus one, the question was, does that actually get evaluated to it?
1:19:32
For example, is two, does that become three? Does it come forward? As you can probably determine recursion?
1:19:42
The answer is no. Actually, we just stack up.
1:19:46
We just stack up this enormous evergrowing expression. And it's only ever computed when we hit the base case when we need to know that value of an.
1:19:52
So all it's so I kind of sidestepped the issue.
1:20:02
It's slightly misleading in principle. This is a recursive function to be recursive function proper.
1:20:05
When I do that, I must force the evaluation of N plus one.
1:20:12
Otherwise, I haven't gained anything.
1:20:17
I'm just I'm just assembling this enormous and evaluated expression with lots of plus ones in it, which is tantamount to having a stack, isn't it?
1:20:19
So it's a really good question. Now you can fix it.
1:20:26
Somebody said earlier, you know, can I bypass the evaluation?
1:20:30
Yes, I could go in here and I could make that second argument strict, which would give me back my Terracross of property.
1:20:34
But there are other ways of saying the same thing.
1:20:39
So there are some other built-In functions in Haskell which have this secret forcing argument for encoded within them.
1:20:42
We'll come back to that. OK, thank you. I mean, you've got a question. Um, yes.
1:20:48
Um, can you hear me? Yep.
1:20:55
Yeah, I was just wondering, isn't it a bit redundant to if one is increasing and one is reducing, eventually level out up like, say, 500?
1:20:58
Is it possible to just do the double function then to skip a lot of steps?
1:21:09
I was just wondering. Well, I might have this if I stop if I start with that any smaller and they're never going to be equal.
1:21:13
Yeah. Yeah, you're right. You're right. If I did, you could you could. You could of course, out of next week.
1:21:24
The trouble is, what are you going to do if I say that those two pieces, those two parts are exactly the same?
1:21:29
I don't say on the small camera that if they're exactly the same, what are you going to do?
1:21:36
Um, just a double function on one of the are not allowed to use two times.
1:21:39
We're only allowed to use plus and minus one. Oh OK. It's a great idea.
1:21:44
But unfortunately I made the rules very strict, Richard, which is.
1:21:49
Sundering so by adding like they were like at the end, like where the plus one is, can we force the evaluation?
1:21:56
Yeah, no, you can't wear clothes. Everything is lazy, lazy, lazy until you start doing these these these called Stratman sanitation's.
1:22:07
So we don't really we'll come back to this and I'll show you how to get around it in common usage.
1:22:15
Is that right? Yeah, but it is a very good point.
1:22:21
You should the message you should take away is that in principle this algorithm is in principle, tell recursive.
1:22:25
But the reality of doing it in Haskell is that the latest evaluation means that it doesn't work properly as a recursive function.
1:22:30
But we can fix it. And and in this lecture is not the time to start thinking about fixing a union.
1:22:37
So in order to make a function, tell recurse, we must we must now do any.
1:22:47
I think we lost you there, but you mustn't do anything yet, you simply treat your arguments around and you should not wish to not do anything.
1:22:56
And that's just how they function. And we can't risk something else just called a function.
1:23:03
That's why it's called tell RECURSE. The last thing you do is to call the function says something like, we can process the argument.
1:23:09
We cannot do something like process the result of their function.
1:23:15
Exactly. The last thing you're allowed to do is to call the function.
1:23:19
You have to do anything else. Some quick questions, Dumi.
1:23:23
Richard. Your muted.
1:23:32
Well, Stephen Chen, you've got to question all these old hands, I think the old hands, because I sat down a while ago.
1:23:38
Oh yeah, I think it's teams just being extremely slow in that case.
1:23:46
I've got a question, though, and I was wondering for the success and presence functions to the foreign stuff.
1:23:50
Yes, I did know that everything's everything's lousy.
1:23:57
So I could have I could have written here. You know, I could have said I'm trying, yeah,
1:24:03
I could say something like the predecessor of M and the successor and but know they're still done lazily.
1:24:11
Richard, Richard is an old hand. We got a fresh question. No, I think well, I took it down.
1:24:21
All right, let's get back to. OK.
1:24:30
So I think what you should do at this time, in the end,
1:24:42
I might do another example from the unassessed sheets and what you should do is work your way through those sheets.
1:24:44
Yeah. Another thing I was going to tell you, by the way, because I wasn't sure how this is going to work until I spoke to and who does the timetable.
1:24:50
You'll see there's a slot on your timetable on Wednesday mornings at 10 o'clock.
1:24:57
And so we're going to use that as a catch up session. And it's optional.
1:25:01
It's not a lecture. It's just that if you if you're badly stuck on something and you want to come along
1:25:05
and just type type questions into the chat or raise your hands and ask questions,
1:25:10
then I will be online somewhere. But it's completely optional and voluntary.
1:25:15
So if you feel comfortable where you're at, you don't have to come. And we're not going to be doing anything at all at once.
1:25:19
We're simply going to be looking at, again, what we've covered and where people are stuck if you're if you're stuck.
1:25:23
So if you're not stuck, you don't have to come. And if you are stuck and you want to come, it's 10:00 am Wednesday morning.
1:25:29
And the timetable here. So it's going to finish off the stuff on square roots here.
1:25:34
That's what I would do. If it's OK with you,
1:25:40
I'd like to re re put my desk back the way it was because I've got my stuff over in the place of just going to turn the camera off.
1:25:42
Now, give me some more real estate and hang on a second.
1:25:50
Hang on a moment. OK, I'm back.
1:25:54
I guess I should just make sure you can hear me just somebody put a hand up or shout something.
1:26:40
Kasab unplugged anything, can you hear me? Yeah, yeah, OK, that's great.
1:26:46
Thank you. Right then. So we're going to get another example now.
1:26:51
So what I said to you before was that we have to ensure that our recursive call is
1:26:55
one step closer to the base case and that doesn't need the examples we looked at.
1:26:58
It's like, oh, I started my base case is zero, therefore I've got to subtract one somewhere.
1:27:02
But you might imagine that my base case is some end and I started zero and therefore I have to add one or two to get close to the base case.
1:27:07
And it may be that getting close to the base case is based upon some other numerical computation of.
1:27:14
Stephen, you've got a question. It was an old hand, and that's an old one.
1:27:19
Well, it may be based on some other numerical computation or some other another computation.
1:27:26
And I'm going to show you an example of calculating square root square. That's what happens, right.
1:27:30
So this is the famous algorithm. It's called Newton's Method of Calculating Square Roots.
1:27:36
If you've seen it before. But we end up with this iteration, which you can see on the slide here, where we start with some approximate action,
1:27:42
some e0, for example, and we go from one approximation to the next one using this magic formula in here.
1:27:50
And you think, well, where does that come from? Well, I suppose I should duty-bound to tell you.
1:27:57
Let me just go to the magic whiteboard. It almost all goes down to calculating zeros.
1:28:02
It functions. So if I've got a function. Does something like that, and I want to know where the function hits zero, so.
1:28:06
I'll do it mathematically. This is some. X is here, and then I'm closing out of X, the idea is I have some approximation.
1:28:16
And which I'll call a and and I want to get to the next approximation, I'm going to do as follows.
1:28:25
I'm going to look at that there. Look, at this point here on on front, I'm going to use the tangent of that point.
1:28:34
The slope of that tangent to get to this point, and that's going to be my next approximation.
1:28:45
So you think to yourself, okeydokey, and what can we say about that?
1:28:51
Well, this distance here is. If I am and if I divide, if I n by the distance across here, which is I am minus.
1:28:58
And plus one. That thing is, by definition, the slope of the curve at the point and commonly known as.
1:29:14
And I'm going to use my this prime does mean after I mean, it does mean the differential this point.
1:29:24
It's not just a Haskell identifier. So I thought I'd be right that that means that I and plus one is again, just by rearranging this and I guess.
1:29:29
Excuse me. And I get F of a n divided by Catrine of a L and there we are.
1:29:41
Now the question is. If I try to calculate square roots, what should I take for my function?
1:29:53
So the trick here is to spot the fact that if I have the quadratic, it looks like that.
1:30:00
And I'm going to have a name clash looking at my notes, so I think I'll call that one.
1:30:08
We'll call this why in this effort? Why?
1:30:13
Now, if I raise this quadratic so that that distance in there is I'm trying to calculate sort of excellence, I think, on my my notes.
1:30:19
So if that distance is X, you know, and I pick this quadratic, I say that F of Y is which one do I want?
1:30:27
I want Y squared minus X, then that implies that this is zero.
1:30:38
When Y squared equals X implies that Y equals the square root of X, that means that the zero of this function.
1:30:46
Must be at root X, and if I wanted the zero on the other side, that would clearly be minus one because there are two solutions, right?
1:30:55
So if it was widespread minus X, that means that frim of Y must be to Y to Y because I've changed the name.
1:31:05
So if you plug all that into this formula here. Magically, out pops just by straightforward rearrangement, this recurrence here,
1:31:16
and that's called the Newton Newton's method for calculating square root.
1:31:26
So you have to repeat the process again and again and again, of course. Now, think about this.
1:31:30
These presumably these these A's. These are approximations of floating point numbers.
1:31:34
So it's no longer the case that I've got some base case when we're talking about integers and I'm subtracting one to get to a base case.
1:31:38
I'm not talking about an iterative computation.
1:31:45
We've got floating point numbers and they're being transformed in some completely mysterious way, according to this this current relationship.
1:31:47
So couple of things to think about. When are we going to terminate? Well, presumably when my approximation is close enough to the square root of X.
1:31:55
In other words, if I square, I should have some some number which is close to X.
1:32:06
And what we mean by close to will come to that in just a minute and and what and where should we start?
1:32:11
So if I come back to the diagram and what should I choose to my initial value of a zero zero, for example?
1:32:18
Well, the other thing to bear in mind is that I don't really want to choose and I zero down if I'm interested in the positive square root of X,
1:32:27
I don't want to choose. And I zero in that region because I'm going to converge on minus root X.
1:32:33
I really want to choose something which is bigger than zero if I choose exactly zero, by the way,
1:32:39
the slope of the curve there is zero and I make no progress at all that will just loop indefinitely.
1:32:43
So anything bigger than zero will do. It'll converge. So I got to pick something.
1:32:50
So I think what I said and that's what we think X over to. But I could pick one, you know, we can make this up.
1:32:55
We can find a single. All right, so how do we do it right?
1:33:01
So what's the basic. Remember the magic from what's the magic process?
1:33:08
What's the best case to find the best case then to find the recursive case, which means coming up with some clever recursive relationship?
1:33:13
Well, that's what this thing gives me. This I am. Plus one is there is the magical recursive relationship.
1:33:20
So I just have to encode that hit actual code base, close quote.
1:33:26
And I'm done. All right, so here we go.
1:33:30
This will do it. Now, let me just talk you through it and hopefully somewhere in my example,
1:33:35
she should be inside the script and I'll go unchecked and check this morning.
1:33:41
I hope it's in there somewhere. I don't want to talk it out again. OK, so let's see how this goes.
1:33:46
So this is the bottom. Here's a precondition. Again, I'm going to assume that is greater than or equal to zero.
1:33:55
So we're just dealing with the world of zero and positive values of X. So how do I calculate the square root of X subject to that precondition?
1:34:00
I have to iterate starting with some initial approximation, like zero zero A1, A2, A3, A4,
1:34:09
until we hit the terminate in case the termination case is this one here where we use a relative error.
1:34:16
So if I subtract X from A squared where I use my current approximation, if that is close to that, that should be close to zero.
1:34:23
For me, at least divided by X should be close to zero. And I simply have to specify some epsilon to determine whether or not to terminate.
1:34:31
So you should know, I think from your experiences in the lab last week, you should probably set in the in the here somewhere.
1:34:39
You should never compare floating point numbers for equality.
1:34:44
It's just asking for trouble because of rounding errors and because very often you never quite get down to zero.
1:34:48
So you could end up with a computation.
1:34:53
So the idea is we calculate this relative error, so we subtract a square from X to take the absolute value of that and then divide by X,
1:34:57
and then we can pick an epsilon, some fixed epsilon, which defines how accurate one that relative relative error to be before we terminate.
1:35:06
So maybe something like point zero zero zero zero one.
1:35:11
And it's important I divide by X because I don't know what the magnitude of X is in the first place.
1:35:15
If X is itself a very small number.
1:35:18
But I want to sort of normalise it so that we just think it's kind of in variance to the size of the size of the X.
1:35:20
OK, so here's square root of X. What do we do?
1:35:27
Well, how clearly I can't I can't encode the iteration, we're just using the square root function because there's no mention of any anywhere,
1:35:31
is there are not carrying around an approximation with me. So somehow I've got to carry around an approximation.
1:35:40
So perhaps one way to think about this subject come to the magic whiteboard, we could say something like this,
1:35:48
I could say square root, I forget what I call the square or something like it.
1:35:53
Say, the square root of X is, well,
1:35:58
maybe I'll call it some square root prime function and perhaps I'll give it the X and I'll give it the initial approximation.
1:36:00
What did I say X over to? I'm perhaps looking at the top most level, I can define my square root prime function,
1:36:08
which as you give me any order, can you give me the current approximation and I will do what do I have to do?
1:36:16
I have to do something like ask whether the absolute value.
1:36:22
Of X minus A squared or eight times itself is divided by X because I want to normalise it to give me a relative error.
1:36:26
And if that's less than some fixed epsilon,
1:36:37
perhaps I should call this I should name this in my programme Somewhere Epsilon or something, so I can easily change it.
1:36:39
And if that's true, then I stop because it means my approximation is sufficiently close to the squared about X that I'm happy to, to stop.
1:36:46
And I just give me about the current approximation. Otherwise I have to have another go.
1:36:53
So I'm going to go, otherwise I have to have another go, in which case, what do I have to do?
1:37:00
I have to reinvent the square root function. Yes, quality, prime function, same X.
1:37:07
But now this AI has to change from what it was before to the newe, which I get from.
1:37:14
This precarious relationship, so I want you in here a plus excited, I want to I guess this should be a plus X over a.
1:37:23
Brackett's. Divided by two, something like that, which is what I've got in the function on the screen now,
1:37:36
the only difference between what you see on the slide there and what you see on the magic whiteboard is that here I have to find this.
1:37:44
We call them helper functions, functions which help to define another function.
1:37:50
I've defined this function of the topmost level.
1:37:56
Other than that, I don't think I made any typos, maybe I have, but otherwise these two functions and this is solving the same problem.
1:38:00
By the way, when I talk about helper functions, so my security, my square root,
1:38:08
prime function is helping me to define the square root function, do not call your helper functions.
1:38:13
H e l p e oh, I'm not going to change the colour of the red pangas.
1:38:19
If you do that, someone's going to put a big cross through that and going to minus probably 5000 marks for choosing a bad name.
1:38:24
All right. So I tried to give you a helper functions, meaningful names.
1:38:31
And this is really you can say this is one very nice use of this little priming thing in here,
1:38:34
and it enables me to construct the name of a helper function from the name of the original function.
1:38:39
All right, Richard, you have a question. So why exactly are we doing X by two here?
1:38:46
I didn't quite get it. Oh, I just had to choose.
1:38:54
How would you if I say I'm trying to calculate the square root of X for an arbitrary non-negative X, how would you start?
1:38:58
What would you what would you choose for Azera? We have to pick something.
1:39:04
If you didn't like it, which is about the last one, I'm a bit confused about what exactly is as well.
1:39:11
He is the current approximation. You see what I'm going to start with?
1:39:20
So let me get let me come to the white board. I show you what we're trying to do.
1:39:25
We're going to start with some e0 here, and then we're going to somehow construct a one another construct constructed a two.
1:39:28
And this will go on until I get to some A and or some AK or something where this is sufficiently close to the square root of N that I can stop.
1:39:35
It's an iterative algorithm which hopefully will converge on something very close to the square root of this growth of X.
1:39:44
Yeah, so the question is, how do I know what to wear, how how should I pick my Azera?
1:39:53
And it's an arbitrary decision. I said, you can start with one. You could start with two.
1:40:00
You could start with one hundred and seventeen if you wanted to.
1:40:06
So I just picked this over to perhaps I picked up a tip because I'm trying to speed it up a bit, maybe cut down a few iterations.
1:40:11
It turns out this convergence really quickly. So it's arbitrary then?
1:40:17
Is the scope of a helper function limited to the actual parent function, or can you call it from outside?
1:40:25
Right, okay. So the scope I come to in just a minute, Ben, Adaiah.
1:40:31
I pretty much have the same question saying let's just go back to the whiteboard and because you're looking
1:40:37
at a version of the function where I put both the function and the helper function at the top most level,
1:40:43
so there is scope everywhere and then you tell what you do. This is nothing wrong with this.
1:40:49
But you look at this and you think, well, this helper function is only being used to help me to define the square, which I don't need anywhere else.
1:40:53
So so why would I expose it at the topmost level? And the answer is you probably shouldn't.
1:41:01
What you should do is nest that function to make it a local function.
1:41:06
So if I do that and I'm not going to get the layout right, because I obviously laid it out for the topmost level.
1:41:11
But if I put Awaran here. So I kind of pushed this lot inwards to nest it, so it looks like a nested definition.
1:41:17
Imagine that's three spaces to the right or whatever, whatever it needs to be.
1:41:29
Yeah, so now security prime is in scope only within within their security, but that's the first thing to say.
1:41:33
So I can't say if I go back to the command line. Jason, come on.
1:41:42
I'm going to ask you I can ask you what I can't see Square prior to the second observation is the following.
1:41:44
What is the scope of that X? The scope of that X in that case would be all of this.
1:41:53
Oh, would be oh, certainty would be all of this.
1:42:00
We know from that, we know that from our discussion of scoping rules the other day, that's the scope of it.
1:42:08
So then you think, well, why do I bother to pass the Exane into here so that I can use it here and here if it's already in scope.
1:42:16
And the answer is you wouldn't in this case if you missed the function, you can now.
1:42:27
You can now get rid of that. Get rid of that, because I'm not changing the volume, but I can get rid of that.
1:42:33
And now when I refer to the X in here excuse me, when I refer to the X and here it does in me, it does indeed mean.
1:42:42
This here, which is the one on one, so the X never changes, it's only the if you like, the changes that go from one generation to the next.
1:42:50
And Richard, is that an old Hendron, you were an engineer and you've got your hand up as well.
1:42:59
So I I want to know how fast it can work.
1:43:07
And yes, well, perhaps we can try it out in just a moment. So as I first heard that log on its mailing list.
1:43:10
Ah, well, that's a very good question. The trouble with iterative calculations, it's not it's never easy to say how many steps they take.
1:43:18
You know, I can't say this is of the order of the square root of X or the logarithm attacks or something.
1:43:24
It does. It depends on the function. And it depends how good my initial populations have close, it is to the to the.
1:43:29
OK, thank you. I don't know the answer then.
1:43:37
I'm going to put you while you're chatting, I'm going to put the toll you up on the screen so that we can lovingly stare,
1:43:46
that should be pretty much the version I've got on my much of what carry.
1:43:51
You can't quite. Hamza, could you please explain the difference between the function you defined in the magic whiteboard and the one on the slide?
1:44:01
There is no difference now because I have nested it. See why this little thing,
1:44:15
if you imagine I nest the square root prime function inside in a in a where clause so that it's local to the outer square root function.
1:44:21
It's exactly the same, I hope is the one you can see on the slide. I guess one difference is that on the slide here,
1:44:30
I especially put the type signature in for the helper function, whereas on the magic whiteboard aham.
1:44:35
Thank you. You're welcome. Sorry, so I can't see the whiteboard, whatever it is, sort of disappeared and I charged you joining and stuffing it.
1:44:43
I can't get it back. And you see the now. Now I just feel like I can.
1:44:52
I just see your name. And I think this is sounds like anybody else got this problem.
1:45:00
This sounds like it might be to do with, you know, teams is probably.
1:45:07
Doing what it did to me the other day, I'm sorry about that, it should be on the record.
1:45:13
And you think that recording of myself. So when so how can we print this out in the console?
1:45:17
So how would you print it out in the console so we can make checkout line by line that's doing what he wants it to do?
1:45:29
Well, actually, as it stands, you can't.
1:45:34
But it turns out a bit later on, I've got to see if I've got that function in the script and I can show you a converging.
1:45:37
OK, I. The approximation formula, the new formula and the reasoning that if you can I'm sorry, sorry,
1:45:44
could you just go back to the neutral approximation formula, how it was like approach.
1:45:54
I was well. Could you just explain again how you got this result like you were showing us a graph?
1:46:01
Oh, because the the method for calculating the functions and the function, I chose to calculate the zero I have lost.
1:46:09
The diagram now is just what is just Y squared minus X.
1:46:18
What's Goldman Sachs is zero when why is the square root of X?
1:46:23
I think probably the best thing to do, because I have too much of the time and everybody else, it should be on the recordings.
1:46:30
If you go back to recording again, you'll see me drawing the graph. Thank you.
1:46:35
You're welcome. And I think you have an old handless and you question.
1:46:39
I think it's an old hand, so right, so there we are.
1:46:48
I think what I'm going to do is.
1:46:57
Oh, well, certainly what I was going to say, if we can run this programme, wasn't I, let's see if we've got the square root.
1:47:01
See, we've got the square root function. We are so this is the square root function.
1:47:12
Let's just check that it works. So let me go to GHC and say, what is a square root of 60?
1:47:20
Well, that's pretty good, isn't it?
1:47:33
And obviously that will be one of the squares, one of our favourite numbers, that's obviously three three five nine five one six, as you will know.
1:47:36
So you can test this to your heart's content.
1:47:44
Well, as an example, it's got it's got it's within Epsilon, it's not a hundred percent accurate, I could change the epsilon, become more accurate.
1:47:54
So it's only an approximation depending on my value epsilon that I've chosen.
1:48:02
But it seems to be doing the right thing. But you did ask me about convergence.
1:48:07
You just see. I think I might have another one.
1:48:12
Mm. Yeah, OK, so what I can do here is just bear with me, because I know you're you're absolutely busting a gut to know how this Convergys.
1:48:22
This is this is a function we'll be looking at later on in the course, it just so happens that what it does.
1:48:46
Oops, it should now give me Oopsy Daisy what's happened there.
1:48:51
What about, um. Um, let me just have a think about this, um.
1:49:00
And I'm going have to hack this a little bit, and you shouldn't be doing it this way.
1:49:25
I'm just trying to see if I can show you a converging. Uh.
1:49:31
Boy, is that doing that. No.
1:49:48
I'm just trying to. This is actually going to give me what I want or not.
1:49:58
OK, so the design on that is bad is the other way around.
1:50:10
Yeah, I know. I don't want I don't know for a fact of the whole thing, but it's getting there.
1:50:18
Right. So to do this properly another time, I think in the US, I've got a funny feeling in the slide somewhere,
1:50:23
it might be the case that I have to wonder, will this before we come back and just further down the slides.
1:50:29
Pretty sure somewhere we've got a scenario doing this last year at.
1:50:37
Well. No. Then I'll tell you what,
1:50:52
I'll prepare something offline and I'll will start the next lecture by showing you how a conversion idea is quite interesting to see in action,
1:50:58
but I'm going to have to pick my way through the examples. OK, I'm going to stop and I'll stop now because you've got to go to another session.
1:51:04
These old hands, Hamza and Genyen, or they put questions.
1:51:12
How are they put down? I don't know when it happened.
1:51:18
I think it's time to let you go. So what you did was work your way through the unassessed, exercise your sheets in your spare time.
1:51:23
And obviously this week you've got a lab where you have to start thinking about writing recursive functions on numerical type.
1:51:29
One thing I would tell you is that I think writing recursive functions on the American side is actually really hard.
1:51:37
And the really the good news is that tomorrow I'll show you how to start writing functions over lists and it and
1:51:43
what you'll find is it's much easier writing recursive functions over less than is watching over numeric types,
1:51:52
because there's really only one way to proceed. So I'm going to let you go.
1:52:00
Thanks. CHEERING Thank you, thank you.
1:52:04
Thanks.
1:52:15