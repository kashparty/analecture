ID: 70983190-7eda-4ddd-8cb7-ae2000d6a185
Title: Q&A1
Category: COMP40017 - Linear Algebra (Spring 2021-2022)
Lecturer: Chiraag Lala
Date: 17/01/2022
I've started recording sorry about that. So, yeah.
0:04
This this procedure of reducing a dimension,
0:09
so reducing the dimension down to of collection off points down to a plane or any sub space where it is much more easier to
0:15
understand the the information that is done using principal component analysis and that uses eigenvectors and eigenvalues,
0:27
which you will learn in this module. So I now change to the white board.
0:35
So. All right.
0:46
Whiteboard is there. OK. OK, which camera should I move to?
0:59
It again, can you help me out at once again, please?
1:12
Come on, Zoom, they can't see that white photo with it.
1:18
Maybe a few photos to the West.
1:26
I think it's going to be like which I kind of on this one.
1:31
I don't know. Jurisprudence is there then how do I move that camera?
1:39
Have you until now?
1:56
I don't. I mean, I guess I was supposed to learn all this.
2:01
I'm trying to figure it out like this.
2:11
She's. There's just one camera there should be one of.
2:18
OK, so something to look out. So although I did find some pockets, I don't know about the number one.
2:33
OK. All right.
2:52
I am learning planning with the lights.
3:03
OK? All right. So but again, the whiteboard is still very small.
3:07
Maybe this option we were all learning on on the other perfect.
3:13
All right. So. Now they won't be able to you still have to say this is does acting like a microphone?
3:28
All right. So. OK, maybe we were going to project down the three dimensional Galaxy Z Fold two dimensional.
3:43
So first of all, let's broaden our dimensions.
3:55
So this is not this would be my x axis.
4:00
This is my y axis. And this is the Z-axis.
4:04
I'm taking the origin to be the centre of the galaxy by saying that,
4:14
I mean the me of all the points in the Galaxy, so the Galaxy looks something like this.
4:18
Imagine it still did somehow, no. It's but it's in this dimension of space.
4:30
And each star is.
4:39
What we call the location of each star with respect to the centre of the galaxy would be what would be
4:44
some victor and I'm representing that with this particular star is being represented as a Victor B one.
4:50
This particular star is being represented as a that we do and so on.
4:58
We have billions and billions of dollars. OK.
5:02
Each week is the coordinates of the location of that star and this three-dimensional space.
5:08
So it takes coordinates y coordinates for them. So I am calling that the One X.
5:15
We do x y z three x.
5:20
Once you know all the points. The next step is to compute what is called the gold radiance matrix.
5:31
Yes. What to avoid?
5:40
Yes. So we won. We won. We are the same point because we why it?
5:46
Categories are. So. Now there is something called the coherence matrix.
5:54
I just use the term, and that's where you measure.
6:05
It's going in between different axes, so I jumped this spot.
6:12
You learnt this at some stage in the module, but this matrix would comprise of the obedience along X.
6:20
The covariance between X and Y of four, these points going in between X and Z.
6:33
Similarly to events between X and Y.
6:47
Obedience in this market is not good enough.
6:59
Comedians between X and Z. All right.
7:07
And basically, you feel this. What is called this covariance matrix and you do the computation later on and then.
7:12
You're from this from this matrix, you compute what I call eigenvectors.
7:24
Right. There'll be three eigenvectors e one e 23, and they'll have corresponding eigenvalues land on land, back to land at three.
7:33
I'll add an arrow just to indicate that these are vectors. All right.
7:44
We'll ascend, we'll arrange these in the order of the magnitude of the eigenvalues.
7:52
I assume this is the order. This is the eigenvalue to the maximum magnitude max and the second and the third that E1 would be.
8:01
This plane along which there's maximum medium is maximum information.
8:13
BP directors are the. The one dimensional sub base of this space, which has the maximum information,
8:22
and it will correspond to that direction, which which has the second most important mission.
8:33
The axis along which you have the second most information.
8:40
And we treat this one third eigenvalue.
8:45
Would be the one which just look back in killer to the galaxy, the plane along with you.
8:50
Yeah. So are we completing the story based on one star's position on all stars position?
8:58
So that could be the formula for saying X and Y looks like.
9:07
We I X. B, I Y.
9:16
I ranging from one to all the all stars in the galaxy, divided by the number of stars in the class.
9:22
Sorry, yeah, surfing crush. We can't see the boards.
9:32
The the writing is quite quite. Yeah, on recover, yeah, I can see that.
9:37
I don't know if I can zoom in further. Let me try you perhaps to change your head.
9:47
So I'll get gets clear. It can use a darker marker.
9:56
There is. It's.
10:01
And working in the sector because the structure is different,
10:43
because the people they think are so why is this more like this is about this big, complicated secret?
10:47
Let's talk about it just to talk about the subject.
11:07
So even though the culture is so popular now, as it seems, they exactly the same way all images.
11:23
Thank you, guys. All right. It was always a very, very old experience.
11:34
So we don't have sensitivities because this was one of the first stories that first created.
11:38
The whole idea was that people realise this is very first patients.
11:46
So we thought, what else can we use it for? And then we just came up as like the next big thing.
11:55
So this was going to say it is actually the first application of that, which was interesting.
12:00
And it was a it was a combination of surgical strikes and ideas where it created a set of post-its on stage into language.
12:07
So was almost like code language.
12:18
And I think another goal for it was a little box of six bar rules and two women divorced.
12:24
This was considered a very interesting concept, applying for multiple sources with a very small amount of tolerance, and it was a lot of the time.
12:33
But some people realise that this makes it very good for its, just as it would be very harmful to people's expectations for next year's elections.
12:58
And of course, because there's no sense in which it's something that's the same something else.
13:26
And that. This went on for for idea.
13:45
But I look at it this.
13:55
I feel like I had to struggle on the part of the state in which can between simple things.
14:11
So are you teaching a little? Mr.
14:29
The blame. So another system which is lots of lots of people.
14:59
It's more just.
15:25
Typekit. So this is the sort of games they're so cynical.
15:33
You. So perhaps not licence.
16:28
Is that? I guess.
16:38
Hello. Can you can you hear me? Yeah, I can hear you.
16:53
Yeah, it's yeah, it's not that important what I'm writing on board right now.
16:59
You learn all these things at some stage,
17:04
but basically these eigenvectors kind of represent the the first two eigenvectors with maximum eigenvalues represent that play,
17:08
along with down a plane on which you should project the galaxy so that you don't lose out the information like this final structure,
17:20
you only miss out on the weight of the galaxy. So that's the idea behind eigenvectors and eigenvalues.
17:33
That's how you respond to that. Reduce the timing of all of the data.
17:40
OK. Is it possible that you only get to eigenvectors?
17:46
No, you get three. You will get one.
17:54
He will learn that. OK. All right, so.
18:00
It's all back to the. Sites. That.
18:11
All right, so. So dimension reduction using BCA helps you reduce the dimension of your data, especially,
18:42
this is particularly useful if if you have a high dimensional data like it, it is very high dimensional space.
18:57
So I'll give you an example in my own work in natural language process.
19:07
We embed words in a very high dimensional vector space.
19:15
We call that vector space semantic space, right?
19:20
Because these words, the position of these words in this high dimensional space represents the meaning or the usage of that word.
19:23
So words which mean the same are synonyms or, you know, have the same usage in day to day language.
19:31
I'll often gloss over closer in this semantic space than the others.
19:40
All right. But again, this is a very high dimensional space generally.
19:47
The one that I have been using is was a three dimensional, three dimensional vector space.
19:53
So how do I visualise that? I was using the same techniques of BCA,
20:01
which involve eigenvectors and eigenvalues to bring it down to a two dimensional plane so that I can visualise what these word embeddings were.
20:05
How are they positioned in this vector space?
20:16
So that leads down in the slide are some x are some of the wooden and buildings that are popularly used in natural language processing.
20:19
The work, the way in global markets. So when you.
20:30
Reduce the dimension to two that you when you projected down to two dimensional space using BCA, it looks something like this.
20:35
Now again, the the words are not visible, but if you look closely and you will see all the cities and countries are clustered together.
20:44
All the other, the time the numbers are clustered together.
20:54
There has been some loss of information because, again, you are reducing down,
21:01
reducing the word embeddings from a three three dimensional space down to two dimensions.
21:05
So there is some loss of information, but that is minimal. You are preserving as much information as possible along the two.
21:11
Along that plane, which has the highest eigenvectors, the the eigenvectors with the highest eigenvalues.
21:20
So. Yeah, this is one application and you.
21:27
You can you can find such applications and many other tasks in machine learning and natural language processing.
21:33
There are more applications of linear algebra, especially though the use of matrices.
21:43
So in computer graphics, you've been using Snapchat and Instagram filters like.
21:52
How do those filters work? So suppose.
22:03
So so you can think of these matrices that we will learn as a way of transforming a vector, as a way of moving points.
22:08
You know, in our vector space so.
22:18
So if you have a foot, if you are taking a selfie of your scent. The image each pixel has a location.
22:23
Right in each point in the image has a particular location.
22:34
Now you can use matrices to move those points.
22:39
Some other fix it that way you are changing the way you can make yourself or make your face look slimmer if you use a particular kind of a matrix.
22:44
You can. You can sure you can bend.
22:56
You can rotate the entire image if you use another kind of a matrix and use that
23:01
matrix to operate on the entire image on each and every pixel of the image.
23:06
So that's the basis behind behind many such applications in computer graphics.
23:11
In cryptography, you can think of your input message as a vector.
23:18
That needs to be included. That is some, Victor. And then this matrix.
23:24
You can and then the Matrix can then move that input vector to some other location.
23:32
In other words? If again, I would have used the whiteboard, but never mind that has been creating a lot of problems.
23:39
So basically think of your input message that needs to be encoded as a vector.
23:51
Then there is a matrix which will encode that vector into some, remove that vector to some other location.
23:58
And then the inverse of that matrix will the decoder side would move it back to its original location.
24:05
So this movement of that vector from one point to another is encoding that input message,
24:13
which makes it unreadable for anyone who does not know the inverse matrix.
24:20
So these this matrix is like the inverse matrix is like a key.
24:27
So again, there are applications in cryptography. Then Matrix has applications in.
24:31
I put I use matrices in one in one project that I was pursuing 10 years ago, which was to predict the flow of a football match.
24:41
So enough in a sport in the football, there are two teams for those who don't know, I'm pretty sure everyone knows how the how the rules of the game.
24:56
But there are two teams and they try to score a goal.
25:06
Now. So what I what I did was to predict the flow of the match like.
25:11
Where will the ball move around, like from which player to which player will the ball be passed on to over a period of time?
25:19
And I did that using matrices where that deep made the information being stored in
25:29
that matrix was the probability of a ball being passed from one person to another.
25:38
And then if you take that matrix, I'll explain this in more detail later.
25:44
So when you take that matrix and keep multiplying it to itself, take a power of that matrix.
25:50
What you will see is the flow of the game being simulated by by the.
25:57
So if player one passes the ball to player to play, two passes the ball to player three.
26:06
All that information is getting stored in the matrix out of the matrix, assimilating that flow of passing of the ball from one player to another.
26:11
Right. So I get to that in the in the in the model at some stage.
26:22
Right. So again, are many applications.
26:31
And yeah, it was also I was also told to talk a little bit about the history of linear algebra, but I'm not going to bore you with that.
26:38
The only thing which is quite interesting is to know that.
26:48
What do you think the study now was discovered or invented depending on how you see, depending on the perspective it was invented after calculus,
26:53
which is surprising because calculus is so much more than what it requires you to define, limit, define so many things and in linear algebra.
27:05
And then you study, you realise that it is so much more intuitive and so much more easy to follow.
27:17
Once you understand what what we are doing, what the.
27:24
What the what? Once you basically start to understand what things like matrix multiplication does, what in words does what determinants do.
27:30
And if you can visualise what eigenvectors are doing, linear algebra seems to be far more easier than calculus.
27:42
And yet it was discovered quite later, which is kind of surprising.
27:50
Yeah, that's it for today. I had not planned anything else. Any questions?
27:58
All right. Well, that's let me try once again.
28:09
Do. Help you understand how how to use matrices in computer graphics.
28:15
It's like, let's let's try.
28:27
Once second. OK.
28:32
Instead of. OK.
29:06
All right. So. Think of this as your original.
29:30
Image. So perhaps you have taken a selfie, but this is your face.
29:39
All right. So this is the original image and how they make sure the pictures that are picked
29:48
says that different locations and they had the right blue green brightness.
29:54
And that's how you get the point of.
30:03
Now, if I want to make this image, if I want to make your face look fat, the one thing that I could do is use this matrix, which is say.
30:09
Two zero zero one.
30:26
And applied to each and every pixel, it is a vector.
30:31
Basically, it has two coordinates, so a pixel away unit would have the X coordinate and the white coordinates, right?
30:36
So this X and Y. Is the victor, and when you apply this matrix on this victor, it will move it.
30:46
Two weeks. Well, I.
31:02
So this particular pixel a way you're. But moved by two times to the right, the location was not it should two times to the right.
31:09
Similarly, there might be a plane somewhere to the left of the y axis and those picks, it would be multiple times to the left.
31:23
What do you make? Do you get eventually?
31:33
One with the fact of is now this was the simplest example I can imagine what each what different kinds of matrices would do to the image.
31:37
I suppose I want to rotate the image, say, 90 degrees to the left or right, something like this.
31:52
I could use a matrix, which looks like. Zero one.
32:01
Speak. I could use a matrix, which looks like zero one.
32:10
I. But there's no there's there's a picture of how to find such Mukasey's, which I explain later, or maybe you can't do that chapter on basis.
32:22
You know how to create these matrices? OK. So zero comma, one minus one, guys.
32:41
And I use this matrix. What happens is the X.
32:48
It gets when you do this matrix vector multiplication, the point gets moved to.
32:55
Is that correct, sir? There was no matrix multiplication.
33:16
Right? So what is happening here is an ex-wife point was moved to minus like on her x, which means you can visualise this image.
33:21
God stated, I got rotated by 90 degrees like this.
33:38
All right. Similarly, different kinds of matrices will result in different kind of transformation of the audition elements.
33:48
That's how the interests are used in companies that.
33:56
Yeah, coming to the football example.
34:04
We'll think of a very simple, very ugly example, let's say that only two teams of two players each, so are.
34:14
Let's see Lionel Messi, which is represented by name Christiana Rinaldo, Melissa La, and will let any other players like, yeah, it does.
34:25
OK. OK. All right now, I didn't this matrix.
34:40
With the problem with the probability of messy, OK, let's build a diagonally diagonally piece later,
34:51
so or you're the second in your yard is the probability of messy losing the boy to the dryer or boxing the boy, if that at the same.
35:01
Yes. Is the probability of mercy losing the ball to Salah b m and is the probability of mercy losing the boy to Levandowski?
35:12
Right? And similarly, you fear the entire matrix.
35:28
All right. Once you have this exact goal, this matrix.
35:33
So Amy picks represents what is going to happen next.
35:40
As it I think statistically the probability of what's going to happen next.
35:44
If I were to simply take the power to the ball at a.
35:50
It will tell you the probability distribution across the board and bosses.
35:56
Of course, there is a lot of assumptions in the back like this is the example of this is the auto matrix.
36:01
You can simulate the game. By just picking, by just microplane, the Mate X2 itself again and again and again and again.
36:14
Yeah. This is all this was my project. Goes so yeah, there's so many, so many applications of millions of people who are going to too much,
36:27
you know, in future, you would see algebra everywhere.
36:41
In physics, those who are close to me who wish to pursue your sciences against ecological crops, up pops also everywhere.
36:49
So yeah, it has it has widespread application, which is why is it so?
36:59
Yeah, that's it. That's all I had to share today, and I see you on Wednesday, hopefully with less technical glitches.
37:06
All right. Thank you. See you next time.
37:17
Thanks. Thank you.
37:21
I have to say it's.
37:40