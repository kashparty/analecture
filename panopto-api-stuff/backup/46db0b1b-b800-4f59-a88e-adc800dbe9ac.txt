ID: 46db0b1b-b800-4f59-a88e-adc800dbe9ac
Title: QRT ACI Talk October 2021
Category: Applications of Computing in Industry (ACI) Talks
Lecturer: Tom Curtin
Date: 21/10/2021
Tom. So, OK, welcome, everybody, to today's applications of computing, an industry seminar.
0:01
We are extremely delighted to have Steve Edwards from Cubed Research and Technologies.
0:11
He's going to tell us all about a very exciting subject.
0:19
Electronic trading and low latency networking is basically a full on arms war going on out there all the time.
0:22
And we're about to get a good insight into exactly what's going on.
0:30
I think so, yes. Steve, please take it away. Thanks, thanks very much.
0:34
So, yes, I'm here today to talk about electronic trading, low latency networking and low latency infrastructure.
0:40
I work for a company called T.
0:49
We're a research and technology based firm that manage a number of funds on behalf of our investors.
0:55
We have offices in Asia Pacific, Hong Kong, Singapore, Mumbai, some European offices in London and Paris.
1:05
We're a growing company over the last couple of years.
1:17
Despite the pandemic, I think we've almost doubled in size. So, yes, very much an exciting place to be a bit about me.
1:20
So I have been in the tech industry for around 19 years, 10 of which have been in the financial services technology and electronic trading space.
1:30
I've been a cube for three years. Prior to that, I was at JP Morgan, which, as you may know, is is a big American investment bank.
1:42
I tend to specialise in low latency structure and instrumentation, but I've been very lucky,
1:54
I think, with my career that I've never been pigeonholed into a particular role.
2:01
So I like to to know how how things work and the full holistic technology space that we operate in.
2:08
And I've been very lucky in my career to have roles that support that.
2:16
Yeah, I think my advice would be definitely find something you're interested in,
2:23
if you can in your career and if it makes a difference to the organisation that you're employed by then, then that's a match made in heaven.
2:28
So a little bit about low latency trading transition from the you may see on on kind of all the films,
2:39
the lots of traders on the floor looking at ticker tapes and screens and shouting at each other to buy and sell orders to turn in.
2:47
Transition to electronic trading started around in the mid 90s and then accelerated into into this century algorithmic trading
2:56
as a form of electronic trading where we're using a predefined model algorithm to place trading instructions for the exchange.
3:11
So all the trading decisions are defined in advance and the strategy is to
3:19
find a balance and we're using a complete electronic path to complete a trade.
3:24
High frequency trading is a form of algorithmic trading where we're inserting inserting trades into an exchange at a very high frequency.
3:32
And this could be thousands, hundreds of thousands of dollars per hour.
3:44
Lots of trades in a fraction of a second.
3:49
All that happens at a very high speed and low latency, the definition of low latency has probably changed over time.
3:54
In the early part of this century, low latency was probably measured in seconds,
4:03
whereas in 2021, we're definitely into some microseconds and nanoseconds.
4:08
It's a little bit about the algo trading and trade lifecycle.
4:19
We have a market data on the exchange side on the slide here,
4:25
the green boxes would be on the exchange and the the orange lines and all the trade aside,
4:31
we have an exchange that publishes market data containing information about the state of the market,
4:38
whether there are the orders, the order types that are available on the market for buying and selling shares.
4:47
That is typically published to either multicast connexion to a market data feed and from a trade aside,
4:58
and that would take the raw binary format for market data and transform that into a normalised for me every day.
5:06
So depending on the market, this is this can be a fair amount of data and the market data will take his orders and prices
5:19
and various quotes and bed and office for various stocks appear and disappear on the market.
5:29
Now, Algo is basically listening to that normalised market data from our feed handler.
5:36
And based on a trading strategy that was predefined, it decides when to execute a trade.
5:42
So it may be that, for example, the conditions are right to buy, say,
5:49
100 shares in BP at a specific price based on the market data signals coming into the algo.
5:56
And at that point, it would send a message to our order management system,
6:02
which performs some basic risk checks to make sure that we're not buying shares at a price that are outside our agreed trading volume converts that
6:07
trade into or that information into a binary format that's suitable for the
6:18
exchange and sends the order to what's called the exchange matching engine.
6:22
The exchange matching engine will try to match our order of, say, buy 100 shares with another order that's available on the exchange.
6:28
Somebody's trying to sell 100 bija BP shares at a specific price.
6:36
There are different types of orders that can be sent to the exchange, typically with low latency trading.
6:43
We're trying to execute one of our orders immediately so the matching engine will acknowledge our order.
6:50
And if there is a corresponding order to match with on the exchange, it would we would execute our order and we would trade.
6:58
If there is no corresponding order and nobody has a say,
7:09
100 BP shares in my example to sell at that particular price we were trying to buy for, then our orders cancelled.
7:15
That's that's essentially the typical life, a trade life cycle.
7:24
Touch on the latency arms race that I mentioned was mentioned at the start of the presentation,
7:34
speed really is the essence when we're trying to get our orders onto the exchange as fast as possible in order to to beat our competition.
7:43
Historically, market participants have invested huge sums of money in trying to get a latency edge on other traders.
7:54
Let me just go when I said ologies. For example.
8:06
Companies and traders will often try to pay huge sums of money to get close to the exchange, so even my slide deck here,
8:14
Trader C would pay for colocation space to be close to the exchange and potentially trade around and try to be at that
8:23
point because of the short cable run traders see has a potential advantage over Trader A and B over the last 20 years,
8:34
there's been a an evolution in network speeds.
8:45
So faster network speeds result in a lower serialisation delay of getting data onto the market.
8:50
One gig would take around one point two microseconds to transmit one hundred and fifty bytes packet to to the exchange,
8:59
whereas a 10 gig is around one hundred and twenty nanoseconds. So the evolution from 100 meg to one gig to to 10 gig networks has played its part.
9:09
Looking at alternative network technologies such as microwave has also played its part.
9:21
Microwave tends to be around 50 percent faster than the speed of light and fibre with some expense.
9:31
Reliability with microwave is very badly affected by weather conditions such as sunshine on
9:39
the microwave dishes or heavy rain storms and tropical storms that you would get in the US.
9:48
To give an example of the kind of speeds that we're seeing to get from a message
9:54
from New York to Chicago over fibre would take around seven point six milliseconds,
10:00
whereas over microwave it would be around four point four milliseconds on some of the fastest microwave routes.
10:05
Typically what people would do, given the unreliability that microwave is send the same message over fibre and microwave at the same time.
10:12
And if the microwave message arrives faster than great,
10:22
if the microwave message is dropped for any particular reason, then we have the fibre messages as backup.
10:25
And that three milliseconds really makes all the difference.
10:34
Absolutely, absolutely. Huge, huge difference.
10:38
If where is an example, if we're looking at an exchange in New York and we're trying to see if there's
10:43
some kind of market event in New York that drastically affects stock prices,
10:54
you would want to take a position or buy or shift your financial position in Chicago.
10:59
The race would be to get that market information in New York as soon as possible in Chicago.
11:07
So if everyone's trying to do the same thing effectively and offload a bunch
11:13
of shares in Chicago based on some big news that's just happened in New York,
11:18
then you'd want that message to arrive as fast as possible.
11:22
And if you can get it three odd milliseconds faster than the competition, then you should be you should be in a good spot.
11:25
These days, it's a little bit less like the wild, wild West,
11:39
a whole bunch of market regulation has been brought in in order to be really competitive in the low latency space,
11:44
you need to be co-located inside the same data centre as the exchange equipment, the market data publisher and the the matching engine.
11:53
There's no real kind of cloud based or trader desktop based in your office for running low latency.
12:05
It's all very much. You have your trading stack inside the exchange.
12:12
Most exchanges now will regulate their cable length for fairness.
12:19
So when you install your your snack inside the exchange and you order a cross,
12:23
connect the fibre connexion from your equipment to the exchanges network, that cable and is the same for absolutely everybody inside the exchange.
12:30
And you'll find coils and coils of fibre running around the exchange if you're closer than and further away.
12:40
There are people that do try to still game the system by reaching up inside the roof.
12:48
And if there's a big coil of fibre, they're trying to cut it and splice it.
12:55
But if you if you're caught doing that, you'll be severely penalised financially up to and including booted off the exchange.
12:57
So whilst there's there's still some cheating that goes on,
13:05
most of the exchange connectivity is now regulated and the real competition is down to you inside your own trade.
13:10
A like. So just to go down a bit into a typical low latency trading infrastructure on the exchange side, as mentioned,
13:18
will have a market based publisher which is publishing the state of the market Pashtoon exchange network and the exchange matching engine,
13:37
which is listening for orders from from participants and trying to match those orders together for trades on the trader on our side,
13:46
we would typically have a number of network switches depending on the size of the KOLO.
13:56
In the diagram here I've got three. There's an exchange switch which handles our connectivity to the exchange and aggregation switch to PATCHIN,
14:02
one or more service switches and then our service itself that run feed handler or algo engine or a model.
14:16
That is our strategy for trading on our order management gateway.
14:24
Typically in production these switches and set up through always duplicated for Resilience 10 gig at the moment,
14:30
I would say is that the de facto speed 25 gigs and 40 gigabits per second probably coming down
14:37
down the line saying 10 gig is mostly for the serialisation and the speed on big market events.
14:46
Typically when markets open and close for big events such as that as an event called Non-Farm Payroll in the States,
14:55
which is the announcement of the number of new jobs created. And that's used to give an indication of the state of the US economy.
15:03
So if you're trading affects, for example, based on whether that announcement is very different from expectations,
15:12
you could end up with a whole host of market data updates as the exchange moves rapidly as the announcement wasn't in line with expectations.
15:21
And you may need to be able to absorb four gigabits per second, five gigabits per second and burst traffic coming down from the exchange.
15:32
Instrumentation, how are we doing? I think it's always critical to measure the performance and test the performance
15:48
of your application of your infrastructure as and when you make changes,
15:59
just to make sure that there's no ill effects or adverse effect.
16:03
And also when you're making improvements,
16:08
just to make sure that the improvements we've made have had that desired effect and we haven't broken anything.
16:10
With instrumentation in the kind of low latency space which operates again,
16:18
we can't afford to add additional latency overhead as part of that measurements,
16:24
that we need to find a way to be able to very accurately measure the stuff without any adding any additional overhead clock.
16:29
Synchronisation is another challenge. Market data messages, as they come down from the exchange,
16:37
contain a accurate timestamp of when that market data published and in order to for all algo and strategies to make
16:44
sense of how old that market data message is and how fast or when we potentially need to react to issue a trade.
16:54
We need to clock on our on our stack needs to be an accurate synchronisation,
17:03
the exchange clock so that we can judge how long that message took to arrive on ask.
17:10
Its resolution needs to be as good as the performance of our stack these days.
17:17
We're down to nanoseconds and even picoseconds.
17:24
And we also need, on our measurements, stack sufficient performance to be able to cope with those high volume burst events that I mentioned,
17:28
such as big financial news events, or when we have market open a marketplace on a daily basis.
17:37
Clock synchronisation, there's a good law from Sago's law that I always like to quote,
17:49
which is a person with a watch knows what the time is and a person with two watches is never sure.
17:55
It's very hard to get two clocks and exact synchronisation with each other.
18:01
The way this is typically done today is using GPS and advanced time distribution technologies like GPS.
18:07
P2P is delivered over a network. It time for precision time protocol and it's a way of using hardware time,
18:16
stamping an immense network cards on the servers, having server switches, networks, which is the time away.
18:26
And typically with petechiae we can expect synchronisation of well under a microsecond.
18:37
And in the best environments, I would expect to see a time synchronisation of around 50 nanoseconds to UTC with GPS,
18:44
which is which can deliver better performance. The PDP as a coaxial cable, which is driven from an oscillator directly inside the Grand Master,
18:54
which in turn is disciplined by the GPS signal from a satellite,
19:04
and that can bring as well under 50 nanoseconds in tens of nanoseconds synchronisation.
19:08
That's our side. And I we we constantly drive to have good synchronisation on our side.
19:16
Exchange clocks do varying quality, and if your clock is good enough,
19:22
you can certainly see when there's a problem with the exchanges clock and it starts to suddenly drift away from UTC.
19:27
You can very clearly see that with your instrumentation, there are regulatory implications of having good clocks and the European regulations,
19:35
those committed to mandates that anybody who participates in high frequency trading
19:46
or low latency trading must have clocks back down to within 100 microseconds of UTC.
19:52
And you must be able to prove that your system clocks and your algo engine is stateswomen 100 microseconds of UTC at every point.
20:01
That's relatively straightforward to do.
20:12
And I wonder if at some point in the not too distant future that 100 microseconds will be tightened as trading stocks become faster and faster.
20:15
So how we do instrumentation, if we go back to our service stack,
20:28
is to iron out fibre connexions to and from the exchange market data inbound and order entry outbound,
20:32
we insert optical taps, which is like a glass prism that is inserted, inserted into the fibre path and physically splits the light into two parts.
20:41
The production path going down to say, oh,
20:51
switch and the light split going into a precision capture device where a packet this is timestamped because it's a passive device.
20:53
It's not electrical. There is no nothing to go wrong.
21:05
And also there is no latency overhead. And inserting that glass into the path, there's probably a latency, possibly around four nanoseconds,
21:10
which is acceptable given the the benefits of instrumentation or capture device once up and running timestamps on packets and records events to disk.
21:20
It will also decode market data messages coming in and our order entry messages and messages going out.
21:35
And based on that, we're able to have a very accurate picture of our tech to trade measurement of our stack.
21:42
So go back to the original slide. If we remember, we have market data takes coming in and our orders going out to the exchange.
21:51
We can now measure exactly how long, including all our network switches and servers.
21:59
We reacted to a market data signal coming in that told us conditions were correct to buy 100
22:04
shares in BP to the point which our order to buy those 100 says left to go to the exchange.
22:10
As mentioned, analysing the data is super important every time we introduce a change.
22:23
We can now check the impact as we make improvements to our technology stack using various mechanisms.
22:30
It's really important to.
22:40
Evaluate whether the technology changes we're making to drive down our latency is actually infecting the profit for the business.
22:45
Are we hitting more orders as in far more of our orders being executed or is at the same rate?
22:55
And are we making more money?
23:03
So evaluating the technology improvements against what the business goals are, as is supercritical with some exchanges depending on the market data.
23:04
It is also possible to look at orders that are appearing on the exchange and also look when those orders disappear as a result of a trade.
23:16
By plotting that data out, it's possible to infer how fast competitors that are trading against the kind of orders that we're trading against are
23:27
so we can kind of work out how fast we need to be in order to match against those orders that we potentially missed.
23:39
So to speed things up, there's a number of things and tricks that we can do on the infrastructure side to do to decrease our latency.
23:53
The first would be to try to minimise the number of server of network of server hops between our components.
24:05
If we take our feed handler, our go engine and all the management processes, if we run those on separate servers,
24:13
the feed handler has to send a message over the network to the algo engine out to order on the order back up to the exchange.
24:22
If we can consolidate those processes on a single server,
24:29
then we can use in the server process technology such as Unix domain sockets or shared memory.
24:34
And we avoid having to go out of the PCI bus, on the server and across the switch.
24:42
These switches a very fast switches there around 380 nanoseconds from a packet and packet.
24:49
And so they are low latency. But once we get down into the ultra low latency space, hundreds of nanoseconds do dear matter.
24:55
There are scale considerations with doing this. Depending on how complex a strategy is, you may need more cores taken into account.
25:07
The system cause processes that need to run the feed handler and the order management.
25:18
If you have a very complex model strategy, you may not have enough CPU cores on a single case to be able to do this.
25:23
But if you can get a strategy and the supporting processes onto a single server, you can save a lot of latency by consolidation.
25:31
As a second step,
25:45
we could try to reduce the number of network switches we have in our stack each which costs us around three hundred and eighty nanoseconds,
25:47
as mentioned. So if we if we're able to do it by collapsing all three layers onto a single layer or exchange facing switch on the
25:56
light switch and our service switch onto a single network switch with latency of three hundred and eighty nanoseconds,
26:07
we can save around one and a half microseconds as a message has to go down the stack from the exchange,
26:14
from market data and up the stack towards the exchange for order entry.
26:21
That's around one and a half microseconds because we can say there again, there's a scale question.
26:26
If we have a very busy colocation site with lots and lots of strategies,
26:33
having a single switch to plug everything into, we may run out of resources and rappaport's on that switch.
26:39
So there is a balance to be.
26:46
The latest one of the latest evolutions of network switching and the low latency space is something called Lawhorn switching.
26:52
If you're familiar, familiar with the assignment of the network stack is layers one, two and three typically switches.
27:03
Traditional switches would operate at the network layer with IP routeing functionality and also the latitude,
27:14
which is just basically Ethernet to Ethernet communication. Layer one, which is the physical layer is the focus of Lawhorn switching.
27:24
How it works is a switch could basically be operated as a type of crossbars switch, which is effectively your programming,
27:37
a switch to connect electrical pathways to each other within within the switch, vastly reducing the latency overhead of that network switch.
27:47
We no longer need to worry about routeing protocols or kind of Appalachia processes in order to get a packet from into and out of a switch.
28:02
It's a pure electrical connexion from the cross connect coming down from the exchange and out to our server.
28:14
There's some trickery that we need to do in order to get messages up to the exchange.
28:23
If we have multiple servers, all sending messages or turning bit streams up to the exchange,
28:27
we need to somehow multiplex those data streams onto a single wire that goes up to the exchange,
28:33
which is slightly higher latency, vastly lower latency than a traditional switch.
28:40
So swapping in layer one switch into our stack, typical latency across alignments, which is down to around four to five nanoseconds,
28:47
which is a big reduction from 380 nanoseconds we saw previously and at the multiplex path going up around 80 nanoseconds.
28:58
So if we think of our two way communication from the exchange market data coming down from the exchange on the inbound path to the
29:08
order entry on the outbound path that previously is to switch hops three hundred eighty nine seconds worth of latency times two,
29:19
and we're now down to eighty four nanoseconds. So that's a vast reduction in our ticket trade latency.
29:28
I kind of scratch the surface here of the technique, some of the techniques we use on the infrastructure side to to improve latency,
29:42
and there's a whole bunch of other stuff that we can do on the House side as we
29:54
use High-Performance Network cards and Colonel Bypass technology to code our
30:00
application directly to interact with a network switch rather than via the operating
30:06
system that really does speed things up in terms of latency on the CPU side.
30:15
My colleague gave a presentation earlier this year around the overclocking and speeding up the the CPU processor to drive down latency.
30:21
And there's a whole topic on developing your code,
30:31
using low latency techniques and also with with the new FPGA functionality that's coming out into the space.
30:37
FPGA stands for Field Programmable Gateway,
30:47
and that's a way of it's a hardware based system where we can programme our own logic directly onto a piece of hardware that drives down latency,
30:50
whether based on the hardware path, we have less jitter as hardware tends to be more deterministic in terms of of latency than software.
31:08
And potentially people even go as far as dropping the server altogether and trying to code
31:21
their strategy directly onto an FPGA in the network switch from the Deutsche Boerse exchange.
31:27
The fastest turnaround times they see in terms of their trade measurement can be as low as 40 or 50 nanoseconds, which is which is huge.
31:34
Or they should probably say. Yes.
31:44
In terms of of take away and advice, I would say that always measure your systems, always build instrumentation,
31:52
not as an afterthought, but really think about how we can measure the the systems we're trying to build.
31:59
And certainly the latest space without any adding any additional latency,
32:07
adding brake lines and locking into any application changes its latency profile.
32:14
So if you're developing systems that need to be very fast,
32:20
it's definitely worth thinking about how testing and instrumentation can be added with minimal latency overhead.
32:24
Always analyse and understand your targets. It's definitely all very well for us to spend huge amounts of money driving down our latency.
32:34
But if our competitors are either significantly slower or it's based on the strategy that we're using, there's no value in that strategy.
32:46
Being able to trade past a certain latency point, then that money is not well spent.
32:59
And based on the analysis, always check to see whether the improvements you're making has improved the goals on the business side.
33:07
Have profits gone up? Are we executing more orders or for some reason, have the changes we made made it worse?
33:16
Definitely. Pick your battles, focus your efforts based on our trade numbers.
33:24
It may or may not be looking at technology which shaves a few nanoseconds off our trade measurement.
33:36
If we're still in the milliseconds order of magnitude on our trade, there's there'll always be low hanging fruit, I think with with this stuff.
33:42
And it's important to focus on areas that will make the biggest difference before focussing on the one you say,
33:54
which will potentially make no difference at all and definitely compete up to a point the latency arms race.
34:02
So I would say is a battle that you'll never win. People spend huge amounts of money trying to make their system as fast as possible.
34:11
And in the event that they are that trader that we had the algorithmic model running
34:21
on side and FPGA inside a network switch and they were turning trades around in 50,
34:28
60 nanoseconds, that will always be somebody who has found a way to make it faster.
34:33
And you may be number one for two or three weeks, but someone's going to come around and make something faster.
34:38
So depending on where your strategy needs to be, it just needs to be fast enough.
34:46
Not not the fastest. Just some follow up reading and resources, there's a good book, Flash Boys by Michael Lewis.
34:53
It profiles the early years of the late Late Show on race and the trading, high frequency trading,
35:07
low latency trading space investigates and interviews a number of the key players in the key institutions
35:17
around in those early years and also looks at some of the technology challenges that were there at the time.
35:24
It's quite an interesting read if you fancy watching a movie as a good movie called The Hummingbird Project.
35:31
And that's about two high frequency traders who identify an opportunity to build a very
35:38
short fibre cable run between two trading venues and try to try to make them millions.
35:45
Some of the terminology that I've raised through today, colocation and market terminology.
35:53
Investopedia is a very useful site to run through and get a better understanding
36:01
of of electronic trading and high frequency trading and how that hangs together.
36:08
In terms of career opportunities,
36:18
I keep definitely check out our website that's got the latest list of intern opportunities available that we have coming up throughout the summer.
36:21
I'm focussed on the computer science side of Cube, but there are ample opportunities on the research side as well.
36:34
I'm very lucky, I think, to be working for Cube.
36:42
I get to play with advanced technology all day that really does genuinely have impact to the company's profitability.
36:45
It's a wide,
36:55
holistic variety of technology that's across the trading stack and also all the supporting systems that we need to be able to manage funds,
36:56
advanced trading buses and cloud based technology. It really is a very interesting space.
37:06
It's a great company. It's a small company.
37:12
And it's all the places I worked. And I think I wouldn't be hard pressed to name a company that has a better culture than keep.
37:17
Of whistle through that, that's that's kind of the end of the presentation.
37:28
Does anybody have any questions? Yeah, thanks, Steve.
37:35
I mean, that was actually perfect line for a presentation. So so thanks for that.
37:39
And yeah, just to reiterate, Flash is absolutely great read if you haven't read it yet as an introduction to the whole low latency trading space.
37:43
We do have some questions.
37:56
So first of all, how effective is overclocking in reducing latency and exactly what are you what exactly are you overclocking or what?
37:59
Can you try and overclock? So it's very effective.
38:10
It certainly has made big impacts who are to trade measurements?
38:16
I'm not allowed to tell you exactly what our lowest tech trade measurements are,
38:22
but based on the kind of numbers that I've spoken about where I'm reducing switch latency from 280 nanoseconds to four nanoseconds,
38:28
if I bothered to do that, that gives you an idea of the magnitude that we're working out.
38:38
Typically, we're taking a specialist kind of gaming style motherboards, inserting those into service style data centre cases,
38:44
so mountable servers and taking water cooled CPU coolers and subspecialist kind of intel chips and ramping up the clock speed from,
38:56
I think, around three point six gigahertz to five point nine gigahertz.
39:09
And it does make a huge difference if you've got a and algo engine that is CPU intensive,
39:14
listening to those market update messages coming in in order to make trading decisions, being able to do that at a high speed is significant.
39:20
Gosh, five point nine gigahertz. That is very, very fast. That is really, really good.
39:30
Other questions that we got on here, somebody asks, what is the difference between quant research and trading?
39:36
So I guess that is the I'll probably need to take that one away to get an exact definition, I would say, to keep myself honest.
39:45
There's a research strategy. There's a research function, Keeves, which looks at basically all historical market data, how markets move.
39:53
We capture our market data every day. We upload that to the cloud for future analysis.
40:04
There's a research function that to able to take that data, analyse and come up with potential new strategies for the future,
40:13
for trading is more kind of the on the execution side and the the trading side.
40:27
I'll get you a better answer than that and I'll drop it over in an email.
40:33
Yeah, actually have students are more interested in the con side of things is another very good book, The Quants by Scott Peterson.
40:39
I don't know if you've read that one state. Oh, no, I haven't, actually.
40:46
Yeah, it's is it gives it gives an amazing overview of the whole Quansah trading space.
40:49
The Quants by Scott Patterson. It's it's a very good read.
40:56
It's it's it's the one that has given me personally the best overview of the whole the whole space.
41:00
OK, some of us saw it go and say, oh, no, I'll definitely I'll definitely take a read.
41:07
So some as a follow up on your overclocking thing, are you using Elenita,
41:16
which is that liquid nitrogen and helium cooling for for your supremely high flow?
41:25
I don't think you can say I. I don't know what the liquid is.
41:33
It's why I thought it was water cold, if I'm honest.
41:39
And basically in the case in the server they've managed to shoehorn in three months,
41:45
there's not a lot of space in a typical server that goes into a rack they managed to
41:55
shoehorn in a pump in a very sealed water court system with some passive radiators back,
42:01
which pumps water around, takes heat away from the CPU and exhausts South Korea.
42:08
Robeson fans, I think water. But I may be wrong.
42:12
There's all sorts of concerns every time we go and install one of these servers into a data centre about whether it will leak,
42:17
etc., and that that definitely has happened.
42:24
I think the tech has come on a long way now and certainly touch on the status of planes taking out the trade systems today.
42:27
Yeah, my office workstation, as it turns, is liquid cooled and it has a tendency to spring leaks all over the power supply.
42:36
That's not that not the best. I'll tell you, if you're just looking for an easily maintainable system, just get to get there called one said.
42:44
Julian asks, How important is volatility at these frequencies, like your algos adapt with volatility or some strategies just change somehow.
42:55
So, for example, or are there any special strategies for managing market openings and so on?
43:04
So I suppose depending on what your strategy is, yes,
43:13
most strategies or low latency strategies of all of our ilk almost rely on volatility in the market,
43:17
looking for differences they can arbitrate or trade off.
43:30
So typically, if markets are very volatile, if something like the house pricing, the mortgage mortgage credit crunch that we had in around 2007, 2008.
43:32
If you're in the right space with the right strategies, you can make a lot of money based on market volatility.
43:51
That was the case of GameStop in the US, where people were encouraged to buy GameStop shares, either Reddit and other things.
44:00
And that kind of had the potential for fans of our I to lose a lot of money as the market kind of moved in an unexpected direction.
44:09
And I think we also had a lot of funds Barak had earlier or maybe in actually the year before when the vaccine for Maidana was announced in the US,
44:20
it caused a market crash, but a market crash in the upward direction.
44:34
And if your strategies aren't expecting anywhere near that level of volatility, a lot of people found themselves in a particularly bad position.
44:39
I think a couple of funds even went under just based on the announcement that Madonna had come up with a potential vaccine for the coronavirus.
44:49
Great Daniel is curious, why would the regulator care about your coxing?
45:04
Because you need to be able to.
45:12
You need to have a very accurate record of trading events if you're responsible for high frequency trading.
45:21
It came around for a number of market issues.
45:31
The one that jumps out in my mind is I don't know if you ever heard of Knight Capital,
45:37
but Knight Capital, where a trading firm out of the U.S. and they had some very high performance,
45:43
high frequency trading stocks and they unfortunately released a some code into that production environment, which was meant for UTI.
45:49
And effectively, this system was trading against itself and it took out about one hundred forty five million dollars out of the firm.
45:59
And about 45 minutes is kind of that kind of forensic being able to prove a case at this point.
46:12
I made a decision to trade. Element to it,
46:20
I think the regulators care and also there's there are limits on high frequency trading and having the ability to say
46:27
actually it was this exact time where I made the decision to trade based on this exact time of the market update coming in.
46:37
If you were ever in a position where your you've exceeded your limits or you've caused a potential issue on the market,
46:43
which does happen, then you can prove it.
46:50
Exactly the timing of decisions and events leading up to that potential issue.
46:54
And that will help you make your case with the regulator to answer that kind of the rough reasons for regulation and time synchronisation.
47:00
Yeah,
47:09
another fascinating study on the deregulation is all that business of the the hound of Hounslow and his fiendishly clever futures trading system,
47:10
right where he was supposedly was partly responsible for the flash crash that that happened.
47:21
That's another good read, by the way, for people. Yes, and absolutely.
47:28
And we've you know, it does happen with with great trading people inserting, say, maybe some unauthorised behaviour into systems,
47:33
having an accurate time record of when your institution is sending or stage changes.
47:45
I mean, what's what's your view on actually whether, for example, I mean,
47:51
there's a fine line between a clever trading system and one that's actually illegal because it actually amounts to spoofing.
47:58
Right. I mean, I still have included in my mind as to whether, for example,
48:04
these clever futures trading system where effectively, constantly adjusting the size of his order.
48:16
So it always went to the back of the queue so you could have enormous orders in the system, which made it look like there was stuff there.
48:22
But then he had time to get out. If anybody started to nibble on that line of orders in in the back and he could he could get out.
48:28
I mean, some people might say, well, he was just looking more than one step ahead and good for him because it's a pool of sharks.
48:35
And if you go into the market, you must be prepared to have your legs, but not. Yeah.
48:43
And if you can find a way to avoid that. Well, good on you, right? Absolutely.
48:47
Yeah. I mean, I guess there's a fine line between being one step ahead and spoofing.
48:54
I think ultimately that's up the up to the trader to argue and the regulator to decide.
49:00
Certainly with our company we have a whole bunch of checks in place,
49:08
not to mention pretty stringent compliance processes that would look very unfavourably
49:16
if one of our traders was looking to insert speed for orders of that nature.
49:22
Yeah. And what do you do? Do not write the words in an email.
49:26
Yeah, quite right.
49:30
Another question. Would you could you please share some pros and cons of FPGA based low latency trading?
49:34
I mean, is that still a big thing? I mean, I know it was a big thing five, 10 years ago.
49:42
Is that still very much in use? Yeah, very, very much so.
49:47
Based on the exchange side and on the traders side, I would say the the disadvantage is the cost to entry.
49:52
And depending on what you're trying to do, you get FPGA solutions that have like an abstraction layer and you can code using C++
50:00
with some APIs and some clever kind of compilers that will convert that into HDMI.
50:12
But if you really want to implement from the ground up a strategy based on an FPGA,
50:18
you need to have kind of some a team of people that understand HDL.
50:25
And certainly what we're seeing in the industry is that's a definite skill shortage of people with that with that level of developmental skill set.
50:33
So cost of entry would definitely be one. I would also say that there's only so much you can fit on or deal with an FPGA.
50:42
So if you have a very complex strategy, it may not necessarily be suitable to put onto an FPGA.
50:54
If you have a very simple strategy that's looking for a very specific set of events coming from the market and you can implement that as,
51:02
say, look up table. If the signal appears, then get this order out to the exchange as fast as you can, then that's that's very suitable for an FPGA.
51:09
There's a hybrid approach, which a lot of people I think are looking at as well,
51:22
which is effectively that kind of constant reprogramming of an FPGA by a software
51:26
model looking at specific signals with the software oversight on that FPGA.
51:34
And then so you have TED orders on the FPGA that are primed and ready to go and you're constantly changing the stock potentially,
51:41
and the buy sell quantity and price that you're looking to execute on.
51:52
You can have that lined up in an FPGA if a tip comes in, when conditions are met,
51:57
get that order off and then your software reprogrammes the FPGA to be ready for the next set of orders and market data signals.
52:02
All right, thank you. Yeah, another question here, following up on the whole architecture, overclocking things,
52:14
are you using consumer grade KPIs for this and any special kinds of memory like memory?
52:23
Uh, yeah, I don't have the exact specs. And we do use is nothing particularly special.
52:31
Um, it's the kind of CPU and motherboard that you would find of the kind of high end of of of gaming rigs.
52:39
And if if you're an enthusiast on the overclocking scene, you know,
52:46
we're typically using kind of as you use gaming motherboards and commercially available CPUs,
52:52
memory specs, very high speed, but nothing particularly exotic.
52:59
I'm saying we've kind of SSD and VMS. I think the biggest challenge that I'm sure you're all aware of and we're certainly feeling
53:07
that pain right now is the silicon shortage that's impacting both server and networks,
53:14
which availability some of the lead times that we're seeing on some of this kit is in excess of nine months.
53:20
So I think that's a real challenge over the next couple of years for the industry. Gosh, any role for GPS in these systems anymore?
53:27
Yes, very much so. But I would say on the kind of backend modelling side rather than the low latency critical path.
53:36
Yeah, that makes sense, that makes sense, good. OK, I think we need to stop there.
53:48
Unfortunately, we could go on for hours, as you could tell, but thank you.
53:54
Thank you very much. If anybody wants to get in touch, what's the best way?
53:59
You know, I'm sorry I didn't put my email address on that slide deck, but yeah,
54:04
feel free to forward on any emails or share my email address with anybody who has any questions and how to get you an answer as best I can.
54:08
And if anyone, as I say, is interested in looking at key for a potential internship,
54:18
do please take a look at the research and the computer science opportunities on the website.
54:25
Great, lots of students saying they found that really fascinating and interesting. So there we go.
54:31
Thank you very much, Steve. That was really, really good talk.
54:35
Thank you very much. Thanks for the feedback. Have a good day, everybody. Kids, everybody is right.
54:39