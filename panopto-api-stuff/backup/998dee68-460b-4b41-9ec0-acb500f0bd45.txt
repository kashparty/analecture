ID: 998dee68-460b-4b41-9ec0-acb500f0bd45
Title: McLaren Applied ACI Talk Jan 2021
Category: AY20/21
Lecturer: Tom Curtin
Date: 19/01/2021
Yes, we have a Gordon. Great. OK, everybody, so welcome to today's applications of computing in industry talk.
0:07
We have a team from McLaren Applied Kenneth Learing, and I meet Gwalior, who's head of software engineering at McCarran Applied MIT.
0:18
Would you like to start off by saying a few words? Yes, sure.
0:31
First of all, thanks for inviting us again. This is the second time.
0:36
We are participating in the ACA lecture series. I think is almost a year ago, a different world.
0:40
We saw you face to face with lots of students that we dreaded into the hall at MacLaurin.
0:47
We used the data to our advantage. The challenges of harnessing that data and building solution in predictive analytics on different domains.
0:52
Today's focuses more on simulation world. Well, one of the other key technical pillars, his virtual product development.
1:02
And I think it is a very interesting area, a very challenging area as well.
1:10
And I think it encompasses not just computer science, but it also, of course,
1:16
data science and more importantly, simulation engineers, mechanical engineers.
1:21
So we have Kenneth Lay here who is going to talk us through that amazing world of how we use simulation,
1:25
hobby scale and simulation at McLaren Applied. If you have any questions or you know how you want to get involved or talk to us, you can come.
1:31
Why our Billiam or Tom? They would have us our details.
1:42
So I hope you enjoy. And. Or do you. Thanks, Sam.
1:46
Thank you, everyone, for coming.
1:52
It is my pleasure to be here to present some of the work that we do here and McLaren apply it a little introduction background to myself.
1:54
I studied at Imperial College. I did mechanical engineering for four years and I graduated in 2016.
2:03
And since then, I've been working at McLaren, applied as a simulation engineer, working under their simulation and modelling team.
2:10
And now being grouped under the Virtual Product Development Department.
2:18
And today, like Ahmed said, I want to introduce and to give everyone an overview over the simulation work that we do at McLaren
2:25
Applied and how we implement simulations and embed them into the processes of our customers,
2:33
into our own processes and turn them into an advantage,
2:40
the edge that our customers need to gain a competitive edge over their competition and over their rivals.
2:44
So the agenda for today is is quite straightforward, will first give her a quick introduction to those who are less familiar with our company.
2:56
And then we'll give a no an introduction to what digital twins and and how it relates to models and what it mean.
3:04
What do we mean when we talk about virtual product development?
3:11
And then we'll go into a bit more detail now into the challenges that face when we try to implement of EPD, of virtual product development process.
3:16
What that means for certain industries and and applications and how we MacLaren applied have built that experience in
3:25
overcoming these challenges and are looking to produce products to help our customers solve these problems as well.
3:32
So who are we as McClaren applied, and why should you continue to listen to me talk about simulation work?
3:42
The McLaren group encompasses three three distinct companies, and we are currently headquartered in Woking, in Surrey.
3:50
You can see our our lovely headquarters here,
3:59
a figure was used as a as the backdrop or one of the headquarters of one of the bad guys in Hobs insurer.
4:01
I believe this is a headquarters that we have in invoking and it has a total workforce of over 3000 people spread across three companies.
4:10
I think most people or many people would be familiar with our Formula One racing team, a McLaren racing star off a many, many years ago.
4:22
It's the second longest, longest serving Formula One team in the current grid.
4:31
Only shadowed by Ferrari. And we'll be touching upon some of the work that they do as well and how they use simulations.
4:37
The second company is MacLaren Automotive. And they were born.
4:46
After McLaren racing, but they've been bringing out the Supercars in HyperCard that we all know and love today,
4:53
starting off with the MP for Chelsea and then moving on to models like the P one seven 20 s seven six five Alti,
4:59
the speed tail, the centre, the centre and and the Elvire and so on.
5:08
And then we also have McCarren apply, which is ourselves, the third company in this group,
5:16
and we take the technology and the innovation that was developed from these two companies, from racing, from High-Performance Automotive.
5:21
And we look to apply them into all sorts of different industries, large scale manufacturing industries, defence and aerospace,
5:29
medicore all these different challenging areas that we believe can do with some some
5:38
innovation that we have developed in-house and can we can apply them into a much broader,
5:44
broader field. McClaren applied, we have three key technology pillars that we that we base ourselves on and we focus our attention upon.
5:49
And these are areas that we believe are things that society and today's society require and
6:00
can do and that we can provide additional value through the application of our technologies.
6:08
The first area is electric electrification.
6:15
It is something that's been hot in the news for quite a while now and electrifying cities and urban areas has been a focus of governments,
6:20
particularly in light of climate change. And in in this current Kovar situation, it's only driven this the push even further.
6:30
And here at McLaren applied, we develop high voltage, a hundred volt inverters.
6:39
And we also partner with with external suppliers to provide Moto E motors into the automotive sector as well.
6:45
And we also provide energy storage, battery solutions into the sporting and the automotive market as well.
6:53
For instance, we are the sole suppliers for the Formula E Racing series in their current Gentoo iteration.
7:01
And we are that the suppliers that currently enable Formula E to Formula E race cars to drive for the entire race distance.
7:08
If some of you remember INDEF in the previous generation, one,
7:18
their batteries were about half the size, so they had to do a car swap halfway through the race.
7:22
But with our current technology that we've developed along with our cell partners,
7:26
we are now able to develop that capacity and the power required to drive a Gentoo race.
7:31
Under our second technology pillar is telemetry control and analytics.
7:39
We believe in the usage and in in the collecting of data to analyse and understand
7:43
our systems that are in service and to derive additional insight from their men,
7:49
to derive additional value from them and and thus be able to add to to perform control actions,
7:55
to perform decisions and empower decision makers to drive their decisions based on data rather than just intuition.
8:02
And under that technology pillar, we we manufacture and make a vast array array of different sensors and supply them into,
8:12
again, the automotive and the motorsport industry.
8:21
We also have connectivity solutions, so Wi-Fi and Bluetooth solutions that we have applied to the public transport sector.
8:24
Currently, the the entire Formula One grid users are standardised, standardised ICU controllers.
8:32
We also provide the Formula One grid with a time series data visualisation tool called Atlas 10,
8:39
and that helps them analyse and to visualise their data in real time and to make those split second decisions that they have to do.
8:47
Also, race is going on. The third technology pillar that we believe in is something that will go into a bit more detail later in this presentation,
8:55
which is virtual product development,
9:07
and the core essence of it is essentially using a virtual environment to accelerate the development of our real world products,
9:09
using a variety of different tools, simulation and simulation management tools,
9:17
using simulators and using some of their data analysis and visualisation tools that came from the telemetry control and analytics department as well.
9:23
So let's go a bit more detail into what virtual product development is.
9:37
Why is it such a big deal and why is everyone talking about it these days?
9:41
And to do that, we really have to go back to the beginning and talk about digital twins first.
9:45
What are digital twins such a hot marketing term that gets bounced around these days and everyone seems to want to jump on the bandwagon?
9:51
But the idea behind digital twins is nothing new at all.
9:59
It's simply a mathematical model that represents some or a piece of code that
10:05
represents some aspect of a system in the real world and especially in academia.
10:10
We all have the writing equations and models and writing code since the 50s.
10:18
And and I've been using these tools to develop our understanding of real world systems.
10:22
And it's not only till recently when computing power and other marketing driving forces have been at play,
10:30
where this term digital twin has become really popular and amongst one of the hot buzzwords of today.
10:36
But there's something different between utilising a digital twin or writing a mathematical model.
10:45
And the idea behind virtual product development, because PPD takes this idea another step further.
10:51
Not only are you using discrete single models to help you understand a problem or to solve a particular question,
10:59
you're actually embedding the usage of models and simulation throughout the entire development process of a product.
11:06
And you're embedding them throughout our product so that you rely upon those models not just to answer specific questions,
11:15
but to be your single source of truth as to how your product is to behave.
11:24
Once you bring out intermarket.
11:30
And using such an approach has a number of different advantages that I can only list out a few at the moment because of the lack of time.
11:33
The most obvious and the key advantage of using PPD is that you can start testing your product and talks,
11:44
start testing your concepts much earlier in your development cycle, in your traditional V cycle, you would go through your conceptualisation.
11:51
You go through high and then low level detail design,
12:00
and then you start your validation and testing process using perhaps simulation tools or using physical prototypes or doing lab testing.
12:04
But the EPD approach is to start testing of right from the beginning.
12:17
If you only have a concept design, you can start testing that.
12:22
If you start developing subsystems out of a high fidelity, you can start testing that as well.
12:25
And that bringing all that testing right to the beginning of your process ultimately ends up in
12:32
a much quicker iteration time and reducing the time that it takes to bring a product to market.
12:39
And in the world of commercial products, time is money and therefore you reduce the cost that it takes to bring a product to market as well.
12:44
The second advantage is that you can design and optimise your design based on data and based on experiments and testing,
12:55
rather than relying purely upon the experience of your engineers, which is fast and often a very good source of data as a starting point.
13:05
You can hone in on that which is not humanly intuit and intuitive,
13:15
but you can you can trust upon the simulations and designs that you that the simulation work that you do and really
13:20
optimise your design so that you gain most value out of the product or the concept that you want to bring out.
13:28
The third advantage is now that you've gone through this entire process and brought a market, bought a product out onto market.
13:36
You also have its digital twin, like we mentioned. You have this model that you have been developing and processing throughout the
13:45
entire development cycle and can use that same model for its in digital monitoring,
13:52
as well as something that our colleagues in the telemetry control and analytics.
13:58
Do you have that model? You can correlate our model with the data that you collect in service.
14:02
You can use that platform as the basis to see whether your together infield data
14:09
and see whether your product is developed is operating as we as you would like,
14:15
whether it is time for a regular service of your model or not, of your model, part of your product yourself,
14:21
or whether there are discrepancies in your model that you should be improving upon the next iteration.
14:27
So collecting all of that data allows you to produce your second model, your future, your future product, using a much bigger database.
14:32
And you can base that to produce your next iteration. And your next product.
14:44
And to give you an example of of where all this came from, McLarens VPC story really began from Formula One and from McLaren Racing.
14:52
To the Common I, most Formula One cars may look very similar to each other,
15:03
and that's driven mostly by the rules and regulations that the FIA impose on each team.
15:07
But upon closer inspection, you find that there are over 28000 components on this car, on the chassis side as well as in the engine.
15:13
And you have to bring a completely new concept or a new design from between winter testing or even a bit earlier than winter tests.
15:21
Then the winter break and off to launch in.
15:32
In March and. This spans across approximately nine months time,
15:36
and you have to bring a complete redesign of your entire car in order to to improve your car performance measured by the millisecond.
15:42
With so many different components and a continuous improvement programme throughout the entire season,
15:52
almost the entire car gets redesigned throughout from March till November.
16:00
So, as you can see, the scale of the problem is massive.
16:05
You have to iteratively, learn, build and measure the performance of your vehicle with such a rapid pace of development.
16:08
It is impossible to build physical prototypes for everything to build prototype vehicles like they used to do a test teams in the past.
16:16
And that's really driven Formula One. It is a virtual product, virtual development process.
16:26
The FIA have encouraged this by restricting the number of test days that they can do.
16:33
And it really helps drive down the costs of office four as well.
16:40
And the results really speak for themselves these days, you see winter testing, they only have six days to prove out their prototypes.
16:46
And you can see reliability built into their cause and performance. That really comes from the complexity of the car.
16:54
And this really comes to show how that how performance a virtual product development
17:01
process can be in in an environment that really encourages this sort of an approach.
17:09
We can also look to MacLaren Automotive, our sister automotive supercar company,
17:17
to see the process that they develop in using virtual product development.
17:23
So the P1 vehicle was brought out a few years ago,
17:29
and it was our first hybrid vehicle that we wanted to bring out into market because of the limitations in budget and time.
17:33
We are our colleagues there really didn't have the luxury of building prototype after prototype testing our bench off the bench.
17:41
As a typical traditional High-Performance Supercar company would do.
17:51
So they took the process that EF1 had developed using the tool,
17:57
using a variety of virtual engineering tools like the vehicle simulator, that will talk a bit more about later on.
18:02
And also managing their data and experiments that will again talk about it more.
18:10
And the result was that we were able to bring out the P1 in the span of just 24 months,
18:14
24 months in twelve in two years, we were able to bring out a completely new.
18:20
The first hybrid vehicle in our entire company. And I believe that no other super supercar company is able to boast the fact that we are.
18:25
We can bring out a new car or a new model of a car every 12 months.
18:33
And all of that is thanks to this approach that we take in virtualising, our entire virtual in virtualising, our entire developer process.
18:38
So coming back to us then, what kind of EPD do we do here at McLaren applied?
18:50
And as I mentioned a bit earlier on in this talk, we seek to apply EPD and virtual development into all sorts of different industries.
18:56
We partnered up with, ah, with Deloitte to bring out a product called Supply Cycle,
19:08
which is about turning the manufacturing processes of a large scale OEM plant and turn.
19:13
And the schedules that they run and turning that into an optimisation problem
19:20
and help reduce the time that they take to to switch over different manual,
19:25
different product lines. So that's in the large scale manufacturing sector.
19:31
We also work in the medical sector.
19:37
This is a product that we partner not with a company call ortho sensor to bring out inpatient health monitoring systems,
19:39
helping patients to recover from after their cert, the knee operation.
19:47
We also, again, worked in the as I mentioned earlier. We supply the battery packs for formula each generation to.
19:54
And the process of specifying the battery pack to meet the demands that down to how we design,
20:01
how we package all those cells into an entire battery pack. All of that was done virtually in-house using of V.P. approach.
20:09
And last we use are our heritage from motorsport and from automotive.
20:19
And we apply the EBD process to a whole host of different vehicle development processes as well,
20:25
which is something that I will get into a bit more detail in the next section.
20:32
And this next part is about the challenges of implementing PPD, if everything I've been saying is true and VPC is such a wonderful process,
20:40
then surely every company out there should be doing it already.
20:49
But the fact that not everyone is or not everyone is successful in implementing PPD means
20:54
indicates that there are certain challenges in the process of implementing such a process.
21:00
And I'd like to break this problem down into three main sections.
21:07
The first is Tibbett, is to build confidence in the results of your simulation work.
21:12
How do you trust the numbers that come out of your computer programme?
21:19
And furthermore, how do you trust it more than you trust the numbers that you generate from your infill testing?
21:23
That is a shift in the mindset that needs to happen and our tools and processes
21:29
and ideas that concept so we can follow to help aid in that transition.
21:34
The second problem is data and experiment management, through all these virtual experiments that you've running, you generate a huge amount of data.
21:41
And the way that you process them, the way you sort them out and the way you keep track of them becomes a much bigger problem.
21:49
And it becomes a major challenge when it comes to commercial complex model, complex models performed in in a commercial environment.
21:58
The third challenge I would like to call them is commercial considerations or things
22:08
that a commercial organisation has to factor in when you try and adopt of EPD approach.
22:13
So to start off with to talk about building confidence in our simulation results,
22:22
I would like to take some some findings from a paper that was published in 2019 called Uncertainty Quantification in Vehicle Dynamics.
22:28
And in this in this paper in this review paper, they presented a number of different ideas.
22:39
I would just like to briefly summarise here.
22:46
So you have a system that you want to characterise and understand and that some or you want to develop a certain real life realworld system,
22:49
and that's represented here as the solid grey box. Two different approaches that you can take to understand your system.
22:58
You can either they'll just system and then start performing infield testing on it, using processes.
23:06
You're using a process called metrology. And that is what has typically been done for decades and decades.
23:13
Your experiments aren't perfect in any in any sort of way, there are a whole host of measurement errors and there are limitations,
23:23
city experiments that you can run in real life and limitations to the understanding of the boundaries of your system.
23:30
That means that there are plenty of errors in your experiment and and which
23:38
is why you end up with our balance on the numbers that you end up reporting. The other approach that you can take is to build a virtual model.
23:42
And you are in the process of developing your system.
23:53
You rely upon your model as your single source of truth rather than building prototype systems and.
23:56
And perturbing them in the first place.
24:02
Now, this is a very different mindset that one has to take trusting your model rather than trusting your realworld system.
24:05
Being simulation led rather than being a real world, let.
24:13
And by all means, the model is not perfect. The model, by definition, is a simplification of reality.
24:18
And so there are a whole host of errors that you have to account for.
24:24
And to try and fix up and minimise in order for you to rely upon the model as your real representation of your system.
24:28
The first area that you should account for is modelling error. And to reduce that modelling error.
24:38
This simplification, in reality, you have to test the logic of your system or your subsystems under controlled environments,
24:44
using things like bench tests or using unit testing. You really prove what you're proving here is not that your model exactly matches reality,
24:53
but that your model behaves the same, exhibits the same behaviour.
25:03
The logic behind your model reflects what is what is real and what is what the real system should do.
25:07
And part of this is also identifying where the boundaries of your model lie, because your model is inherently simplified.
25:17
There are things that your model simply cannot and should not try and answer in identifying those
25:24
are those boundaries is almost as important as encapsulating the logic within your model itself.
25:30
The second part of it is calibrating the model now that you have the logic or the structure of your model.
25:40
You have to populate that model using parameters that really characterise the exact type of system that you want to.
25:47
Want to represent, for example,
25:57
we have in house a vehicle model that is extremely flexible and it can represent all manner of different vehicles, and that's the logic.
26:01
And we've tested that logic using using many different vehicle types and and testing all sorts of different subsystems.
26:09
But using different parameter sets, we can use that vehicle structure.
26:18
That model structure to represent a four by four High-Performance hyper supercar or even your everyday hatchback.
26:22
And all of that is down to the science of parameter in your model based on the requirements of your system.
26:30
And lastly, to build additional confidence into your model, you need to perform the process of verification, testing,
26:38
whether your model can actually be resolved numerically with any sort,
26:45
with the degree of fidelity that that you require in the world of perhaps dynamic system.
26:50
You have your differential equations that you must solve numerically. Is your solver performing as you as you desire?
26:57
But if you're performing an optimisation problem, is your is your optimisation problem.
27:04
Have has your solution converged to the degree of fidelity or optimality that you require?
27:11
And these are all things to be aware of and things that we have noticed here in McLaren applied.
27:17
Now when we try and approach, when we try and develop a model that is accurate enough to for us to lean upon and to use within the VCT process.
27:24
Now, to give everyone a bit more of a concrete example,
27:35
I would like to introduce our McLarens in Vehicle Dynamics simulator that we use in-house for a variety of different works.
27:38
So to introduce the system, I'd like to show you this little video clip.
27:48
Okay, so that was just a little clip that we produced a number of years ago that introduces our vehicle dynamic simulator to the world.
29:00
And it's a system that we built and designed in-house and is currently installed in the McLaren Technology Centre.
29:09
It's a vehicle simulator that's unlike any other on the market.
29:16
It has four six degrees of freedom in it.
29:20
And the main key selling point here is that has nearly 400 millimetres of vertical travel here,
29:25
which is a lot more than what our previous situation was, which was based on a design produced by a McLaren racing.
29:31
And with this additional vertical travel, you are able to simulate all sorts of automotive automotive related scenarios much better.
29:39
And you can simulate the movements of suspension, suspension, arms, much more akin to everyday use rather than motor sport.
29:49
Great. The simulator is powered, has driven.
29:58
The motion platform is driven by electric motors. And so it has a much higher fidelity in their emotions.
30:03
And we claim to have a flat frequency response up to 40 hertz,
30:10
which is something that is much higher than what we can see in a lot of our competitors in the in the commercial market.
30:14
But if we take a step back from what we can see in the physical space and look at the vehicle simulator from a conceptual system level,
30:24
we can start to see all the models at play and how we use models in this in this simulator environment.
30:32
So this is the McLaren VVS, represented by a whole host of different models.
30:41
It's a it's a slight different. It's a very different actually a very different mindset from what we would consider as a gaming rig or a training rig.
30:49
We're not using a simulator here to train the driver, although we can.
30:58
That's not its primary use. We are, in fact, using the driver to developed the vehicle to develop other parts of the system.
31:02
And that's because we recognise that you can represent a driver or you can think
31:11
of a professional racing driver or a test driver as a black box model in itself.
31:16
A human being, a good driver is able to amalgamate in and summarise huge amounts of data, sensory data,
31:22
and produce a very concise report of how the driver, he or she feels about what the vehicle is actually doing.
31:31
So we are actually using this black box model that has been trained over years and
31:40
years of experience in order to provide feedback into our vehicle definition,
31:45
into our vehicle model. And we try and use that system to understand how our model is behaving.
31:51
In order to do that, we need to feed the driver with accurate inputs.
31:59
In this case, sensory inputs. So you have in the middle here these five different blocks which represent different models.
32:04
The visual models provide visual feedback into the driver.
32:12
That represents what the the the car looks like on the interior, as well as what the track looks like.
32:17
Also how we also have an audio model which plays into the drivers here and tells the trial or what the the engine is is doing,
32:24
whether they are whether they are what they know at the wind is doing at that instance,
32:33
for example, and other audio clip cues that we might want to provide to the driver.
32:40
But most importantly, we focus upon the physics of the model.
32:47
We want to make the motion that the driver feels as accurate as possible and as insightful
32:50
as possible to tell the driver radio what is the car doing at that instance in time.
32:57
So we have the physics of the vehicle interacting with the track, which is in itself is a model that we run in real time.
33:02
Then we pass it through.
33:11
Into a virtual representation of what we think the human vestibular system is doing, which then we which we call a process called cuing.
33:13
Which then gets passed on to another yet another model, which is the controller model for the motion platform itself.
33:24
Which then ultimately gets fed as sensory feeb sensory data into the driver and thus the driver closer closes the loop for us.
33:31
And you can use such an approach for hope. Such an approach is extremely flexible.
33:43
And this flexibility is what gives this kind of a system its value and its power.
33:49
Because you can use this kind of a system for all sorts of different applications.
33:55
For example, the most typical one that precinct would use is to tweak the vehicle set up before every race weekend.
33:59
It would go through a number of different vehicle configurations.
34:09
And the driver would provide their professional feedback on how the vehicle changes in its behaviour based on its that current configuration.
34:12
And because of the high frequency response that we have in our system, we're able to do primary right works,
34:23
even secondary ride work, which is something that not a lot of simulators can do in the in the market.
34:31
And furthermore, we can push the boundaries and even start doing mph work, noise,
34:37
vibration and harshness work using our platform, combining the audio as well as the motion.
34:42
And because we have a driver in the loop, we can test ideas.
34:50
You can use this system to develop eight US controllers at virtual A.I. drivers and how it is Pisit,
34:55
particularly how you may go from a level two to a level three and back down from level three
35:02
down to level to sort of the handover processes between the driver and the real human driver.
35:08
These are all things that we can test using an environment like this,
35:14
because it has because we are feeding the driver with a high fidelity sensory information.
35:18
But this loop that I show you at the bottom here, Boldon emboldened in red here,
35:28
feeding from the driver back into the vehicle definition is only one thing, one sort of a loop.
35:34
You can, in fact, pipe the driver feedback into any other model of the system to provide to do model correlation work.
35:40
In fact, again, this is something they're racing to in there. After each race we can the race driver would go back into the simulator,
35:48
drive a few laps and provide some feedback into how the physics of the model performs and whether
35:56
there are aspects of the vehicle model that we are not capturing or parameters that need tweaking.
36:04
Or you can use it to develop your queuing system. You can do it.
36:11
Use it to develop your audio or your visual systems as well.
36:14
All of this is possible because we have this close coupling between the driver and the machine.
36:18
But what if one of our customers don't have a vehicle dynamics simulator or they don't have the investment to do it or various complications about it?
36:28
How then do you build confidence in your simulation work? So instead of perhaps using a full dynamic simulator,
36:39
you have some basic off-line sims that you you perform that give you some indication of your of your product design.
36:46
The next step forward you can do is build a static simulator, which is also something that we at McLaren applied are looking to, to produce ourselves.
36:54
And at building this stack of simulations helps you build up confidence in your models as well.
37:05
Because a static simulator helps bridge that gap between your offline sims and your fully dynamic SIM.
37:12
It also helps you explore those designs that you don't need. And that would take too much time to test in a vehicle simulator for dynamic simulator.
37:18
For example, Basic Aid asks controllers or or basic model correlation work.
37:29
You may be able to do on a static rate rather than having to bring it to a dynamic rig.
37:35
Again, this is something that we are currently developing in the house,
37:41
and it's the image here I'm showing on the slightest only for illustration purposes.
37:44
The second problem that I mentioned earlier, Ron, is about data and experiment management.
37:54
Just to give everyone a sense of scale of the size, a problem that we're trying to solve in the commercial world to do a single automotive design,
38:00
your model perhaps has about 20 inputs and 20 outputs.
38:08
So you want to trim the model has about 3000 parameters or so, and you might want to run your model over one hundred operating points here.
38:11
And so there are lots of numbers that you want to track. Even in a single single design.
38:21
And each configuration meeting your configuration of your model and the and the version of your model that you want to run
38:28
and the data set that you ingest and it produces at the end are linked together as what we called a single experiment.
38:35
And you can daisy chain all of these experiments together to form a workflow.
38:44
So hopefully I've given everyone that an idea of their sense of scale that we are talking about here.
38:49
They're huge quantities of data that we are passing through our workflow at any moment.
38:54
And to further complicate things, we are importing exporting data from different data formats and different sizes.
39:02
So make it all those collaborative. You might want to be able to lifestream your data and to process it in in a collaborative environment.
39:12
And so on. All of this is compounded by the fact that your models on static either and your models are developed throughout the entire process.
39:19
And that sort of development needs to be tracked as well over time.
39:31
So all of this data and processing cannot be done by a single spreadsheet with data that is stored on on an engineer's local laptop.
39:35
This quickly. Becomes. Beyond what a single engineer can do, and so you need additional tooling in order to help track all of these different figures.
39:46
So this is where we can take engineer the engineering world can take a lot from the software world ideas like version control.
40:01
How do you test your ideas and test the logic of your systems automatically?
40:09
How do you deploy your models using an automated pipeline and forming this continuous integration process?
40:14
How would you offload your computational load from your local environment into the cloud?
40:21
These are all things that software has years and years of experience in.
40:27
They are only starting to trickle into the engineering world.
40:31
And this is something that we have noticed at McLaren applied,
40:36
and this is what also why we are currently building in another in-house solution, which used to be called Midas.
40:40
But now we are provisionally calling it experiment manager, experiment managers,
40:47
really a tool that's hosted in the cloud that enables all sorts of different engineering workflows to be managed.
40:53
You can run all of your experiments in a cloud environment.
41:02
You can iterate through those designs and share that data amongst all of your your colleagues and different engineers and different departments.
41:05
And they can also ingest data from all sorts of different sources, whether it is in field testing,
41:15
lab testing to and from your different simulator breaks or of fraud ingesting data from simulations within itself as well.
41:21
And by having an environment like experiment manager, we've we then enable a workflow and then an engineering process that is fully traceable.
41:34
You can track all of your all of the experiments that you run back to the requirements that you set from the beginning.
41:45
And it also enables collaborative working between engineering departments and different locations as well.
41:52
So automotive, we have an office in Spain that run experiments and and track testing and get that data gets
42:01
shared with our colleagues back in back in the U.K. and Formula One travels all around the world.
42:08
And the data that they collect there has to be shared and with the factory team as well.
42:15
And this really shows the power of managing your experiments in a way like like we would like to propose here.
42:21
And finally, I'd like to just share a bit on some commercial considerations or organisation level
42:31
considerations in in our years of experience and the customers that we have engaged in,
42:37
engaged in and our partners that we've worked with. We've broadly categorised two different types of companies in this PPD process.
42:44
One of them would be that they are very new to the V.P.
42:53
The idea of computer aided engineering and they don't really have many models to rely upon.
42:56
So for them,
43:04
their first step is actually to start building models in the first place and to show them these many different complex tools can be daunting for them.
43:04
So there are questions that they can ask and that we often ask our customers and our clients.
43:13
What sort of a problem might you actually trying to solve?
43:20
And you should really build a model that caters for that kind of a problem that you want to want to answer.
43:23
How complex your model be? How many degrees of freedom?
43:31
Where should you store all of your your data and where you want to execute your your your your simulation work?
43:34
How do you protect your IP and how do you protect your data?
43:42
These are all questions that we have asked and continue to ask are our customers when they start to build their models.
43:44
But that's only one type of firm, one type of company.
43:55
But the vast majority of OEMs in the in the market these days have been on the V.P.
44:00
journey or have been on the computer aided engineering journey for a long time now.
44:04
They've built Tucker repertoire of models they use in-house, perhaps using complex modelling software like answer provided by companies like Kansas.
44:09
But their problem is that their models are often siloed in-house within their respective departments.
44:20
And they lack the ability to join up all of these different tools and different models
44:29
that they have in order to generate a fully fertilised product development pipeline.
44:34
And so using something like experiment manager that were mentioned earlier can really
44:41
help these companies bring all of their different models and simulations together.
44:46
And for them to even further accelerate that development process.
44:51
And it's something that we've seen in many big engineering companies, their respective departments, for work on their respective models.
44:57
And they only really come together as chief engineer meetings every few months or so.
45:06
So the lack of communication and the discrete modelling environments that they run on is what is really hampering them.
45:11
And that really requires not only the adoption of an experiment management tool, but a change in the eye in the work.
45:20
How a company works together as well. Again, something that we've helped a number of our customers try to.
45:28
In all of this requires investment into tooling skills, upgrading the skills of their engineers and training as well.
45:37
And something that we've had to face quite a number of quite a number of times is management,
45:45
asking engineers or asking, asking ourselves, asking McLaren, apply it.
45:53
Why should we adopt this EPD Business. 50 process.
45:59
What tanjil can we show tangible benefits to their business?
46:03
And so by performing presentations like these, sharing the knowledge that we have on the V.P. process,
46:07
we hope to to share our experience and our knowledge upon EPD and really convince you that this is the process that we believe in.
46:13
And that would really help drive down the cost that it takes to to bring a product to market.
46:24
So to quickly summarise why I've been talking about over the last few last few minutes, PPTA virtual product development,
46:31
virtual product development is a process that we believe can really accelerate that product
46:40
development cycle and ultimately reduce the costs that it takes to operate a product to market.
46:45
And we've shown you examples both from our sister companies in in in Formula One as well as in automotive and in-house as well,
46:52
using the McLaren vehicle dynamic simulator as an example.
47:01
There are many challenges that exist in adopting a VPC approach, especially if you're coming from a very different mindset.
47:06
And there are many factors to consider.
47:14
But the things that I've shown you today hopefully can convince you that there are tools out there and processes and
47:16
considerations that you can do to help you transition over to somewhat or more of a virtualise product development cycle.
47:23
And lastly, code developing with an experienced partner, a partner who has gone through this process many times and has contact,
47:33
has all the tools and the experience that you need for like McClaren ourselves can really help with that transition process.
47:40
So this is what. Although I would like to share with everyone today.
47:49
Thank you all for listening. And now open the floor up for some questions.
47:53
Yes. Thanks very much, Ken. It's really fascinating talk. Does anyone have questions for the McLaren team?
47:58
If there's no one who wants to go for, maybe I can start. So I thought this idea of the experiment manager was very, very interesting.
48:15
We had an academic in our department a while ago that Dr. Jeremy Bradley,
48:21
who proposed the idea of something called Performed D.B. in which you stored or the results of your your models and your simulations.
48:27
And you you could share them, you know, between different research groups and so on.
48:35
So so it's interesting to see that you've you found the need for something similar in your industry.
48:40
One thing I did want to ask you about is when you do your simulations and you're looking to, you know,
48:47
really trust the results, how can you be sure that they are not only realistic, but also complete?
48:51
So, for example, if you miss out some aspect of heat modelling, you might, for example,
48:58
be at risk of a fire that then doesn't show up in the in the simulations.
49:03
How do you deal with that?
49:08
Yeah, and it's certainly something that we've had experience in as well and from the years of development in from from racing and from automotive.
49:10
I think that a lot of it does come down to the iterative nature of developing
49:21
a model and testing it at every point and in the development process as well.
49:27
You might start off with and for example, in in our battery development, you might just start off with the electrical chemical side of things.
49:32
You start building a model based on that.
49:40
But then over time, you start piling on the levels of complexity that you need to build up a four four system for system model there.
49:45
And one thing that I mentioned earlier is a really about identifying that the the limitations of your model is almost
49:53
as important as so understanding what the model can't do is almost as important as knowing what the model can do.
50:00
So, you know which questions to ask in which you shouldn't be asking.
50:07
And I think through this iterative nature of testing constantly and you might end up having a much smaller
50:11
fire in your in your prototype rather than having a much bigger fire when it comes to your final design.
50:19
To give you an example. Yeah, very interesting. I must say, yeah.
50:26
When you said you you trust the you want to move to a world where you trust the numbers more than the simulation numbers,
50:31
more than the real field testing numbers.
50:39
Yeah, I didn't I didn't know about that because I've had students come to me and say these are these experimental numbers that you've got.
50:42
They don't agree with my models. So your experiment is wrong.
50:49
Right. And I wasn't I well, I wasn't sure that that was the correct interpretation.
50:53
Anyway, we have some questions here from the students.
50:59
So students would like to know what kind of opportunities are there at McLaren for first and second year computing students?
51:04
You. Sorry. Before I answer that question, though, I'd like to address what you talked about, the fact that the two different approaches,
51:12
because it's something that many people have asked, which one should I trust more?
51:19
I think of what I've shown today is a bit idealistic and this is impossible to fully rely purely on a computational model.
51:23
You do need that hybrid sort of approach.
51:32
And I think this is in our experiences what has worked worked best, but we're slowly moving towards more of that virtualise area.
51:34
But in terms of the opportunities for first and second year students, we do offer internships.
51:43
I'm not entirely sure what the what the situation is, whether with internships at the moment.
51:49
But we do have those those summer internships and yearlong internships where questions come in.
51:55
They really get embedded into a project within the team and work on perhaps some aspect of experiment manager that we talk about.
52:03
Perhaps you'll be working on how to connect a certain at all to the entire database that we took in the cloud and
52:11
stuff like that that really not only explores different ideas where it helps you show the students the application,
52:19
how an idea like experiment manager can be applied in the commercial space.
52:27
OK. All right, thanks. I think it did. Sorry, just to yeah, just to compliment on that, I think McClaren applied has an amazing spectrum of skill set.
52:33
It's not just computer science or mechanical hardware, electrical engineers.
52:43
So I think anything the opposing team is also is you can build products which encompass a spectrum.
52:48
You know, normally go to a software company only walking cloud. You don't look at physical things as opposed to do you work on the hose spectrum?
52:54
So, yes, I think I think the kind of engagement we're looking for is not just internship.
53:02
It can be more like collaborative work and working on a particular hypothesis which more technical hypotheses.
53:07
I'm very interesting. You talk about the database. The obvious question is what kind of data model are you scaling?
53:13
So it's very interesting offline question.
53:19
If you connect to us and this forum gives us that, you know, touch point again with the McLaren Leiden and your guys on different levels.
53:21
So we welcome all all engagement. Brilliant, thanks so Charmaine.
53:31
Would like to know the following.
53:36
Did you have technical experience in data modelling, programming and so on before joining McLaren applied or did you learn it on the job?
53:38
That's a good question. So I as I mentioned earlier, I studied mechanical engineering here at Imperial.
53:49
And I think the focus there was very much on like the traditional side of things.
53:55
And I only really started touching upon data modelling in my final year projects when I tried to reproduce a CFT Solvay using a neural network,
54:00
which was very ambitious at that time. But no,
54:11
I really started touching upon data modelling and data science when I started working
54:15
at McLaren applied because of this collaborative nature that we have in the company.
54:19
It wasn't enough to simply work in vehicle dynamics and traditional simulation.
54:24
We had to start incorporating a lot of this, the data science, the software engineering,
54:30
in order to produce a product that would be commercially viable,
54:34
that our clients would actually want and solve the problems that they were interested in.
54:38
Yeah. Very good. Right. Boyd has a question. Do you have enough computational resources to simulate the many different variants of the whole vehicle?
54:43
And especially thinking about potential emergent problems like vibration that might only come to light when you put the everything together.
54:52
Yeah, that's a good question.
55:05
The the resources that we need to simulate a vehicle, especially in in our simulator, our driver in the simulator environment,
55:06
we are running our Real-Time vehicle model out in real time, at least of one at one kilohertz frequency.
55:14
So we've also on top of building the fidelity of the model.
55:21
We've also learnt how to trim the model so that it can be executed in in real time as well.
55:26
Certainly, we use a lot of different techniques and we we utilise all sorts of off-line, high fidelity models as well to build us that confidence,
55:33
the correlation that we need with the High Fidelity Offline fly model and are our
55:42
real time model are things that we consider when we run a system like a simulator.
55:47
OK. Brilliant and last question from Steve, because we're running out of time there during the covered pandemic.
55:55
We understand McCarran contributed to the room to. Did MacLaren applied contribute to that and were was V.P. D or aspects of it?
56:00
Part of the process enabled the rapid development of those ventilators.
56:11
Yes. I think it was a collaborative, collaborative effort from the entire McCarren group.
56:17
I'm not entirely sure. And I think our involvement was in building some support or some physical supports for the ventilators themselves.
56:25
And I think that the specification of that scope was that we would replicate an existing design.
56:34
So there wasn't a huge amount of scope in terms of the the innovation that could be involved, but something that probably was done via VPC,
56:40
which you could read up on the news about Mercedes and how they worked with Accademia to reproduce to see Pappe device.
56:49
And that was done. That really shows the pace that you can achieve using a virtual virtualise.
56:57
Well, it was a reverse engineering process in in in their situation.
57:04
Brilliant. I think just to add to that, sorry, just quickly, yes, we did participate and it was that it was a great opportunity to contribute.
57:10
We can share more details. They are already publishing our applied. I think of website.
57:18
I can share that your plan as well. You know exactly how we contribute to that.
57:23
That's fantastic. All right. Well, Kenneth Anomic, thank you very much.
57:29
That was an absolutely fascinating talk and it's been a pleasure to have you.
57:33
I wish we could continue, but unfortunately, we are.
57:37