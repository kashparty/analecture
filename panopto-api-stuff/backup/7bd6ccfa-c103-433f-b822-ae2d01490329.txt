ID: 7bd6ccfa-c103-433f-b822-ae2d01490329
Title: 5.1 Floyd-Warshall algorithm
Category: COMP40008 - Graphs and Algorithms (Spring 2021-2022)
Lecturer: Iain Phillips
Date: 13/02/2021
So now I want to look at transitive closure and Warsaw's algorithm for computing the transitive closure.
0:02
So let's remind ourselves of what transitive closure is.
0:10
So we have a binary relation are on the set X and in the discrete mathematics course.
0:15
You were told that the transitive closure of AR is what's called R plus,
0:25
and it's the union of after the K from K equals one up to infinity and the art of the K is just composing the relation are with itself K times.
0:30
And if X is finite and has size N then you can actually stop computing the transitive closure at stage end.
0:41
So our class is just the union from K equals one to N of out of the K.
0:52
Because after that you are just getting repeats.
0:57
For us, we'd like to relate this to graphs and in particular, obviously, this relation will be directed to graph G.
1:01
And the nodes are just the members of X and we have arcs from X to Y.
1:10
If and only if R is relates X to Y.
1:14
So let's. I have a diagram for that.
1:19
If we. Drew, I think it's time again.
1:24
And here we have our graph.
1:33
And here we have points, maybe one, two, three, four.
1:38
And then maybe we have an area from two to three, perhaps from one to itself,
1:44
that we could allow that maybe from four to one, maybe from four to three like that.
1:49
And let's put in three goes back to as well.
1:57
OK. So there is a possible binary relation and we notice we do not allow parallel arcs here.
2:04
So because we are interpreting a relation here. So that would make no sense. But we do allow loops.
2:13
So we're saying that our relates one to itself. Well, it's easy to see that out of the K x y.
2:18
If and only if there is a path of Lenth K from X to Y. So that is our graph theoretic interpretation of art of the K.
2:27
So if we're looking for parts of lenth to here, then for instance we go, we can go from four to one and then from one to itself.
2:35
So that is a path of length to. Or else we can go from two to three and back to two.
2:43
That's another path of length two etc. So that allow.
2:49
And what we want for the transitive closure here is to compute the union of R r squared R.
2:53
Q Renart the fourth in this case because N equals four in our little example.
3:02
And what we then can say is that R plus relates X to Y.
3:07
If not only if that is the path of length greater or equal to one from X to Y.
3:14
So that's what we're trying to compute. And well, we can also relate this to matrices.
3:21
And so if we have, we can get the adjacency matrix of a graph such as this one here.
3:30
And we. Let me. So that's obviously in our example.
3:40
That's going to be a four by four matrix. So we can say that one is related to itself and nothing else.
3:45
So that would be zero zero zero two is related to three.
3:52
And two, nothing else like that. And then three is related to two.
3:57
And two. Nothing else. And then for is related to one and two.
4:05
Three and nothing else like that.
4:13
Just count it one, two, three or four and five.
4:17
Yep. So we've got five arcs and we got five ones in The Matrix.
4:20
So that's the adjacency matrix associated with the graph.
4:26
And the nice thing is that we can compute R to the K just using matrix multiplication, so I won't do it here.
4:31
But if you want to compute R squared here,
4:38
you just multiply this matrix by itself and you might get values greater than you won't be, just zero and one values.
4:41
In that case, you might get a two or something of that sort if there were two different paths taking you there.
4:50
But we can say that after the K i j. If and only if A to the K, the matrix multiplied by itself, the IJA entry is greater than zero.
4:56
So one or above. And then the transitive closure can be just got.
5:06
By summing up a two, the one up to eight.
5:12
The K has matrices and R plus that the.
5:16
Well sorry that's B well that's a B is that then.
5:22
That effectively gives us the transitive closure because we can say ah plus ija if an only FBI J is greater with the zero.
5:26
So that gives us ways of computing the Transdev closure, we can just take the adjacency matrix,
5:35
keep on, find the successive powers A to a up to a to the N, and then add them together.
5:43
And that will give it give us the result.
5:51
So that's using basically a method of saying, well, the transitive closure is all paths of lenth from one up to N.
5:55
So let's compute the parse the length one. Then the path of length less equal to two.
6:03
Less Meikle to three all the way up to N and by this obvious method.
6:08
But we can actually do this more efficiently by a quite different method.
6:15
So then that is the the war shields algorithm method.
6:20
So let's come onto that. So now let's suppose that the node's a want to end.
6:25
And we're looking at a path from X want to X case.
6:34
So let's have a diagram and let's just make it quite general now.
6:38
So here's a general graph. Gee, and we've got a path from X one to X.
6:44
K. And here it goes.
6:52
There is a general path going from X one to X K.
6:57
And the nodes here are the intermediate nodes along the path, everything apart from the two end nodes or the intermediate node.
7:01
And what the clever idea in war, Shor's algorithm is that we're going to look for palls that use nodes less than or equal to AI as intermediate nodes.
7:15
So and let's so all these intermediate nodes here in the graph have to be a value is less than or equal.
7:25
Two eyes. That's right. That's right.
7:33
For the intermediate nodes. And we'll take successive values that I basically from zero up to N is the idea.
7:39
So let's define B sub K. I j.
7:48
To be equal to one. If only if there is a path from ide j.
7:54
That uses intermediate nodes Lessner equal to K. So we let's change that.
7:58
That's now. So we lost all grofe mind.
8:07
Let's put that back. And let's change that to.
8:15
They. And here we have Jay.
8:25
And then this will be Kay. Okay, so we're looking at files from my to J.
8:30
And they have intermediate nodes which are less equal to Kay.
8:36
So that's the definition of B kay.
8:41
I, i j equals one. If they if this path from I to J which using intermediate notes lets me equal to Kay.
8:45
Well what's so nice about that. Well if we take K equals zero then you can only have intermediate nodes less, more equal to zero.
8:52
So that means you can't have any intermediate node. So that means that there must be.
9:01
And basically I must be an hour ARC's directly from I to J.
9:06
So it's just equal to the original adjacency matrix A.
9:10
But if we put K equals N, then we're basically getting the whole transitive closure ared plus because then we're allowing all intermediate nodes.
9:16
So let's be very K from zero to N we actually get we start from the original matrix which we know what that is.
9:29
And if we can just go through successive valleys of K, then when we finish it and we will have computed the whole transitive closure.
9:37
So the next part, of course, and the most delicate part is how to compute B, Sub K from B, sub K minus one.
9:48
So let's have another diagram. So let's let's take the same diagram and let's.
9:59
Just think about what's happening here.
10:11
So we've got we're trying to compute B, sub K, so we're trying to compute the less than or equal to K.
10:15
Well, then let's think about whether there are two possibilities.
10:21
We've got a path from I to J using intermediate knows less frequent a K either K is not an intermediate node of P.
10:27
But then all of these nodes here will be less than or equal to K minus one.
10:35
And we know that already because we've already computed B sub K minus won't divide J.
10:40
So it doesn't change. But the second and more interesting case is where K is an intermediate node of P.
10:45
So we've got a K on our diagram. Let's put it in.
10:53
So here we are. So this actually is K now K.
10:58
Well we can assume the K only occurs once in this diagram because imagine the K occurred twice.
11:04
Well then we'd be going from Iyi to K and then from K to K and then from K to J.
11:11
So the bit going from K to K is just redundant, is not giving us any extra parts.
11:17
So we might as well just eliminate that. So we can just eliminate the cycle from K.
11:23
K. So K only occurs most once.
11:28
But then what do we have. We have a path ramyun to K.
11:32
And in this path from EI to K, then we can see that within this same path we've just got intermediate knows less than equal to K minus one.
11:36
And similarly over on this sub path. On the right. Less equal to K minus one.
11:48
So therefore we know how to compute that because astrocyte asking is there a path RMI to k
11:54
using intermediate nodes less Mehul to claim on as one that's just be K minus one Eick.
12:03
And similarly, the other path we can just use B sub came on is one K J.
12:08
So either K is not an intermediate node and that's just given to us by the baby, be K minus one IJA or else it is an intermediate node.
12:15
And in that case, we just have to compute the conjunction of B.K. minus one K and became Unspun K.J.
12:27
So that is waterwheels algorithm. And here is the code for waterwheels algorithm, which is just exactly what we did on the previous slide, basically.
12:34
So we take our adjacency matrix as input. I've copied it into a separate boolean array here.
12:47
And then we go in the main loop. It's just a for loop because we always do these and iterations for K equals one to end.
12:56
And we're going to then we're going to update the values of B.
13:07
So we go over all the values of B in its matrix. So we've got to some loops on I and J.
13:14
And then we update B IJA to say, well either. Now we're trying to do it for K.
13:22
And so either K did not occur as an intermediate.
13:29
No. That's this first case in which case we leave the IJA unchanged.
13:33
Or else. Or else it was a suppling.
13:38
It was an intermediate node. And in that case we've got this other case.
13:42
So what we now need to do is to compute just this boolean combination of these.
13:47
And that's exactly what we did on the previous in the previous argument.
13:53
And after we've done that, then it should be the case that B is now updated to be B, sub K.
13:58
And therefore, when we come out of this altor for loop, then B will be equal to be sub N.
14:05
So you notice that this B equals B sub some index here is effectively acting as an invariant A.
14:12
In arguing for the correctness of this algorithm. And then so at the end we will have the transitive closure.
14:22
And the complexity is clearly bigger than cubed because we've just got the three, four loops nested.
14:30
Right. So that was Waterfall's algorithm closely related to that is Floyds algorithm.
14:41
In fact, sometimes they are referred to as the Floyd Warshel algorithm because they are so closely related.
14:47
But Floyds algorithm solves a different problem, not finding the transitive closure, but the all pairs shortest path problem,
14:54
which we had before given a weighted directed graph, find the shortest paths between all pairs of nodes of the graph.
15:01
And we can just modify foreshores algorithm very simply.
15:09
So let's suppose that we've got our weighted graph with nodes one, two N and we've got our adjacency matrix A.
15:15
Which will we'll have the weights in the adjacency matrix here.
15:25
So that will give us the weights of the graph. And what we want to compute is be some okay I j.
15:31
And that will be the length of the shortest path from Node I to know J.
15:40
Which uses intermediate nodes less than or equal to K.
15:45
So that's what we're trying to compute. And if there isn't such a path then we can set these up.
15:49
Okay. IJA to be infinity. We just want some high value.
15:56
And so that will signify that we haven't found a path. And how do we initialise this?
16:02
Be Sub-Zero IJA. That just says, well, if there is an arc from I to J.
16:09
Then it will just be the weight of that arc that otherwise will set it to infinity
16:15
to indicate that there isn't a path using effectively no intermediate nodes.
16:20
And once we compute B sub and IJA, that will be the true length,
16:27
the shortest path from either J because B sub and allows us to use all intermediate nodes.
16:33
So now the argument, of course, is that we need to compute B, some K from B, sub K minus one.
16:42
So let's imagine that we have a shortest path P from I to J.
16:49
Using intermediate nose length less than or equal to K of length D.
16:55
So how can we find that shortest path? Let some as before.
17:01
There are two cases depending on whether K is an intermediate node of P or not.
17:07
Well, let's have a diagram straight. So.
17:12
That's effectively it's the same kind of argument as before.
17:18
But let's draw the diagram again. So.
17:22
We have our graph. And we've got a path from I to J.
17:29
And we want to find the shortest path from I to J. That's using intermediate knows less than or equal to case.
17:38
And we're looking at intermediate knows less than three to K.
17:45
And then we have two cases as before. Is K an intermediate node or not?
17:50
If it's not an intermediate node, well, then we know that all the intermediate notes are less than equal to K minus one.
17:57
And so we know that this D that we're trying to compute here is already being computed by B to the came on its one IJA piece up came on Swane IJA.
18:05
More interestingly, if K is an intermediate node. So let's put it in the diagram.
18:18
O k is an intermediate node. Well, again, could K occur twice in this path?
18:24
Well, that would make no sense because this is supposed to be a shortest path using those less equal to K.
18:31
So makes no sense to go from K and then come back to K again.
18:36
We can just cut out that part and get a shorter path. So therefore, K only occurs once and therefore obviously in the path from AI to K,
18:40
we've got less than or equal to all the intermediate knows the less than equal to K minus one.
18:49
Similarly, on this path from K to J. All the intermediate nodes that are three equal to K minus one.
18:55
So apart from K, everything else is less than equal to Cayman's one.
19:03
But then how can we compute the length of this path.
19:07
The D. Well it must be just. It must be just.
19:12
We already know the shortest path from I to K using those less equal to K minus one.
19:18
That is already given to us by B sub came on this one.
19:24
I k and the length of the shortest path from K to J.
19:28
Using those less than equal to K minus one is just given by B, sub K minus one.
19:34
K.J. And so the length D here is just go by adding those two together and therefore we can
19:38
see that base up k IJA is just the minimum of the possibility where K does not occur.
19:46
And the second case where K does occur. So we just take the minimum of the two cases, one and two above.
19:56
Notice that this formula also works. Even if there isn't a shortest path, just using you, just using notes less, more equal to K.
20:03
So it still works in some form. Right.
20:12
Well, then we can just now just.
20:16
Write down the code for Floyds our or the pseudocode, so we input all matrix with the weights and then we set B IJA to be zero.
20:23
If R equals J because we'll say that the length of the shooter's path is there and then in that case just departed and Sarah with no arcs in it.
20:36
Or else it will be a IJA. If there is an arc from AI to Jane or else it will be infinity.
20:46
If there is no arc so that initialises us. And now we've got that B is equal to be some zero.
20:53
And now we go through all three, four loops nested as before, and Earth to compute the new value would be IJA.
21:00
We just take the minimum of the existing value would be IJA or B.I K plus B.K. J.
21:09
As using the argument on the previous slide. And then at the end of this, we have computed all the shortest parse between all the pairs of nodes.
21:16
So this matrix gives us all the. And the complexity is clearly big over and cubed as before because of the three nested for loops.
21:25
So. Waterfalls album Floyds Algorithm, which are effectively much pretty much the same algorithm,
21:39
but they are both examples of what's called dynamic programming, which is a style of algorithm.
21:47
So in the dynamic programming style, what we do is we break the main problem down into some problems and some problems are ordered.
21:54
For instance, they could be ordered by increasing size. They may also be typically overlapping.
22:04
We'll see example when we come on to we'll later in the course,
22:10
we'll be able to contrast the dynamic programming style with the divide and conquer style.
22:14
So the sub problems are quite often overlapping as they are in the Floyd Warshel algorithm.
22:19
And then these sub problems will culminate in the main problem. So as you increase size, eventually you get up to the size that you want to solve.
22:25
The true problem we are interested in solving.
22:33
So to solve the main problem, we move through the solve problems in order that typically of increasing size.
22:36
And then we solve each some problem using the stored solutions of the previous some problems.
22:43
And then we store our new solutions for later use. So we are computing B, sub K from B, sub K, minus one.
22:48
And then we store B, sub K and use that to compute these up K plus one, etc.
22:56