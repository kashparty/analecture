ID: c6743dd8-67e6-4b11-8d14-ae2d0148fc6a
Title: 8.2 Bottom-up
Category: COMP40008 - Graphs and Algorithms (Spring 2021-2022)
Lecturer: Iain Phillips
Date: 06/03/2021
So we've seen a recursive solution to the word brake problem and we've seen how to improve that using memorisation.
0:02
Let's now solve the same work brake problem in using the bottom up style and see how that works out.
0:10
So the idea is that we're going to solve increasing some problems, culminating in the main problem.
0:20
So the main problem is for the whole string and the sum problems are going to be increasing.
0:26
Initial segments of that strings. Now, let's see how that have a diagram for that.
0:34
So here is R or string. Index from zero up to lenth s minus one.
0:41
So here is our string S and we're going to look at increasing some problems.
0:51
So let's take a slice up to but not including I.
0:58
So this is S Kerlan. I like that.
1:03
And so the nice thing about that is that we start off with just the empty slice.
1:09
And we work up by the time that we have set eye to be equal to N.
1:16
So I is off the end of the string here. Then we have actually got the whole word, which is the actual problem that we want to solve.
1:22
OK, so we need to store the results from our previous solutions, so we'll store the result for S are up to but not including I in an array.
1:32
Would you be? And an important thing to notice here is that this is in the style of dynamic programming, that these problems overlap.
1:42
Basically. OK.
1:50
So here is our algorithm. So we're going to set end to be the length of the word.
1:54
And we're going to set WB zero equals true, because if it's empty, then trivially we'll say it's true.
2:03
And providing the den is greater than zero will now go through from I equals one up to end.
2:13
And so take successive values here. And so this is illustrating some stage of the for loop and we're going to compute WB.
2:20
Ah. So let's say that it's false. But we'll update that to true.
2:31
If we do actually find a solution. So then to actually do this for PI, we need to now a sub loop.
2:36
So going through from J equals zero up to a minus one.
2:45
So at some point J will be here. And then we'll be considering the portion up to but not including J.
2:49
Which is here. So and we're asking whether B J is true.
2:57
Okay. And then we're also asking about whether this portion here is in the dictionary.
3:05
So those. So, of course, the good thing is that David, B.J., we've already computed that because Jay is strictly less than I.
3:15
And so we don't have to. We've got that value. And then we just make a dictionary.
3:24
Look up for this slice here from J to eye minus one.
3:30
And if both of those happened to return. True. Then we will set W B I to be true.
3:37
And we can stop the Fali at that point. But if we go through all of them and it turns out that they they are all false, then we keep WPI as false.
3:44
And then once we've gone through all the way up to when we can finally return WB and which is the solution to the actual problem rest,
3:57
you wanted to answer? Well, it's even easier to see what the complexity is here again, because we've just got two full loops.
4:04
And so the complexity is order N squared.
4:12
Well, OK, so which is better of these two styles from the top down with memorisation?
4:24
I say perhaps easier to develop, but I think the top level recursive solution was a bit easier than the bottom up.
4:30
Non recursive solution, though perhaps it depends on how your brain works as to which you find easier
4:36
or how much experience you have indeed in writing solution to these problems.
4:43
And well, the top down world could be faster if not all the soft problems need computing because the thing is in the bottom up style,
4:48
you are forced to go round the four loops and so you may end up computing stuff that you didn't actually need from the bottom up.
4:56
Solution is the non recursive solution has the merit of avoiding overheads due to recursion.
5:07
Well, so just to sort of sum up this discussion on dynamic programming,
5:17
dynamic programming typically involves taking a problem that's gotten inspect supernaturally large solution space,
5:22
all the possible splits of this word into some strings and then finding a path to a solution in polynomial time.
5:28
So that is what dynamic programming is. That's the start of problem that dynamic programming is trying to solve.
5:38
And it might be just asking whether a solution exists as in the Hamiltonian circuit problem or the word brake problem,
5:45
or quite often it would be about finding the best possible solution, as when we were solving the travelling salesman problem.
5:52
Part of the dynamic problem programming style is that we have overlapping sub problems which we should contrast
6:01
with divide and conquer algorithms like quicksort or merge sort where the sub problems do not overlap.
6:08
And of course, the other thing is that to be efficient in dynamic programming, we need to store the results of the computation of the sub problems.
6:17
So just a final word on why it's called dynamic programming.
6:25
Programming here does not mean programming as in a programming language.
6:30
It's the more old fashioned sense of planning a suitable order or plan of computation.
6:34
So we have decided what all the soft problem is going to be that we're going to solve on our way to the main solution.
6:40
And in many cases, the same problems that we consider will depend on the previously obtained results.
6:48
And that is the dynamic part where we we we decide which next is the next problem to consider, depending on the previous obtain results.
6:54