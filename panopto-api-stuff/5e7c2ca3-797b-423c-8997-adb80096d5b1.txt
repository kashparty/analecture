ID: 5e7c2ca3-797b-423c-8997-adb80096d5b1
Title: DML&R - Introduction & Motivation
Category: Reasoning
Lecturer: Mark Wheelhouse
Date: 05/10/2021
Cool. So welcome, everybody, to this first lecture of the discreetness, logic and reasoning module.
0:01
It's quite a long way to run throughout both the spring, the autumn term and the spring term.
0:08
This year you'll be starting mostly this time with discrete masses by Stefan.
0:13
Barnacled, that'll be taken over by Alison Draw and the Lao who teaches logic.
0:17
And then next term, Sophia and myself again will teach you a bit about reasoning and how that can be applied to programmes.
0:24
So I'm not so sure as some of you yesterday away from the Jamesy room.
0:30
So Jamesy students were on site there. But please just come me to find the bit more information from the other lectures on this module in due course.
0:34
I think a portion of them could join me here this morning unless one of them is here, a shout out.
0:42
Unfortunately predisposed to other things.
0:48
So I guess the question is probably on many of your minds is what's this module about and why do we have it?
0:51
So what's the point in this module?
0:59
The content of this sort introduction lecture is to kind of go over that and try to give you motivation or a motivation
1:02
for why we use this call these qualities teacher's course as one of the first things you do in your degree here.
1:09
And so what I was going to go through history and look at a few interesting examples of where computer science is made, maybe a few small mistakes.
1:15
And I think about what caused those mistakes and how we might be able to avoid making such mistakes in the future.
1:24
And you're all here, but you're on the computing or doing computer science course.
1:30
You have basically to become computer scientists in your careers and lives going forward.
1:34
So we understand. What does that mean in some sense?
1:38
So kind of motivating this entire lecture is a quote from Kohala favourite quote, which is to air is human,
1:43
but to really foul things up, to really make a mess, you need a computer remote.
1:50
So what's happening here really is the fact that humans make mistakes.
1:55
That's fine. We'll make mistakes. We get Proofpoint, we type things wrong to chat or whatever.
1:59
But when a computer makes a mistake, it does it really quickly.
2:04
And the problem is that means it can make that mistake again and again and again and again,
2:07
maybe millions of times before humans spots that there's a problem.
2:10
Someone's looking at somebody at the bottom that when you say human error that
2:14
broke something on the computer just compounded it a million times over. And there's loads of examples in history.
2:21
Well,
2:25
we have to look at financial trading as a real risk that the code is wrong there and it makes a bad deal and then does it again and again and again.
2:26
You can haemorrhage millions and millions of pounds in just seconds.
2:33
So, yeah, when the computers involved, things can go wrong and go on very quickly.
2:37
So let's look at a few examples in history of when this happened and see if we can work out why that happened.
2:41
So the first one of these is called Sarac twenty five.
2:47
So this was a radiation therapy machine that was used in Canada, inherited a bunch of legacy code from previous Turchin machine.
2:52
And what had happened here was there was an issue with the system configuration.
3:01
That issue is actually possible to kind of treat patients supposed to be with a low dosage,
3:05
I should accept with a high dosage, in fact, in a few cases, lethal doses of radiation.
3:11
So three people died and three people were seriously injured by the machine being mis configured and
3:17
basically treating them with much higher levels of radiation as opposed to its ability to target radiation,
3:22
to deal with cancer cells, but not over your entire body.
3:26
So if you have a look at the diagram about the slide, you can see the problem.
3:30
So the system is set up to run in two modes. There's this kind of low current electron beam is used for treatment,
3:34
but the idea is to target that particular part of the body and targeting cancer cells and try and kill them off to run.
3:42
Then you can run it in a high commode, let's take X-rays and to do that, to make it safe.
3:49
The lead sheet with Clexane underneath the emitter to make sure that it diffuses the radiation so you don't get such a high treatment of radiation.
3:54
The problem was it was possible to fire the machine off in this setting high mode setting when the shielding is not in place.
4:02
And that's what triggered the unreasonably high levels of radiation some patients received.
4:10
So to give you an idea of how bad the problem was, the system was treating people with between 15000 and 20000 pounds worth of radiation.
4:16
The typical dose of that treatment should have been between 20 and 50.
4:25
So this is many, many, many times, almost a thousand times more radiation than should be targeted to people.
4:30
So the reasons went wrong really was various things,
4:37
but fundamentally the system wasn't tested very well or the system was carried out at
4:41
a system level of people who knew what they were doing using the system properly,
4:46
nothing was done. MODULA There was no kind of software validation of the hardware, particularly from here.
4:50
There's nothing in the software that told you that arm was in place or not,
4:56
as well as the system documentation was all at the time so that we used this machine going wrong bluescreen quite a lot and failed.
5:00
And so the clients got used to having to work through that.
5:08
And it meant that if there were messages that were ignored by most staff because they seemed to be needless and pointless error messages.
5:10
So lots of problems here in how that whole system played out.
5:16
And importantly, it killed three people and seriously injured three other people. Were the if you do giving this one, just be careful of the image.
5:19
Such there are some very graphic pictures of your breakfast will not be a pleasant experience.
5:26
So let's hop forward a little bit in time into the 90s,
5:31
so it's not much of one early 90s story set during the first Gulf War in Saudi Arabia and Iraq.
5:35
And we're looking at the Patriot missile system. So this is a missile defence platform deployed back to some places by the United States of America,
5:44
especially in an anti-missile system used to shoot down incoming missiles before they hit their targets.
5:53
In 1991, there was this particular incident where they failed to intercept an incoming Scud missile fired in Saudi Arabia and it hit our barracks.
5:58
I got a picture here of the aftermath of the barracks there that killed about 28 people and injured 100 people as well.
6:08
All soldiers. And there was a problem in the calculation of ranges of things inside system that says here is what was going on.
6:16
Here is actually was a tiny, tiny internal clock error used in calculating the time I was really, really small.
6:26
It's not a point. Not not not not not not not not not not in five seconds or ninety five nanoseconds to put that in human terms.
6:33
That's really, really small amount of time, impossible to the human eye.
6:45
The problem was the code that was used in this area was being run 10 times a second.
6:49
So this error compounded, built up upon itself more and more and more as time went on.
6:55
It's not too much of an issue.
7:00
The problem was the particular unit in question had been up for a hundred hours at the point the Scud missile was fired in Saudi Arabia.
7:02
And by that time, the error had built up to nought point three, four seconds.
7:08
So about a third of a second doesn't sound like a lot.
7:14
But in that time, a Scud missile travelled half a kilometre.
7:18
And that means it goes from outside the systems effective engaged range to hitting its target.
7:25
So the system saw the missile went off shoot you in a minute by the time you decide to shoot the missile down its target.
7:30
So you can see this is a very serious problem here. So the specifications of these units, the Patriot missile systems,
7:36
does say they need to be a new factor and they have to be turned off about once every 30 hours,
7:43
basically have a total of nine again within the system and see if that will solve the problem.
7:48
The problems have been a particularly intense period of Scud missile.
7:54
Attacks on the particular evenings happened and they just had no time off downtime it needed.
7:56
And that led to this unfortunate incident. So that was 1991.
8:02
I'm going to come forward a little bit further in time now to 1996,
8:08
so I imagine many people have heard of Ariane five is a famous space disaster disaster.
8:15
So what happened here was in 1996,
8:22
the maiden flight to the Ariane five rocket was the the new system that was going to put Europe really on the map when it comes to exploring space,
8:25
in terms of delivering stuff into orbit and maybe even making further flights beyond that later on and on the maiden flight of this thing,
8:32
sort of take off the entire shuttle or the spacecraft case exploded.
8:38
Thankfully, it was an unmanned spacecraft, but the workforce, a bulletin board and the entire platform is estimated without including satellites.
8:43
About 500 million dollars in cost was lost when this rocket exploded on the launch pad.
8:51
So what happened here was that there was a crisis slide.
8:58
There was a 64 bit number that was being used to be coming out of one of the sensors on the rocket,
9:02
and it was copied into a 16 bit buffer in the guidance system.
9:09
Now we all know what happens if you try and put something too big, something too small, you break the thing right.
9:12
You can't put 64 bits of information above overflows. You get an out of a message and the system crashes.
9:16
Don't worry, the scientists who built this thing very harmful.
9:24
Yes, we better make sure there's a backup system in case something goes wrong with this.
9:26
Rocket, unfortunately, is running exactly the same code as the primaquine system.
9:30
So the primary system fails, errors and gives up a backup system, comes online, fails for exactly the same reason it gives up.
9:34
Now, the rocket has no guidance system and a safety measure kicks in and says, OK, this is no longer safe.
9:40
Abort, destroy the rocket so it doesn't go flying off into some random populated area.
9:45
So the thing to me that even worse than enough already I know is that all the
9:50
code that was running had the error on it was being used for orbital mechanics.
9:55
Kind of adjusting, of course, wasn't needed at all, but the sensors were on still and therefore giving the errors through the guidance system.
9:59
So quite an embarrassing one. That one.
10:09
And fundamentally, again, this is kind of not doing some type checking like this is quite simple, 64 bit is not the same as some very basic type.
10:12
Checking your cable spot. This particular one. And someone looking at type issues.
10:20
But this will be the pilot, hopefully, as part of this. So let's come forward another year and see the 90s were not a good year for the computing.
10:24
Here we've got one of the probably a lot less known to people, generally not much.
10:36
Seven called the US, Yorktown, Yorktown.
10:39
So the USS Yorktown is an ace missile cruiser similar to the Patriot missile system.
10:44
This is another part of America's kind of anti-missile or nuclear deterrent missile shield.
10:49
And I have one of their ships without doing some manoeuvres back in 1997, and the entire ship shut down.
10:55
So then for about three hours and it had to be towed back into port because that's what they shut down.
11:03
Well, one of the crew members and zero into a database field of navigation, and that caused the divide by zero error,
11:09
crushing the entire machine's network of machines on the bridge of the ship.
11:16
So this puts a billion dollar ship at risk. Wasn't a training exercise.
11:21
This happened, but still it's I've been in a combat situation or worse yet, if if we need to to intercept a nuclear missile fired,
11:26
then that would have been a really, really much bigger problem than it was.
11:34
No one was hurt in this one. So the reason for the failure seems to be that the coach wasn't checking divide by zero, apparently.
11:38
If you look at kind of the reports around the area, the crew, a lot of crew,
11:46
social media talks about how this entire software upgrade they were doing at the time was plagued by numerous, numerous bugs.
11:50
Now, interesting to hear the official US documentation says there wasn't a problem at all.
11:58
The ship was only down for a matter of moments and came back to put under its own steam.
12:04
That's the official report and not what's leaked out on social media from the crew.
12:09
And the thing that I think makes it more interesting to contrast the official
12:13
report with that of the crew is that the software upgrade they were doing, they scrapped it entirely as a result of this failure.
12:16
So I'll leave you to judge whether you think the it was really offline for three hours or three minutes or so.
12:24
Yeah, this is basically failing to check about, which is something we hopefully all know that we should often do for right to use the basic code.
12:33
So then next one is called the Zun Screen of death.
12:42
So here, just pop over for a second onto the TV slide.
12:45
If you've got to meet up. If you can log onto Matamata, twenty one, ten seventy nine, five,
12:50
six dot com on any device, the voting, you should be able to vote on things like that.
12:58
Hopefully you can. Do it now. Wouldn't we want to start?
13:17
A little bit get feedback and see how people are doing, it is a massive on centimetre.
13:24
There's a few people that we used up doing what we said quite a lot of people seem to the of people haven't heard of them, but a few have.
13:27
Let's look at perhaps why that is. I wonder if people have heard about it, thought about it for a reason or the pragmatic reason.
13:36
So much of the same is December thirty first.
13:42
But we start of 2009 and you've just got a brand New Zealand player, which is a media player for Christmas,
13:46
and you're really excited to be using it for the first or second time. And you kind of turn it on and what happens?
13:53
The whole thing freezes up. You Collodi screen that never, never ends.
14:00
So let's see if we can work out what happened here. So what do we look at a desk checking of this kind of source code here is showing you
14:06
a sample snippet out of code that's inside the Zune player turned into a job code.
14:16
Very interested, and that's usually fine. But in some situations it goes wrong.
14:21
So I give you just a second to see if you can work out. Can you see where the code has gone wrong?
14:26
And. In a couple seconds, we will discuss why.
14:34
To this right? The second. So here is can you think about when the mistakes of the few different, uh, numbers are put in four,
14:42
five thirty six, seven, I got out of the car so you can see that as well.
14:59
I don't think we'll go back with that. Want me to put a slide?
15:12
No clothes, sorry. But. So you think the first numbers and so much of early voting returns in 60 seconds go back to the coquis?
15:19
So when you're looking at code like this, it's a good idea to play with numbers that are in or around the numbers you can see in the code.
15:34
So the important thing here, the numbers are being checked in these days.
15:40
Numbers, so we should think about what happens with different values of of days, so if you think of them, for example, they run through examples now.
15:45
Three hundred and sixty four is No. Then you can see your friends, but we can see that the world is days bigger than friends.
15:54
Well, this number clearly is smaller and we can see it when the wall is terminated here in Kurdistan.
16:03
So this can't be the source of any problems.
16:10
So in this case, with determination and we're all good and the same is true for three hundred and sixty five because again,
16:12
that's not greater than three hundred and sixty five.
16:17
An interesting case then it wasn't happening, scientists meeting on the big of a forensic file.
16:22
So two obvious cases. Three hundred sixty six and seven other things are plus or minus one of numbers that you can see in
16:27
your code or good kind of things to test and play around with just what you think about the forensics,
16:34
except in case perhaps give you a hint about where the problem is going to be.
16:39
So in the three to six or seven case, we come into the code, we say, is it Alicea?
16:42
I covered in blood from head very well. So let's not worry about the economy, the co-founder capital either.
16:47
So let's assume both cases. So if it isn't the no case.
16:53
The false case, then we're going to hop down to code down here,
16:59
we're going to decrement days by Forensic Files to add one to the air and you'll see that we end up, Ben, being in a case of a hero.
17:04
But we're in some some valuable days, which is less than or equal to sixty five to is definitely less expensive.
17:12
And therefore, the would certainly. So what happens when it is illegal in this case here, we say is 27, bigger than 13?
17:18
I guess it is that's going to be true. Yes.
17:28
So I'm going to document days by three hundred and sixty six will end up with a value of one year.
17:32
And then again, we end up back in the same place down here. So we go zooming in again at three hundred and sixty six.
17:37
Will we know that when the EPA says no, we end up down here in this case, the previous one,
17:43
this time with the value of one instead of two, doesn't make a difference. So what happens in the case?
17:49
Where is a leak? Well, we're going to decrements days, some days as a result of this 30 days.
17:53
Bigger than three hundred sixty six. Well, 366, if not bigger than four six.
18:03
So this is going to be a no, I don't know what happens.
18:08
What we skip over this branch of the if we don't do the LS because that's the other data.
18:12
So we go back around the loop again. We haven't changed the value of days at all.
18:18
So what happens is it goes back and Loop calculates. It says it's illegal.
18:24
Yes. Especially speaking because, you know, it goes round and round and round and round around.
18:29
And this is exactly what locked up all the same players at that particular point in time,
18:34
because we've just changed over at midnight into the start of a new year.
18:38
That was a leap year and the date number was exactly three hundred sixty six.
18:42
After a number of iterations we went to get into one day over the New Year.
18:47
So, yeah, a bit embarrassing, but a bit embarrassing.
18:52
So this particular one. So I think.
18:56
Yes, significantly. This is the screen down here that you see, and this is really before the day of the push, kind of live patches to code.
19:03
So that was what you saw for all of the first of January 2009.
19:11
So what a great present that was. I was going to do it the first of the year every single year.
19:16
So this is a big hit in consumer confidence. But this particular year,
19:21
it's probably one of the main reasons why the iPad and iPods ran out completely and stormed the market at the time over the months,
19:26
because this basically make us not trust them properly. So I have no idea how much that cost.
19:35
But think of all the potential revenue the Microsoft could have made from
19:42
having these players be more popular than they were from the start of things.
19:45
So, yeah, pretty embarrassing that one. So then a little activity can go back to the Mentone to a second.
19:49
Not here, but people there in the end. So which disasters do you think was the worst?
20:01
Uh. Up.
20:08
But I had results for a second, so just without talking to anybody else, without without checking on on the chart here or in other systems, whatever.
20:12
Just quickly vote for what you think the worst disaster was.
20:19
Of this, not so twenty five, the radiation machine, the Patriot missile system, which is the felt intercept missile, Ariane five,
20:24
which is blowing up USS Yorktown, shutting down its missile cruise ship three hours and Zun Scream of death was doomed, doomed.
20:31
The cold air where your kind of media player looks up the entire completely useless, basically a.
20:39
Let's see what people think this time around.
20:46
Something like that bothers. So we need to show those.
20:51
I think also so people have gone for what we often see here,
20:58
which is kind of picking the the same as the highest one because it has the biggest human casualty toll.
21:01
That makes sense. You notice I didn't give you any specification here about what worst means.
21:09
Someone's input depends on whether we talk about potential disaster stuff. Exactly. So there's a lot of different things.
21:17
So is anybody that voted for a different disaster rather than what?
21:22
To give me a reason, either in Chad or just about why they voted one day.
21:28
Just want a fair go around five or Yorketown. Brave enough to volunteer their reasoning?
21:33
Well, I didn't it because I think here the real problem, the war itself, not a mistake using the weapons.
21:42
Yeah, yeah. I think I've heard discussed before is that with the missile system, it's it's very sad.
21:52
A hundred people died, but those hundred people were soldiers.
21:59
And soldiers take on the element of risk when they go to war and they're out there being deployed, effectively signed up for this conscripted.
22:01
That's not how the US military works. So they've accepted some level of risk.
22:09
And that could be a reason why you would think that's not bad. On the flipside,
22:13
I was doing a couple of years ago arguing about how there are twenty five is the worst because those are patients they're expecting to get better,
22:16
not killed. So that's kind of the flip flop between the expectation of the service and the delivery is massively,
22:24
massively negative on what it should be in a situation like.
22:32
Likewise, I am fighting because I know it's how much information we lost in life being destroyed.
22:36
It's one of the more expensive disasters as well. In terms of what was actually lost.
22:40
The Yorketown could have cost more.
22:45
And again, if it happened, if someone had five nuclear missiles and it shut down because they're in a box at that point in time,
22:47
that would have been catastrophic, almost unforgivable. A mistake that one time.
22:53
Yeah, people seem to hear the first were bad because they're all designed to be. Exactly.
22:59
These are all things that when they go wrong, people get hurt and badly hurt.
23:03
I guess it probably is less bad. But other people, the process at the zoo, the most embarrassing one,
23:07
but it affects loads and loads of users and a really stupid way that you should have checked your code.
23:12
It's not hard to see that this would happen, just putting some value on a few values around whatever and see what happens.
23:16
What's really with the latest on what the F test is greater than three six six couldn't even get out in some situations, depending on how you think.
23:24
So, yeah, it's very embarrassing. No. So there's a lot of other opinions about this as well, um.
23:32
Of interest and. Slide, has that changed anyone's opinion on which disaster was the worst damage or what can be healed from sliding scale?
23:44
So you can kind of know more succinctly quantify rather than saying this one was the worst,
23:56
you can try and give me a sliding scale of which ones you think. You look at my school.
24:00
He will scream and we will show you the distribution of how people vote, what I would find in this particular one.
24:08
So right here, I think, between our campaign, whereas on the previous slide along the back of the picture, it was quite a way in the lead.
24:19
I think there's still a lot of economic sense. Now, technically, there's a lot of people down west or near the west as well.
24:29
So it's always fun to do this, but something then discuss it and then rebote to see.
24:38
Has that changed your opinion on how things stand? Cool, let me just switch off the mic slide, so here's the question, feel free to start the.
24:42
Have we learnt our lesson quickly? Go with the slide along as well.
24:55
What do people think? Landslide. Uh.
25:02
So people have said yes, mostly no, mostly to the people that would do better, a lot better these days.
25:09
So let's let's go back to my slide a second. And we will view perhaps the cold, harsh truth of reality.
25:18
So anybody here recognise this symbol? What's this relating to?
25:29
Heartbleed, yes. Excellent. Well done.
25:37
So those people are going to be hearing about this, so we hope you heard about this maybe on the news a couple of years ago.
25:39
Hopley was in 2014. It really kind of blew up.
25:46
So in a nutshell, what happened here was there was a vulnerability in the open SSL package as a security package,
25:49
kind of arranging how things happen on a server.
25:57
The idea was that users could ask for more data than they should be able to read when getting data back from a website.
26:01
So you could say, please give me my username from Edstrom or whatever service, but also give me the next 15 gigabytes database.
26:07
And because the username, that's a thing you will not have access to yet,
26:16
you can have that it didn't check to make sure how much data you go past the end of the field you're looking into.
26:19
So you can basically get all the data of many of the stored after thing you're allowed to access, which is a pretty serious security problem.
26:24
So that really shouldn't be a problem. I'm afraid there's a whole bunch more things as well.
26:33
I've written up so you can go throughout the two thousands, the most recent sort of five, 10 years or so.
26:38
So you've got the IRS go to file. That was a seemingly harmless extra go to file against SSL code.
26:44
And it caused in some cases you would actually skip over something that check to make sure you were using the proper ESTOS.
26:51
That means you could check PayPal systems into using a completely fake sales to figure and you wouldn't check it because of a stupid,
26:58
bogus thing and go to. The team so arguing that a bug in Android put all the blame on Microsoft and Apple here,
27:06
basically sometimes when you're doing sorting in lists here, you get an out of bounds exception on your right or your list.
27:15
Just a bug in the algorithm. Another fun one, Windows nine.
27:22
Whatever happened to Windows nine? We had Windows eight on it, but that had Windows 10.
27:28
Where didn't nine. So the story here is that apparently there was an awful lot of third party code that started with lines like if.
27:35
Uh, what phrase there if there's an.
27:47
Starts with. Chicken when someone.
27:54
In those nine. The idea is this was a catchall.
28:07
For Windows 95, Windows ninety three point seven, what in particular that were out there?
28:14
So these kind of two versions of the time sort of code was written out.
28:21
You know, Windows nine is enough to have the same behaviour, 95, 98, which are very similar criticisms at the time.
28:24
So that means that yeah, but it's not really Microsoft because it's all the third party code out there is a problem,
28:30
but basically, yeah, there's enough pain still.
28:36
You like systems out there from this. It really wasn't worth trying to fight this.
28:41
So just went straight to Windows 10 instead. Also, anybody heard about the Boeing seven free max MKC instance in recent years?
28:45
Well, this is a series of plane crashes, um, over over recent years.
28:55
Some of them. Yeah. A lot of people to crashes here.
29:01
I said, yeah, 46 people. It says in my notes.
29:05
So Nkosi's the manoeuver manoeuvring characteristics augmentation system, basically an anti stalling device on aircraft.
29:08
It was designed to basically spot if if the plane was climbing too high and then try to help
29:14
the pilot to push the nose back down so the plane wouldn't get to a stall and then pull out.
29:20
This guy sounds sensible. The problem was they relied on a single sensor on the nose of the plane to work
29:25
outside instead of the plane to work out what the elevation of the plane was. And if that sensor broke, then what would happen is the end.
29:32
Oh, no, you're going to stall and try and push the nose down and try and push nose down.
29:39
So even so, the pilots end up having to fight against the system and the system keeps triggering every five seconds, 10 seconds or so.
29:44
So you basically got to fight the aircraft all the way back to landing against this particular kind of motoring thing.
29:53
Try landing a plane when it's trying to push his nose into the bottom 10 seconds. It's really hard.
30:01
And it crashed a couple of flights because of this.
30:04
So, yeah, there's still some pretty serious problems in our software and our testing systems and our previous systems that are out there.
30:06
So I'm afraid we haven't quite learnt a lesson and fixed everything yet.
30:15
So hopefully you guys can can learn the lesson better and be better back into your careers in the future.
30:19
So there's basically. A couple of ways of going about trying to detect and deal with burglaries,
30:27
the two main methods of forgery, testing and proof verification, if you want to give it a different name.
30:35
So you're going to be doing a lot on testing yourselves, I'm sure,
30:46
and the various software engineering courses that you'll be taking over the
30:50
course of degree will also be looking into testing things like unit testing,
30:54
integration testing and testing, explaining what these things mean, testing small components, building up the whole systems as you go through things.
30:58
And there are some definite advantages to doing testing and testing, something everybody should be doing with the code, if nothing else,
31:05
for a few good input output cases and other cases,
31:11
and make sure that your pohnpei follows a lot of the Haskell exercises in the labs you'll be doing this time who have example.
31:14
Just make sure it could at least work on these five cases to give you an unfair round. Add your own test cases.
31:21
Testing quite cheap doesn't take very long. You can even make it be automated inside that sort of version control system with runners and whatnot.
31:25
You can make it happen automatically on your code if you do it right. It's incremental.
31:35
You can test small things, then test bigger things later.
31:39
It's usually quite, quite quick, but the issues are just because it passes the tests, that doesn't give you any guarantee of safety.
31:42
But I guarantee you all of these examples of people this morning, they have some testing on them.
31:50
Perhaps not now, but some testing was done and the authors convinced themselves that this is good enough.
31:55
It works perfectly fine. It's fit for purpose and evidently is right.
32:01
And I guess the main thing is there is the issue of complete coverage.
32:06
You're never going to get complete coverage of most input sets because there's an infinite inputs at any if it's free text, any sentence,
32:09
any any valid or invalid string of English words could go into the system, you might guess,
32:17
but perhaps you don't think you might get new characters to appear in the future. It's really hard to cover everything with testing.
32:22
So the other way of going about this is thinking about verification, about proof.
32:30
So the idea here is that if I've got a proof of something, I've got quite a strong I will guarantee you.
32:34
But that's definitely the case. And if somebody changes taxes, whatever, that's a new proof that they've changed the assumptions,
32:38
that the proof is based on the issue because they tend to be much more expensive in terms of human time spent or in terms of specialism.
32:45
But you need to be able to do proofs because it requires a kind of a strong mindset about magical thinking.
32:52
We are getting to the point where some people start to be automated.
32:57
They're automated therapy these days, and there are tools that will even try and do automated proofs of programmed correctness on Facebook.
33:00
Do a bunch of stuff now with a team code in 13 and check a lot of we have to use internally.
33:10
And now they're rolling out apps on the App Store as well to make sure they obey the specifications they've got with them.
33:17
So, yes, probably a good proof should be error-free, but of course, humans mistakes, it's never really said, for it consumes quite a lot of time.
33:24
A really good crew has the advantage. That leads to a deeper understanding of of the problem.
33:33
There are some lovely proof that there are things like Pythagorean Theorem,
33:39
etc. that really show you why these things work rather than just trust me, they work, which is quite nice.
33:43
However, there are some issues that are quite tricky to prove.
33:50
Anybody here hold head of a holding company. So the whole problem is basically, you can't guarantee me a given programme will terminate,
33:55
it's impossible to prove that and show you why it's the case.
34:06
So there are some things that terminal or other properties are really, really kind of undoubtedly complicated to prove or maybe even undecidable.
34:09
So you can't actually prove them. So you have to be careful what you want to prove if if you can call that direction,
34:17
because you won't necessarily be able to prove absolutely everything.
34:23
So coming back to in this module, why do we have this model, why do we do this stuff?
34:28
So in computer science, we want to be sure that a programme fulfils its purpose.
34:34
We want to know what it says on the tin is what it does and does that properly.
34:40
So the way that people approach this is basically backed by two things we need to specify specifications for our programmes.
34:45
What that means, we need kind of a crisp, unambiguous, the most important.
34:54
With way of describing the intended behaviour of the programme.
35:02
And that means we basically a language that we're going to do this in,
35:07
so you will find the discrete mathematics you can be starting from Friday onwards.
35:12
That really gives you the underpinning elements that you need to be able to underpin the forward thinking of writing specifications,
35:18
things like set theory and other function definitions, these things.
35:27
This all comes from discrete mathematics. And so that's going to give you the grounding, the basic fundamental.
35:32
You need to be able to build up business equations and the language that we write these in.
35:37
It's almost always logic, first order logic, but I'll let him come on that stuff,
35:44
what we teach and this is basically the language you can use to give these crisp and unambiguous specifications for our programme.
35:50
That's really why the first part of this module exists.
35:57
And then to go with that, we need a methodology for how we're going to do our proofs, wave our hands around,
36:00
we need to have a very clear and concrete way of of doing our proofs in a way that's believable, reproducible and understandable to others.
36:08
So. You have a way of how are we going to understand the programmes, codes, behaviour and its allies,
36:18
the code behaviour to get to a proof that shows us it does indeed satisfy the original specification, or maybe it doesn't.
36:25
So we can be doing this via a few different things, but fundamentally, it's mathematical proofs.
36:32
And that something is going to underpin all of is great mass contact to be doing over the next few weeks.
36:40
A lot of it can be underpinned by mathematical proofs and logic.
36:46
Again, stuff underpinning the soundness theorems and completeness theorem that show you that logic works and correct.
36:48
And you can trust it. Basically, we're going to extend these ideas of proofs with the idea of proof by induction or inductive reasoning.
36:54
Later on that be next. And this is so we can basically handle functions, in particular recursive functions.
37:05
Um, so we're kind of you loop around by defence, calling themselves recursively.
37:13
I'm also going to be then applying this reasoning about programmes. If you look at the old syllabus, if you go back in time and have the Web pages,
37:20
you'll see they used to be separate courses on this great maths, logic and reason about programmes.
37:32
We're not unified into a single stream of behaviour so we can get more more joined up thinking between these three different parts of things.
37:37
So we have to leave to leave it all over the map department, which lets you do small proof, the programme is quite a cool thing to play around with.
37:48
It's it to really, really fun to look Kevin Kevin every month.
37:56
But I think you should be very sorry to interrupt.
38:01
Yeah, sir, I have a question about it that may prove only a part of the programme, like the hour isn't part or we can like prove the whole programme.
38:05
So most modern proof techniques will come into this more in springtime, so we got a bit ahead of ourselves here,
38:19
but most techniques will allow you to do your modularly so you can basically prove small things to prove about the function,
38:26
prove that this class, this package, and that you can roll that up to bigger and bigger things.
38:31
The stuff we teach in this module later on with more about dealing with individual kind of functional programmes,
38:35
because actually you get a kind of scaling size issue with the logic we teach teaching this course when you go to big,
38:41
big systems, when you start using memory and application and whatnot as well.
38:47
But there are more details. But let's leave that until until spring time.
38:52
We'll come back to that stuff. That's OK. OK, thanks.
38:56
So got a few minutes left. I want to get over to my other little slide deck for a couple of seconds.
39:01
Sorry on that. Let's talk a little bit more about what actually is proof.
39:07
So to motivate this, we're going to look a little about supervillains, so let's assume that we have a few facts that are true.
39:16
So a person is happy if all their children are rich and if any parent myself very happy if the children grow up to be successful,
39:24
someone is a supervillain. If at least one of their parents is stupid.
39:32
And it always seems to be the way lots of these movies and kind of supervillains breed civilians as
39:36
they go down that down time of their lives and all civilians of which they certainly seem to be.
39:41
I mean, that they always have these money to the Megadeath places and secret space stations, underwater boxes.
39:47
So they must be rich there as well. So given those facts, can we show that all citizens are happy?
39:51
So I think about that for a second commitment to second.
40:04
Uh, no. So I'm looking at an English argument, and I want you to tell me if you think it's a convincing argument.
40:11
So here is my argument. All of the of children must also be supervisions.
40:23
Now, all civilians are rich, we knew that by giving three, which means that all of a sudden the children must be rich because they're citizens.
40:30
Therefore, any citizen is happy. So to a few people putting comments into someone saying.
40:39
What it have no children, so that's your case we would want to think about going forward.
40:55
Some celebrations, happiness.
41:03
That's of kids, yes, maybe so the children is interesting, but actually having no children, any formula is a lot better than you would see.
41:05
That would kind of be a vacuous I not have no children that way about them being rich, automatically happy.
41:13
Make a presumption in order to bring I'm down. I mean, it's it's one of the assumptions we're making to this statement.
41:21
So anybody who's going to get to meet anybody said, well, I think. The argument is not convincing.
41:33
So we go to next slide. So people saying no, well, people are saying yes, but quite a lot those.
41:41
So where is the floor then, can anybody vote for whether I think the floor is.
41:48
So right now, the four main lines of four main steps of this informal truth.
41:54
People are. People say, well, OK, I guess, I guess that makes sense.
42:07
Because he's someone who has got the point I'm hinting at here, but let's let's back over to the slides then and we'll get a little bit further.
42:19
So here is kind of a situation, a model for this set of rules that I'm using.
42:30
So we've got here we've got group grew with the supervillain in which it doesn't look very happy.
42:37
And we've got his children, Edith, Margo and Agnes, who we're assuming for this particular model, are all rich as well.
42:44
Inherited richness with it. Why not? They all seem happy.
42:52
So. First of all, is this a counterexample and the answer is yes, let's say maybe grew the.
42:57
And that's what gives you the hint about what the problem is. Is that is a good person to go back to the statement of facts here?
43:09
So the person is happy, all of the children rich. But I never made any relation between supervillains and people.
43:20
So it needs to be basically an extra assumption out here that families are considering in this are going to be people.
43:32
I hope that makes some sense. So. What we kind of see, we kind of need because some people with the argument before,
43:40
is he pretty much somewhere formalised, don't worry about this too much are going to come into this later on the course.
43:51
But this is the way that we would formulate Zogby, including how to handle this missing assumption.
43:56
I think it gets easier to spot the problem here because we had these properties to talk about sibilance.
43:59
I just talked about a person, and we have no way to relate supervillains and people,
44:05
and so we stop for these things jump out at you that are more obvious about the problem, about the lack of relations between the.
44:11
And if there were no children, then what would happen is this entire support they would get vacuously.
44:21
But that's something to think about. Let's go back to our we have dealt with a lot of the content here.
44:26
Yes. I'm going to give you a taste of where things are going to go so quickly.
44:32
Turn it back into English. You need to add the assumption that super is also a person to the system to get something we could then improve.
44:38
So the steps you ready to go for them? He is talking about, yes, what the children, something that one's fine and more importantly,
44:46
what if parent and child are medical things to think about the other people making other points in the chat as well.
44:56
So this is more just an example to think about why we need to formalise things a bit more.
45:01
I showed you one formalism in first of all, you will be getting to later this term.
45:06
Don't get too worried about exactly what those different symbols and words mean.
45:10
Yet that's going to come because all I can say is you're going to get to the point where you can do proofs like this in this style here.
45:13
It looks scary, but actually this isn't that complicated. You have to do this kind of thing within a few weeks.
45:20
So that's using a technique known as natural deduction, which will learn logically.
45:25
And then you can also use a style we use a bit later in the reasoning about programmes called semi structured proofs,
45:30
where I can kind of give all our assumptions are given us what to show and then walk through the proof one step at a time,
45:36
trying to relate different reasons. But don't try and internalise these.
45:44
Now, I do have an informal reading of this proof in the form that I will share with you later.
45:47
But for now, just know that these things might look scary, but you will be there by the end of the spring term for sure.
45:53
You'll be able to do this by the end of this term, maybe mid next year with a little bit if it looks scary.
45:59
But don't worry about have stuff. So the main thing I'm just saying.
46:05
So what are the aims of our efforts? Why are we doing Proost? So we want the only proof that is the only proof.
46:09
Things that are true but can prove something is not true. I've got a really big problem.
46:16
I had to prove only by the things I want the proof to be easy to read and check just
46:20
after I've written them so I can make sure I didn't make mistakes in my own proof.
46:26
I want proof that are easy to read and check when I come back to them may be months or weeks or years later,
46:30
so I can still be convinced by my arguments sometime in the future.
46:37
And more importantly, I want to that other people can be able to easily be in check, potentially decades,
46:40
decades after I finished watching this proof so that people can believe the proof that I've done.
46:47
And going to drive a lot of motivation of what we're going to be doing in how we approach our approach during during this module in discrete maths,
46:53
logic and reason all the way through how we approach these things, a good proof,
46:59
ideally as a gives some intuition about why the argument holds as well.
47:04
That's not always easy to manage. And there are plenty of groups out there, things like vocality and whatever the process,
47:09
sometimes automated an automated hand control machines, and that doesn't tend to lead to much insight.
47:15
Unfortunately, the true machine of the true insights maybe lost.
47:20
So some really good process will kind of give you a nice intuition about what it's worth.
47:24
The lovely Protagoras using the tiny square, but also dogmatic.
47:29
It's one of the best things I've ever seen and it just shows you what's happening if you love the way of looking at things.
47:33
And can I put you up for doing more of these kind of things or more work games?
47:40
I'll leave. You would think about we're not going to get funded that time. It but happy dragons.
47:47
You can look at this one and try to figure out how would you try and fix one
47:51
on this one does have all of the assumptions you need to go and do a proof.
47:54
You can do it informally with name words.
47:59
And once you learn some of the language of discreetness logic going forward, then you can maybe come back to this and try and do it for me.
48:03
It is, in fact, in some of the best sources, I think, at the end of logic and of the reasoning part, because so hopefully that all makes sense.
48:09
I want to stop that because it's ten to, I'm sure. Got time to break before your next session.
48:20
I can take a couple minutes questions. Anyone has to think that I've got to get up to a second talk in ten minutes as well.
48:24
So five to I have to leave this call with any quick questions. I'll happily do a couple of things now.
48:29
Have you enjoyed that? Can I ask on the last slide, you said we only proves the Palestinians.
48:34
Does that mean that we will never prove that things are wrong? And if so, what do we do then we can prove that things are wrong.
48:42
That's fine, too. But any statement, my proof has to be valid.
48:49
So if I say yeah, if I prove that Tuesday is the day before Wednesday, I should be able to prove that with enough assumptions about how things work,
48:53
I shouldn't be able to prove that Monday is the day before Sunday because that's not a valid statement.
49:03
Right. So I should be able to get to if I can deduce that, then something's wrong with my logical proof system.
49:09
And that's a theory that means anything out of that system is now questionable. And I can't do anything.
49:13
Just give me. Concepts of validity and viability.
49:18
This will come during a logic course later on.
49:24
I'm going to give you some titbits now about where we're aiming for and why we have this much of what we care about these things.
49:26
And pardon me. You said you're going to upload your notes later today.
49:32
Well, doesn't it include those annotations? Did the statements that slides with some further description?
49:36
I think everything that I've annotated is included. Description of double-Checked was anything.
49:43
I can upload these as well. But I think most to me,
49:48
highlighting stupid things are probably not necessarily the text of the is going to have a lot more in it than what I've spoken to today.
49:50
There's more expert reading this mix to follow up for all of the disasters that links to follow up on references and what not.
49:57
And for all the ones I briefed, the modern ones again, this hyperlinks to go look at more detail,
50:03
but I want go for them financially to look into and to try and understand why they went wrong.
50:08
I guess that would go up in Santa later today. I got a pretty busy morning until about 1:00 dealing with second year stuff.
50:14
So this afternoon, this evening, I'll try and get this uploaded for you so you can disable the planet's.
50:20
I have a question about just how we define the valid statement, because I heard that, like into your geometry,
50:30
like we sometimes we have some theorem and w we can some theorem, we can still make the whole system work.
50:38
Yes. A big part of having a balance system is that it's based on assumptions and there are small things that you kind of have to start with.
50:47
There are some things you have to assume some basic elements and changing times will change your system.
50:55
So things like the assumption that one is primes is not rinzai is really important for a lot of very high levels of mathematics.
51:00
And so you have a system we don't care about, one being prime breaks, little stuff that makes it very, very hard.
51:12
Likewise, there are other systems to do with counting infinities and things where you look
51:17
at all the natural numbers and one zero and there's a big debate about that.
51:21
So, yeah, it makes a difference. The stuff we do in this course is hopefully less controversial than any of those things.
51:26
But here is what A is. And we'll build everything from set theory on which I believe in logic.
51:31
This year should be covered by being grounded in theory as a way of understanding what logic means.
51:37
But we have to be a set of of kind of fundamental assumptions or axioms you have to start from.
51:43
Otherwise you can't get going. OK, thanks.
51:49
I'm going to stop that because I've got to get to my next session. I hope you enjoyed that.
52:01
I won't see you on this course probably until spring term.
52:05
So I have a great time with Stephane and Alessandra and allow and then I'll be joining in.
52:09
The springtime is going to be looking down at your reasoning about programmes,
52:15
be looking at how we reasoned about the Haskell programmes you're writing from now onwards,
52:19
how your reasoning about the job programmes is writing in spring term as well, and anything a job can be applied in terms of reasoning.
52:24
So have a good time. I hope you have a break and start your term.
52:31
We didn't do a lectures with Tony. Coming up, a great natural love of learning.
52:35
I have a great passion for high school because of how we teach it so that students have a great day and enjoy the course.
52:39