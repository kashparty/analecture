ID: 9ebefe74-0231-4e36-a0c8-ae2f010b70d6
Title: Java - 2022-02-01
Category: Java
Lecturer: Alastair Donaldson
Date: 01/02/2022
OK, I think it's about time to get started. So everybody, thanks for coming today.
0:23
It's nice to see some people. So my name is Nick Wu, and I'm here to teach you the sort of, I guess,
0:29
the second part of the Java course, which is about concurrency and it's about data structures.
0:35
So for those of you who are online, the camera doesn't seem to be working,
0:40
but hopefully you can hear the audio just fine and you'll be able to see the slides as well.
0:44
And if one of you could choose online, maybe you could unmute and say hello.
0:48
Then I'll know that I can cases because somehow you know, hello, a voice from the heavens.
0:52
Thank you very much. OK, so yeah, let's get through this course.
0:57
I guess I should start by saying about myself, So I my research is in programming languages, in particular functional programming languages.
1:02
So I'm the kind of person that's behind things like the Haskell course that you do that in your first term.
1:11
I'm sorry about that at the end, but but I have been a programmer in the real world as well, so my first job was as a Java programmer.
1:16
And then I also spent some time in C++ programmer, amongst other things as well.
1:24
So I know a little bit about how these things work, too. What else can I say?
1:27
I think that's probably all you need to know about me. I just wanted to start with some of the aims of this course and what we're attempting to do.
1:32
So basically, this is to start with.
1:39
This is an introduction to concurrent programming, which basically means how do you programme where you want more than one thing to happen at once?
1:42
So what you want your computer to be able to maybe download a file as well as present things to your users,
1:49
or maybe that will sit down to two files at once, or maybe input things from the text, as well as from some guideline as well as read files,
1:54
etc., etc. So if computers are permanently doing lots of things at once.
2:02
And so how do we achieve that? Well, that's exactly through our programming. We're also going to talk about things called threads.
2:06
So threads are a way of achieving programming in Java.
2:13
We're going to talk about race isn't race conditions.
2:17
So this is what kinds of things can go wrong when you're doing programming and synchronisation problems.
2:19
Again, similar these are synchronisation films are ways of solving races and race conditions,
2:25
so using tools like exclusion and locks a way to avoid things like that.
2:30
So that's roughly speaking where this course is going. That's that's my goal for this week.
2:35
The way I'm going to find stuff to things is we're going to cover a lot of the concepts
2:40
in this lecture and hopefully do lots of hands on programming in the next lecture.
2:43
And the next time I see you, we'll start looking at something completely different.
2:47
So abstract data types. And then we'll come back again to some advanced concurrency and then some more and more abstract.
2:50
So it's a bit of swapping back and forth.
2:59
And the reason we do that is to just give you a baseline of understanding on some cool concepts before we go in deeper on the more complicated things.
3:01
And hopefully, you'll be able to reinforce those core concepts in your tutorials.
3:07
So that's that's how I would try to structure this. OK.
3:11
So I wanted to start the lecture with some counting.
3:15
Actually, that's not true. I want to start the lecture with some households. So my house rules are quite simple.
3:19
I'd love it. I'd love to interact with you. I'd love to speak to you.
3:24
So if you have a question, I absolutely want to hear it. So please just raise your hand will to speak out loud.
3:28
Everything is welcome. I've also set a timer to go off at about twenty five minutes and twenty five minutes time,
3:33
which will be a signal to me to calm down and stop and let you guys have a rest.
3:40
So then I'll give you three minutes to rest and do anything you like.
3:45
You can leave the room, you can come back and do what you want, and after this three minutes,
3:49
I'm going to start off full speed and we're going to just do that like four times, I guess, because it's going to be game over in two hours time.
3:52
So that's that's roughly how I would do this.
3:58
Usually, I give you a little sheet of paper to give me feedback live so people tend to have questions that they want to ask.
4:00
And I felt like, I mean, usually I cut them out and give out, and I thought like distribution of bits of paper is almost like distribution of viruses.
4:06
And that was such a good idea. So but if you do have things that you want to say,
4:12
I guess you can just come and tell it through one of the three minute breaks or write it down or put your hand up or something.
4:16
Just be brave. OK, so let's start with counting. I presume you all know how to count.
4:21
So this is a programme that does some counting for, as you might imagine, this is maybe counting the number of people use tweets and things,
4:27
number of tweets coming through a server every minute or every second or something.
4:37
What is it doing? You've got a class.
4:41
The class is called counter, and I'm hoping that Ali's got you up to speed with Java syntax and idiosyncrasies at this point.
4:43
Could a private integer counter? So this is privates to this particular class, I would set it to zero to start with.
4:50
And then we've got this method called run. Have you seen run before? No good.
4:56
So run is the method that we're secretly going to use later on when we do thread things,
5:01
but for now, you can just think of it as being an ordinary method.
5:08
It's not mean, so it's not the method that kicks off the entire process, but you can think of it as like.
5:11
So this is just called run. What does it do? It starts with an index called count or couldn't, and it goes for AI from zero to a million increments.
5:18
And then it makes that counter Sante become the couch itself.
5:28
And then the county calls sanity plus one. All right.
5:32
What does this programme do? It just counts up to millions. Very easy.
5:37
And then you can imagine that we do something that gets counter and that returns the counter at, well, good.
5:40
All right. Nothing special here. This should be very, very easy.
5:44
Ali probably said something like Nick is going to do the hard thing, which is concurrency.
5:49
And so this is where things are going to start breaking now.
5:53
Concurrency is hard because while there's a lot going on and you need to understand lots of different things since then,
5:57
how the concurrency is going to take place. But so we can modify the example we've just seen to add concurrency,
6:03
which means that we're going to have two separate threads running at the same time, and we haven't defined threads yet.
6:09
Like to add, these two threads will run at the same time in parallel, and they're going to basically both run that code.
6:15
So the idea is, if we want to just keep on counting, hopefully each thread is going to count up to a million.
6:23
And so because they're interacting on that same that same counter.
6:30
Cold counter. The idea is going to be that they count it to two million.
6:36
So the two of them together should count to. That's the hope. So here is the implementation of that idea.
6:41
So you've got a class called the concurrent counter.
6:48
It extends the sequential council, which is the code that we've just seen and it implements runnable.
6:51
So that implements runnable is magic that tells Java the JVM that you want to be able to create a thread out of this particular class,
6:56
that this class is somehow special and it's going to be run on multiple threads at the same time.
7:04
So let's look at the main method does. The main method says, I'm going to create a new current counter.
7:10
I'm going to make two threads once called T at once called you and notice that we start new threads with this counter inside it.
7:16
So counter is going to be the concurrent counter that we've just created.
7:24
And then what we do is we don't start and then you don't start.
7:29
So at this point, what's going on is you've got a main thread which is executing and it's going to encounter that line to start.
7:33
That main threat is going to say, OK, I need a new thread. It's called T. I'm going to create it off.
7:41
You go, you start doing your work and then the main thread can continue while that thread starts doing what it needs to.
7:46
When does it start command? It's going to run the run command that we defined earlier on.
7:54
So it's going to go through that code and run is just special and distinguished in that way.
7:59
But the main threat to carry on while Ti starts doing its job, and it's going to say you don't start.
8:04
And so now you has been spawned off that it's going to do its work as well. At the same time as T.
8:09
So right now, Maine is executing and Ti is executing and use executing.
8:13
We've got three threads running concurrently. What we have next is this tri block.
8:18
Now have you seen try blocks? Brilliant. So it's going to try to do this block of code.
8:24
And if something goes wrong, it will catch the error and then pull out. So what's it going to try to do?
8:30
Is going to do t join and then you join. What would that do?
8:35
So one thing that one way that I like to understand how Maine is working good.
8:39
I also have no pens. So one way to understand threads.
8:47
Apologies to those of you who are online and unable to see this. I'll keep my diagrams on the board subminimum.
8:56
I'm just drawing a horizontal line, which I'm labelling man and then I'm kicking off with a dot on the line and I'm going to go.
9:01
That's to stop. And that Fred is just doing some code.
9:10
Who knows what? And at some point it rejoins me. We can call this thing to join.
9:16
And what's going to happen is Maine is going to start and then it's going to wait,
9:24
wait until joy and Maine will only carry on once that he has actually joined Maine again.
9:29
So you can think of this as the lifeline of T its thoughts here. It ends here.
9:35
When it joined back with the Maine, the second process, you start off the tee.
9:39
And that can do whatever it likes. And I'm deliberately making it messy. Unless you don't join.
9:45
OK, so as far as Maine is concerned, it's going to carry on as soon as you both finished their work.
9:52
And as far as you're concerned, they can get involved in this terrible mess of who knows what and controlling that mess is the goal of concurrency.
10:00
OK, so. Once we've done the joint, you have this catch command, which says if something went wrong, just print out the stack.
10:10
Hopefully nothing's going to go wrong because this is a very generic way of catching an error.
10:20
And then finally, we're going to print out the counter. Great.
10:25
Any questions about this code? OK.
10:30
And so the way it framed it, if I were to say who thinks it's going to output two million,
10:35
I hope none of you put your hands up because you should be really suspicious, right? But you've got a question.
10:40
But you're suspicious about something going wrong. Yeah, exactly, and something will go wrong if we execute this thing.
10:46
I want to. Yeah, I think I would like to have a look at intelligence now, so hopefully.
10:52
Let's try and zoom in. So here is the code that we've just seen on the slide.
11:03
And what I'm going to do is I'm just going to execute it a few times and hopefully I'm going to start with the sequential counter,
11:08
which is the first example. No tricks up my sleeve on this one. This is just the ordinary thing where there's just one thread running.
11:15
I'm going to execute this through and see what happens, so I just click on play.
11:25
All this code is online. There's a repository. I'll give you a link later on that you can have a look at.
11:30
But hopefully. Oh no.
11:35
I say hopefully it's going to return a sensible number,
11:40
but that's because I haven't actually run the right file, so that's run the sequential counter.
11:43
And, OK, so you can see just about down here that the number two million has come out.
11:49
If I were to run that again with the sequential counter, every time a press play, it's good to come out with this very, very tiny two million.
11:55
So everything is behaving as we expect it to. All right. Now let's look at what happens when we look at the code.
12:03
That's the concurrent counter. That's the server here. I want to look at the concurrent count code.
12:08
I'm going to press play. And what's happened this time, lo and behold, there actually is a problem.
12:14
This thing has output the number one million, and that's a large number.
12:21
OK, so some no, that's not two million, in fact, I think it was even 20 million.
12:28
So there we go. So something's going wrong and it's gone wrong by almost a factor of two.
12:32
This is pretty terrible. So why?
12:37
Why? What happens?
12:41
And it's a completely unfair question for me to ask you because I haven't told you anything about how the JVM works or how any of this works.
12:42
But does anybody know anybody? Guess what, why this is going wrong?
12:48
But why is it possible that both of the object of both of the threads are tried to write on the same object?
12:56
Yes, they are indeed both trying to flex? And why would that be a problem? But yeah.
13:02
Yeah, maybe they're trying to right at the same time. Is anybody want to expand on that?
13:15
Any ideas? I'm going to do. Yes.
13:19
Yes. Yeah, that's great, yeah, sounds like you've got start to the issue.
13:34
So the the issue you described was you've got two threads running.
13:41
One of them reads the variable. The other one also reads the variable.
13:45
So they both think the variable is at 42 and then one of them starts incrementing that variable and increments it a lot.
13:49
So it makes it a million. And the second goes, I'm going to commit it a little bit to forty three.
13:56
The person goes, I'm going to write my million into memory stuff. It does not finish my task.
14:02
I go home now. The second task goes, All right, I'm going to write forty three to the counter.
14:06
Now I'm going to write for people under forty five and it's going to count up.
14:11
We've missed out on a whole bunch of numbers in between from the other process.
14:15
So that's the thing that's gone wrong. And you can see the catastrophe that we have here. All right.
14:19
So that is the problem statement as way, but hopefully interested, at least in solving a problem.
14:23
I haven't given you any motivation whatsoever for why we would want to do this in first place.
14:30
So ice cream is always good motivation. Let's start with that, right?
14:35
OK, so. I want to just get some, some Tums straight first, so I can give it to all this time.
14:41
I mean the. There are two times that I want to just distinguish, so one is the term concurrency and the one the other one is parallelism.
14:51
So you'll often hear people mistaking these two terms, and it's good to just be a little bit careful about what we mean.
15:02
I will also mistake these terms, so I'll try and catch me out if you can.
15:06
But concurrency is sometimes also called logical. Parallelism says that we have the competition of independently executing units.
15:10
In other words, you can imagine these two threads running at the same time or concurrently.
15:18
And so they're both doing these actions. There are two parties trying to do something.
15:24
The result of these two parties, or like the interleaving of their actions, is not deterministic.
15:30
So we can't choose exactly what order, who does what.
15:35
We know they're going to each do like a sequence of commands one after the other.
15:39
But how they interact, which one goes first? Well, that's up for grabs.
15:43
We don't know exactly who gets to go when. So that's what concurrency is, and parallelism is sometimes called physical parallelism.
15:47
Basically, it's about being efficient with your computation.
15:55
It's about two or more parties getting together and trying to resolve something more quickly.
15:58
So, for instance, if you're to sort a deck of cards, you give half the deck to your friends.
16:03
They sought their help. You sort your half. And then you hopefully merge them together to get something sorted at the end.
16:07
That's how we did it. But anyway, the outcome of this should be deterministic.
16:12
So even though you and your friend have both sorted the cards individually when you merge it back together again,
16:16
the artist should be the same as a sorted deck of cards, for instance. So whatever you do, the outcome should be roughly the same,
16:22
even though that could have been some mess in between and who knows exactly how they did and how you did, it could be completely different.
16:28
The outcome should be the same to some degree of granularity. So concurrency without parallelism is possible.
16:33
So in the old days, they used to be single core CPUs, and they were able to do what seemed like different tasks.
16:41
At the same time, they could open a file and at the same time, remember where in the programme you were and then get that problem and this thing else.
16:50
And then it felt like they were being concurrent. But actually, there were single threaded, so there was no parallelism going on there at all.
16:58
The joke is JavaScript script seems to show that concurrency is possible without parallelism because lots of things are happening concurrently.
17:04
But maybe it's no faster than if you just did it on a single call.
17:11
But yeah, so just because you've got concurrency doesn't mean that things will necessarily be faster.
17:14
Another reason why things might not be parallel is maybe you're not actually making your process any faster by splitting things up.
17:20
Maybe the cost of communicating with your friend and merging your cards at the
17:27
end is just too expensive for you to actually achieve any real parallelism. And then the question is, is this part of the current say?
17:30
Well, it's a bit grey, OK? And parallelism without concurrency is also possible.
17:37
And this is quite a contentious issue. You see people the internet saying, No, it's not possible, can't be done.
17:42
You need to have concurrency and all that have parallelism.
17:47
That's mostly true, but it's slightly false because your CPU has something called a sims instruction,
17:50
which means in a single instruction, it can do like four editions at the same time.
17:56
So is there parallelism going on that desk because you've managed to execute four editions at the same time as a single instruction?
18:01
I don't want to sing on a single on a single core. So there was concurrency.
18:07
Sorry, there was parallelism, but there was no concurrency. Any questions about that, especially the latter point to some of you, are probably going.
18:12
So he's got it wrong. That's not how it works at all. OK.
18:19
Very, very quiet. OK, so let's carry on. So this course is about concurrency.
18:25
We're going to try to learn how to do more than one thing at once with no hope of making anything faster.
18:32
OK. So the benefits of concurrency?
18:37
So why on earth would we want to study concurrency in the first place?
18:41
Well, so the first reason is abstraction, so we can separate different tasks without ordering their execution.
18:45
So we ought to be able to say, for instance, I will download these files of here and you don't want to have to wait one for the other.
18:51
Logically, it doesn't really don't really care what order they come in. You just hope that it happens.
18:58
You don't care which one finishes fast, you don't care if they go at different speeds. You just want to get all these files at once.
19:01
So you just want to not worry about these details. The other is responsiveness.
19:06
So it would be terrible if you didn't have concurrency in your system because when you typed in a
19:12
key to wait for whatever the computer was doing right now to finish before that key was received.
19:18
So let's pretend that your computer is multiplying some large matrix and it's going to take five seconds if you start typing in those five seconds.
19:24
It's not going to respond. Those key processes are going to wait on a queue when it's finished doing its job.
19:31
It will look at those and carry on. That's not what happens to the computers. Why?
19:35
Because somebody thought about concurrency, OK? And the last one is performance.
19:39
Well, I said earlier on the parallelism without concurrency is possible,
19:44
but it's jolly useful to have powers with concurrency, and that is the main mode of parallelism that we tend to consider.
19:49
So in terms of performance, that's the way to go. So we're just laying the foundations for some cool code later on.
19:56
And then there's the the new more Moore's law.
20:03
So for about 60 years, there was this thing called Moore's Law, who's heard of Moore's Law?
20:07
That's very good.
20:13
So Moore's law states basically that the the size of transistors on on your chip have reduced by a factor of two roughly every two years.
20:14
So basically you can cram in twice as many cores and a physical piece of hardware every two years or so.
20:25
The result of that is that your computers are getting faster and faster, so they're roughly doubling in speed every two years, which is wonderful.
20:33
Except that Moore's law stopped being quite so true at around twenty seventeen.
20:39
So we're still getting things and becoming more efficient, but not because of transistor sizes or getting any smaller.
20:43
So we're getting down to the point now where they're like crazy small.
20:50
And the physicists are saying, Guys, this is as far as we can push. We don't have to do any better than this, right?
20:53
So why do we care? Well, it used to be the case that if you were a sloppy programmer and your code was really slow or you
20:58
needed to do was just wait two years and your code got twice as fast and everybody's machines.
21:07
And so you would be very happy with that.
21:12
So if you get to play the old classics like Wolfenstein 3D or Doom when your computer, now you need to throttle your machine.
21:14
Otherwise this thing run too fast. But in the old days, you had to wait. So Moore's law was fantastic, but we can't rely on that anymore.
21:21
So what are we going to do? Well, we paralysed. We now have multiple cores stuck on a single chip.
21:27
You might have noticed like Apple's new M1 cause I'm on chips have like eight cores and two fantastic and all the rest of it.
21:33
Well, that's going to become the norm.
21:40
You guys are going to be programming in a world where each computer has loads and loads of cores and you need to build to control that,
21:42
that that complexity somehow. So I hope there's enough ice cream for now.
21:47
What time is it? OK, so.
21:54
I need to split out so terminology. The way to slow me down is to ask me questions and then they won't be quite so painful.
21:59
So terminology, I want to just get on with some some words.
22:06
So what's the process? Why on earth am I talking about processes in the first place?
22:13
So to understand concurrency, we need to understand how processes work and how processes can be split up into what we call threads.
22:20
And when I say understand how they work, we need to understand a bit about how the life,
22:27
the life cycle of a process looks and what kinds of things happen inside your computer when you're executing code.
22:33
So a process is an independent unit of execution.
22:41
Your operating system, whether that be Linux or Mac or Windows, is in charge of controlling the processes that are running at a given time.
22:44
It launches them and it controls their resources and the other kinds of things that you consider to be an app.
22:52
You're running these different processes. Well, each process is characterised by an identifier, so the process is given a process.
22:59
No, usually that number starts at one, which is the initial process.
23:07
And then that initial process forks off all of the other processes.
23:11
It's a different thing, so there'll be a process that looks after your file system. Another one looks after your network.
23:14
Another one eventually looks off to your window manager and looks after your key presses and so on and so on.
23:18
So all these processes get kicked off when you launch your computer.
23:23
So by the time your computer is up and running.
23:27
So if you look at your activity monitor and your machines, you'll notice that you're all like processing over ten thousand or so.
23:31
So lots of different processes have happened, even on a fresh reboot.
23:37
So that's basically one process happening for each programme that's being run and spun off.
23:41
So this process can look at themselves and say, which process? No am I am.
23:46
I am not a no, I'm a process anyway. Each process also has a programme counter.
23:49
So what do I mean by that? A process is basically some code, and it's that code is being executed one instruction after the other.
23:55
And so you won't be able to say, well, which line number of my own when I'm executing. And so that's what the programme story.
24:02
Each process also has its own memory space.
24:09
So it is a place in memory that is allocated, but it's allowed to use for variables and putting information.
24:11
And the operating system sort of guarantees and says, Look, I'm going to give you some space.
24:18
And usually a good operating system will say, I'm going to limit how much space you can have because if you write too much stuff,
24:23
then being too greedy in the computers is going to crash.
24:29
Sometimes that memory space is just unbounded. It just depends on how how the operating system is implemented.
24:34
Usually, when you're programming in something like Linux, you can type in a command called the You Limits Command,
24:41
which just says how much resource you want to limit on this particular process.
24:46
And actually, you can limit not just the amount of memory that it uses.
24:50
You can also memory limits the amount of time so processing time that the process is allowed to use.
24:53
That's a pretty useful thing. The memory space that belongs to process really belongs only to that process.
24:58
So other processes don't by default, get to know about that memory space unless you're living in the 90s,
25:06
in which case there are all kinds of cool hacks you could do. But that's no longer the case.
25:12
So usually these things are isolated by the by the operating system, and you can count on that being your private area for doing whatever you want.
25:15
How then, do processes communicate with each other? Does anybody know that? Yep.
25:25
Yes. Yes, so there is a way of getting shared memory. There is something called it.
25:35
That's right. So shared memory in schools and pipes of the main methods of doing things.
25:40
There's also, I guess you could use like files so you could just communicate on the file system
25:45
as well as you could write something right into a file and then another person, which step by step complex.
25:52
So in Linux, yeah, the abstraction is that everything is everything is a file or everything is a pipe, depending on who you ask.
25:59
And so the way that Linux has been set up is they've tried to make it so that process communication is relatively easy to use as the programmer.
26:07
So you will have encountered things like steam and the outs, the standard instant standard error.
26:14
Those are examples of pipes. There are also examples of files, and it's tough for me to stop very shortly.
26:19
But the idea is those things is that as the programmer is concerned,
26:27
the programme doesn't have to worry about whether the files or pipes or who knows what.
26:31
They're just things that you can write to and things that you can read from. And that abstraction just makes your life a lot easier.
26:35
So I promised you three minutes of respite, so I'm going to give you three minutes on the clock.
26:40
You can do whatever you like and talk amongst yourselves, etc. In three minutes, we'll.
26:44
People are confused about the terminology.
26:55
Ah, yes. So I get it right in this current economic climate.
27:03
I would love to answer that question in front of everyone. Would that be OK?
27:12
I would love you to ask that question in front of everyone so that we can. All right.
27:15
OK, let's do that. Yeah. Yes.
27:19
Probably not right now. But yes, I will definitely go over that.
27:26
I think about it. The comment on that. Oh yeah, that's a really good point.
27:31
Yeah, I will certainly do that. I'll do that in the I'll give you a slightly bigger break in the next one and then I'll do that.
27:35
I just like. We do have this pretty.
27:41
Yes, I will put them up in the next and I was like, Oh yes, we'll just.
27:48
Typekit. Yes. Yes.
28:12
Yes. Is a real.
28:19
No permanent damage.
28:57
I think what makes difference?
29:04
Before example. So that's like, why is it?
29:21
What would you ask that when we start, let's go to.
29:41
Yes. OK, that's time up.
29:50
So let's get going again. So where was I was talking about processes and memory?
29:58
A couple of you had some questions in the meantime, so I think you had a question when asked about the spa.
30:04
OK, so the question was what's the difference between parallel and concurrent? For one another, get closer to launch control tower.
30:15
Yeah, absolutely, very happy to go again so that if we can answer the questions, the question was what's the difference being concurrent and parallel?
30:27
So concurrent just means that more than one process can happen at once.
30:34
So when you've got two independent processes or threads running and they can do different things, well, that's concurrent behaviour.
30:38
So they're both doing something. So it's sometimes called logical parallelism.
30:46
And the idea is that it's like if you observe them both doing things in which to write down who's doing what time.
30:50
It's not deterministic. Who does what, when. So you're not really sure which ones executing at which point.
30:57
But you know that they're both slowly moving through that code.
31:02
The idea of parallelism is the idea that you can execute a task more quickly with the help of others.
31:05
So that's got nothing to do. Well, it's a separate concept of concurrency per policy.
31:14
Right, it's about can we together achieve our common goal of making something go faster?
31:19
It's very often the case. The parallelism is implemented using concurrency.
31:25
So two threads, each of them working together to get a thing done.
31:29
That's the normal way of things. So you'll see people internet saying you can certainly have concurrency.
31:33
So it's certainly a paradigm with concurrency that's easy to see. Some people say, actually, you cannot have.
31:39
Concurrency without power. No thought to the way you can have concurrency without power isn't concurrency without power.
31:47
OSM is where two processes are just working on completely unrelated things.
31:53
They're both working at the same time, but they're not trying to help each other. They're just doing two different things.
31:57
That's concurrency. Parallelism is when two people try and help each other as they try to progress.
32:02
And so you might think the only way of achieving parallelism is with concurrency because you've got two people working on some stuff.
32:07
But actually, the instruction is an example where there's only one person working is just able to do two things at once.
32:13
Parallelism is occurring, but only in a single process. It's a slightly eti-osa.
32:19
OK. Are there any does that kind of question gets anybody else to ask any more about that if we move on to the next?
32:23
Yeah. Yes. What?
32:31
Yeah, that's a great question, so the question was on the on the topic of shared memory,
32:43
what stops a naughty process from doing naughty things and reading other people's bits of memory?
32:48
Well, as I was alluding to in the 90s, nothing stopped any processes from doing that, and it was really easy to hack computers.
32:53
It was fun, too.
33:01
But these days, the operating system has been designed to be very stringent and to give a particular range of addresses to particular process.
33:03
And in fact, it even goes further. Usually, it kind of abstracts away,
33:13
so you don't know exactly which part of memory you just know you've got memory range from zero up to some bounce and you can write in that.
33:16
And how that actually gets mapped onto in memory in real memory is the operating system business, and you don't get to see that.
33:22
And if you try to do something cheeky like write to a negative offset because then you'll get up to your day in the operating system goes No,
33:28
no, no, no negatives allowed. You can't cheat, right? So this kind of sounds that like.
33:35
Absolutely, yes. There's a lot going on when you launch process in your system, it's taken care of memory mapping,
33:48
it's taken care of paging out your processes, all sorts of stuff.
33:54
Stuff is happening. We're going to touch on that just a little bit in about half an hour or so, although this is not an operating system, of course.
33:57
So we're not going to go into as much depth as I'd like to, but hopefully just enough to give you a basic understanding of what's going on.
34:04
Look like a picture.
34:11
OK, so your question was, why did I have to put a try catch block around this joint seems like nothing could possibly go wrong.
34:20
Right? Good point.
34:29
So this is slightly code hygiene. We don't know whether or not he is going to run out of memory and just go, I'm out of memory, out of bounds.
34:33
Exception. Something has gone wrong.
34:41
We don't know whether or not you're a perfect programmer and whether you've accidentally made something that's going to have an exception.
34:44
So do you have a division by zero in there somewhere? I'm not really sure. So we can't.
34:49
I mean, maybe that wouldn't trigger an exception.
34:53
But yeah, but if it gets thrown, it's going to get propagated up to the top level and then who's going to deal with it?
34:56
Well, the main threat has to do with it. So this is the point where Main Street goes, All right, what do I do with this?
35:04
This is exactly the exception. So this is what we isn't exactly what we call defensive programming, so why do we bother with things like this?
35:10
Well, because some great programmes aren't perfect and buggy code does exist, and somehow we need to deal with that.
35:16
And so this is how we deal with that. Yeah, you really ought to.
35:26
Yeah, absolutely. So we're going to see a couple of examples of this in this course, but really,
35:35
you should be thinking about what could go wrong and especially when you're spooning
35:39
up another thread where you might not have control over what's going on there, you should definitely do this, this kind of programming culture.
35:43
Yeah. Good question. So in a module or in a library, should we be doing this thing like there is such a thing is becoming too paranoid
35:50
and having electric hatch around every single thing that you're importing.
35:56
I can kind of imagine a world wide programme like that that is like a unit of trust at some point, but at least with threads.
35:59
I think the best also there is you don't know whether that's going to run up memory.
36:07
These are really good questions, and this is where I think we sort of step out of computer science, where I can give you like clean,
36:12
hot answers and we're kind of into software engineering territory where it's like, well, it's too complicated for us to analyse.
36:17
We need to use some nuance of understanding and trust.
36:23
So if it gets embarrassing, what I would say that like it was like, Oh no,
36:27
you've told me it's one of these like really extreme zealots because my view is like, isn't that awful that we build bridges and we build skyscrapers?
36:34
And we would expect engineers to do the maths work out loads better intolerances, make sure that it can actually carry cars or have elevators,
36:44
or that you know, the maths should work and the software engineers what you do, you're like, Oh, you're 14.
36:51
That means you can use intelligence and then go ahead and make the software that's going to go on and everybody's aeroplane that we both die.
36:56
I mean, it's just this is how I feel about it, and it feels like it's just it's too easy to make good to make software that works well enough, right?
37:02
It's not very easy to build the bridge and convince people to drive over it.
37:11
Thank goodness it's very easy to make an app, send it to the world, and everyone goes, Oh, cool, I'm going to use that.
37:14
And then suddenly that satisfies my self working. Because anyway, I'm not paranoid.
37:19
I'm just saying. Right? So motivation, we've done that.
37:24
OK. I think we've done this on this technology.
37:30
OK, operating system and cause process. So what I want to do now is I want to just walk you through the lifeline of a process so
37:35
that we can have some stunning shots of understanding how interacting processes work.
37:45
OK, so this is called the so-called two state model because there are two states, there's the waiting state and there's the running states.
37:49
So this is basically I should have like a global top left there that says this is where we start.
37:59
This is what you say to the process you say to the to the to the to the colonel.
38:05
So it's your operating system. I want to make a new process, please. And admits that process and it starts off in a waiting state.
38:10
So basically, your your operating system is just sitting there.
38:19
It's got lots and lots of processes all hanging around and it gets to decide which process has a go on the CPU at what time.
38:22
And it's going to start off with everybody waiting. And then it picks process and it says you're allowed to have some time on the CPU.
38:29
Lucky thing and the process goes away and there's lots of computation so that that process of going from waiting to running is called a dispatch.
38:35
So your CPU or your operating system will dispatch a particular process.
38:44
The process is running away very happily doing its work and then suddenly and arbitrarily, the operating system can go stop.
38:47
I'm going to interrupt you. Somebody else's done.
38:56
OK, and you have no control as a process to when that's going to happen.
39:00
It could happen at any point and your state will get saved, put to one side and then somebody else is going to have a go at processing.
39:04
And then at some point the CPU is going to through the optic systems and go dispatch,
39:12
it's your turn again and you have to just it will pull back into memory everything that you had before as before, and you can carry on processing.
39:17
As far as the process is concerned, nothing ever happens.
39:24
It's like I fell asleep and woke up again and didn't realise I was right.
39:27
So the only way it could possibly know that something had happened is like, look to the clock or something like that, right?
39:31
It doesn't say it doesn't get told something's going to happen.
39:37
It just literally gets swapped out. And back in again, you could question the fact that the process is over.
39:41
That did not. Yeah. OK, so you can modify the priority of a process does come out and called the nice command.
39:48
And how nice the processes is, how much love it's going to get on the processor.
39:58
So I guess it is possible, but you don't get to control exactly when you're being scheduled or not.
40:02
The only way to do that would be to use embedded hardware.
40:10
So like at the hardware level, if you're actually controlling what's going on, that's where you get things.
40:13
So. And what I'm talking about, by the way, is sort of this kind of woolly and it's not very well, let's say,
40:16
defined as the real word, but like people will have different terminology for the kinds of things I'm talking about.
40:26
So you will see slight alterations of the names. So it's good to just think of this as like, these are the concepts.
40:30
It's partly because we've got lots of different models of what's going on in your operating system.
40:35
And the reason for that is that there are different operating systems out there that
40:41
have made different design choices about how these things should be implemented.
40:45
So what I'm telling you is like the standard assumptions that say, and then you will find deviations from all of this.
40:48
So it's good to just have a standard model in your mind and then be like, Well, this is probably what's happening on this machine.
40:54
Although you may find that when somebody comes up with a new device on a particular operating system for that device,
41:00
all of these things could be wrong. Right? So just just bear that in mind.
41:06
OK. So that's called the two states model. So we've got admit we've got this patch makes you running while you're running.
41:10
You could finish and you exit, which means that your process is finished. OK. I'm labouring over this because it's going to get.
41:17
Interesting. So here's a problem. Dispatch processes might be waiting for something.
41:23
So what do you mean by that? Suppose I'm a process and I'm happily running and I say I'm going to open a
41:31
file and I'm going to wait until it is fully open before I start processing,
41:38
so I wait for the file. But let's say I was like 20 terabytes big and it's going to take half an hour to open.
41:43
So I wait and it's my turn on the CPU and I've got nothing better to do other than just wait.
41:48
That's kind of sad. Right? And furthermore, maybe I get put into the waiting queue and somebody else does lots of work.
41:53
And then at some point I get asked dispatch again and I like what I wake up and my process still isn't finished and I'm still waiting.
42:02
So what a complete and utter waste of time. So that's kind of the problem.
42:08
So we can update this to the so-called three states model of of the operating system.
42:11
So the three states already running and blocked. So what happens here whilst you're running?
42:21
You could say, wait, and what wait says is I'm going to wait for something.
42:27
Now, when I wrote, Wait that again, there are lots of different names for that that could be triggered in lots of different ways.
42:32
But the idea is that you're waiting for some resource, usually for input from the user.
42:37
Maybe it's for the printer to start printing. Who knows what you're waiting for some resource to free up?
42:41
When you do that weight, you go into the bloc state and you're no longer on the running state,
42:48
which means that the CPU can be busy working with somebody else that's been dispatched
42:54
so your operating system is going to take care of changing your status to be blocked.
42:58
And it's up to the operating system to decide whether or not the CPU should be busy, right?
43:02
Usually it will be busy, so it's going to take some of the process.
43:06
Once you've finished being blocked, let's say the file finally has been downloaded,
43:10
or maybe the key press has been entered or whatever it is, the operating system will notify that process.
43:15
It will say, Aha, I know that you were waiting for this particular resource to free up.
43:22
I'm going to wake you up now because you don't need to wait for that anymore.
43:26
So you come out of block state and into red states, you're not yet running.
43:30
But the point is that when you get dispatched, you can start working straight away.
43:35
You don't have to sit around waiting for stuff to happen. Hopefully that makes sense.
43:38
Any questions? Right.
43:43
So now there's a new problem, new processes might be larger than memory.
43:48
So. Although we've got huge amounts of RAM on the machines, we still seem to not have enough.
43:55
And it might be that your computer has run out of RAM. And yet some process is setting out to spawn new processes.
44:00
Want lots and lots more memory? Lots of competition? What are we going to do?
44:06
In this current model, every time somebody makes a new process, that whole process has to be allocated into memory,
44:11
which it could request a lot of memory and it has to be ready, and it might be that we don't have enough memory for all the processes that we want.
44:18
So we've got like this idea of virtual processes, things that haven't yet been started but have the potential to be started.
44:26
And that's a shame because actually, you only really need a thing when you need a thing, right?
44:31
So you could have it like being created. And then when there's just enough memory, that's when you that's when you pull it in.
44:35
So it's kind of like, please create this process when you can, and its operating system is going to keep a track of what you want done,
44:43
but it's not actually going to start spinning up the process. That memory is not going to get allocated at this point.
44:50
It's just a promise that it will happen later on. So we update this model.
44:54
Oh no, there's another problem. Another problem is the process might want to inspect the output of a child,
44:59
so processes spawn off other processes and a trial process will do some kind of computation.
45:07
And then when that process is finished, it's going to say I'm done and my exit code was and that gives a number like forty to sixty three or zero.
45:12
And that number tells the parent process what happens. So maybe there was a failure, or maybe it was a success.
45:20
But the point is that the parent process needs to be able to often what's able to observe what happens to the child process, what kind of stated exit.
45:26
Now in this model, as soon as you're finished running, you exit, which gives nobody the chance to actually look at what your state was because
45:33
you're no longer in the car like you're no longer in the operating system. So we need to fix that.
45:40
So this means the next model we have is the so-called five state model.
45:45
So here we distinguish two new states created state in the Terminator state.
45:50
So the creative state is basically saying, I am a process I've been created, but I have not yet been scheduled and ready.
45:56
That means I haven't yet been allocated any memory. I haven't been promised any resources yet.
46:04
I'm just sitting there waiting to be executed when the operating system wants me to.
46:09
And so as soon as there's enough space in your in your RAM to actually load up this process, the operating system says good.
46:13
I will admit you now you're ready to go. And then you can start processing.
46:20
Similarly, with the Terminator process, a process a child that has exited is going to sit in the terminated state until the parent says, All right.
46:24
How? How did it go? And then you can say, Well, it went very well. Thank you.
46:36
And then off you go to Nevada, right? So that's how it works. So then we still have a problem, which is that blocked processes take up memory.
46:40
Right. So we've talked about blocked processes, and I've said that what they do?
46:51
A question. Yes.
46:55
Every process has a parent, except the initial process in it, whose process it is.
47:03
So does that answer the question when it exits?
47:09
I'll talk about that in a minute. So there are some new authors there as well, but we'll get that.
47:14
We'll get that question. You went first, so I can't quite hear focuses on multifamily.
47:18
Are. Is the parent, so the question is the process in a blocked state when it's waiting for the.
47:28
I think the answer is yes. So it does the weight command and then the CPU will do the apprentice and we'll schedule it into blocks
47:38
and then you'll get given the given the information and put back into ready and then you can go.
47:46
Yes. Although I'm saying that with hesitancy, because it sort of depends on your operating system.
47:52
So I'll just say yes. Normally, the difficulty.
47:59
Mostly, yes. Yeah. I can only be sketchy with these because it's like, OK.
48:12
Oh, there's a question online voice. Yeah. So if there is obstruct a crit Charles tribe and Charles Tribe Great Charles Red Sea,
48:21
and then he is terminated before C and C becomes a monetarist state or something like effaced,
48:32
you know, there's no way that A. I know the state of play.
48:43
We talk about that. So what you've so let me just explain your questions, make sure I've got it.
48:49
I think you'll envision a scenario where you've got three processes A creates B and B create C and B is terminated.
48:54
So what happens to C, right? Yes. Right.
49:02
And and the interesting thing that happens here is if sea exits, there's no parents to ask it, what's going on?
49:06
So what now? And this has got a funny name. It's called the zombie process.
49:15
So sea is called the zombie process. It's a process that sort of is waiting to be asked how things went.
49:20
And it will never get asked. And so it's kind of really strange.
49:27
So that so that can happen. So you might in Linux, notice every now and then the process is marked as zombie.
49:31
That's what it means. Does that answer your question? Yes, thank you.
49:37
OK, so the problem is block process to take up memory, OK,
49:43
so we talked earlier on about processes of being blocked, so it's waiting for something to happen.
49:47
Now let's suppose that that process is really huge.
49:53
It's like Google Chrome and it's waiting for a download to finish and it's like three gigabytes big.
49:55
It'd be a shame if whilst it's waiting, it took up all the space in residency in memory.
50:00
OK, so what we can do is we can hope to have this idea of putting it to one side where it's not taking up my memory.
50:06
And that's exactly what the six state operating system goes like.
50:13
So there are these things called suspended statements or suspended processes.
50:19
So this is a blocked process, but it's also suspended,
50:24
which means that rather being live in your RAM, which is the very fast, very easy to access memory,
50:28
the process gets put into some sort of longest storage place, so it might be even written down into your hard drive whilst stuff happens.
50:35
So that's basically what a blocked, suspended process does.
50:45
So in order to get a blocked process into suspended mode, the operating system says Suspend.
50:49
And then after a while, it might say activate and put it back into my memory. So something that I don't know if you've covered.
50:55
Have you done any hardware, architecture or anything like that yet? I presume not.
51:00
Something that you might not know is that there are different levels of memory with different characteristics of how efficient they are.
51:06
So you've got your CPU, which is where all the processing actually gets done. That's the fastest part of your computer.
51:16
And next to your CPU, you have something called cache, sometimes called L1 L2 cache,
51:21
which is basically local cache or small bits of memory that are very, very close to your CPU physically and also very, very fast.
51:26
Fuel CPU to access about 10 to 100 times slower than that is your RAM.
51:33
So you'll RAM sits nearby and it's accessed through what we call the bus.
51:39
And the information that the CPU is using can sometimes cool off to information that's in the RAM.
51:43
The L1 L2 cache will be sort of copies of the RAM that needs like fast interaction.
51:49
So then it gets kind of shoved off into the RAM for other life variables that can't currently executing.
51:54
So whenever you create a variable in Java, like an integer character, what have you?
51:58
Usually you can think of that as being in RAM. So it's just executing memory much slower than RAM as you hard drive.
52:03
And that's going to be, for instance, a solid state hard drive,
52:09
which is again 10 100 times slower than your RAM and slower still would be like a magnetic tape drive or like a spinning disk.
52:12
And that can be another 100 times. And as you kind of like, go to the slower and slower, you're able to store more and more information,
52:19
but it's literally orders of magnitude slower than the stuff that's close close by.
52:26
And the reason is simply, it's expensive to have hardware that's that fast will post your CPU.
52:32
Putting something to block state making it suspended is basically saying, I don't need this to be such high priority right now.
52:38
I'm going to put it to one side in a slower part of the computer in slope of memory.
52:45
As far as the process is concerned, it's got no idea that it's been turned to the slower mechanism.
52:50
But that's what's going on. Yes, yes. But.
52:54
It's like. So again, just like every previous plastic, yes.
53:01
Oh, I see, yeah. As far as the process is concerned, it has no idea that it's been suspended.
53:10
So its entire memory, everything about it is being suspended, built like this one suggests.
53:15
Oh, I see what you're saying. OK, yeah, that's up to the operating system to decide it.
53:24
Probably not. So the process of suspending and activating is expensive.
53:28
So usually you see this on your activity monitor in your computer, your you have a certain amount of RAM.
53:33
And what's going to happen is you're going to fill up to that ramp and anything.
53:44
If your RAM is still got some empty space, usually you can assume that things that are blocked are not being suspended.
53:47
So everything is just live in memory when your computer starts going really,
53:54
really slowly and it starts saying, actually, I've got physical space is much smaller than a logical space.
53:58
That's because I'm paging out processes, putting them into a much slower, like,
54:04
hard drive backed piece of processed memory and doing that so that can carry
54:10
on with some processes because you just go you run out of actual physical.
54:15
But it does happen, but you will probably notice new features when it starts getting really, really slow because you've got too many processes open.
54:18
And that's usually because your computer is literally copying that information out
54:24
into the hard drive and then swapping in some stuff to do some work and then going,
54:28
OK, and it's excellent, then copying too hard drive again, copying about file drivers around the work.
54:32
And so this is very, very bad, right?
54:36
And in the old days you used to have like you could actually listen to your transistors humming and you could tell when this was happening.
54:39
These days, you just gets hot, right? Same problem.
54:46
A suspended blocked process should be notified. OK.
54:51
What does this mean? Imagine if you were processing your block and you're waiting for a file to be loaded, but you've been suspended.
54:55
Now, suppose that file comes in. What needs to happen?
55:05
Well, your CPU or your operating system will have to remember that this particular file to you has come through,
55:10
and I'm going to have to tell you to notify once you've been scheduled.
55:16
Right? So once you've been activated.
55:19
So what's going to happen at some point you go from block suspended state to block state and then you get notified and then things and carry on.
55:21
Which is a bit of a shame because you could have been notified or if that state could have been changed whilst you were being suspended.
55:31
There's no reason to wait for that to go back into memory. Right. So finally, we achieve the four five, six seven to seven state process,
55:37
and this is the pinnacle of mankind's developments in operating system technology.
55:48
So here you have the ready suspended state, which means that you're ready to go.
55:53
You're not waiting for anything, but you are suspended.
55:58
So if you were to be activated, you're not waiting for any resource and you can kick in straightaway.
56:01
And that means that there's a possibility of a message going to block suspended process
56:06
that says notify and changes at state to being a block suspended ready process.
56:11
OK. Yes. Yes.
56:17
OK. How does something get unblocked, so I guess you're asking, how does it go from blocks to ready?
56:30
OK, so. Usually that's just going to be there's a bit in the there's a bit in the programme account with something that's basically story,
56:37
whether it's blocked and that flag will get changed by the operating system.
56:46
It's as simple as that. Yeah. So you're not yet executing, so you're not running on the CPU, but that bit has been changed.
56:51
Yeah. Why do you need the two OK to suspend?
57:00
I see one arc from block to block suspended. And that's ready to ready.
57:07
Right? So suppose you're a blocked process, but not suspended.
57:13
I need a way of being able to suspend you. But suppose you're a ready process, you're not waiting on anything.
57:17
I still need to suspend you as well. So these are two different cases of processes both need suspending.
57:22
One is ready to run. The other one is waiting for a resource. Exactly, yeah, that's right.
57:28
So you can just think of suspending is just like it's off to one side.
57:37
As far as the press is concerned, it doesn't know about what's going on. But it is in a much slower, much slower, but much bigger part of memory.
57:42
All right. Yeah. Suspended at the.
57:51
It's a function of those things, and it's also a function of which algorithm has been implemented by a particular kernel.
58:05
So it sort of depends. Yeah, yeah.
58:11
In Linux, you can probably configure how that's done.
58:15
And so people will do sort of qualitative analysis to see like what's a good mix of when to do the things like which,
58:18
which algorithm is the one that works well. And yeah, that's yeah, you'll cover this in the operating scores.
58:25
Anyone else? OK. Oh, yes, so this is what voice from above asked us about.
58:34
The problem is that the parent might not have inspected the child state yet, and so the voice told me it was possible that that could happen.
58:42
This was the ABC problem that we just had.
58:49
And indeed, we can have we can think of the terminated state as consisting of zombies and zombies that have been ripped.
58:51
I did not make this up. So a process that has exited, but that has not yet been inspected by its parent is called a zombie.
59:00
And then once the parent applies the weight, you reap the zombie and then it actually gets taken away from the operating system altogether.
59:09
Okay, so this is like a true picture of what's going on in the system.
59:17
Yes. Think that.
59:22
Yes. Yes, so it is only the parent that can wait for the child.
59:32
And once it's finished waiting for the child, it's got. It's not like real life.
59:36
I have to write, I think, is everything that we need to do.
59:47
So yeah, so it can ask questions, please do.
59:52
Yes. OK. So it's like it's only exit a code of a zombie process.
59:57
Why we need to like hold the whole process in the terminate his dead.
1:00:04
So I got interrupted by my alarm off again. So I mean, it looks like it's the only important thing of a zombie process is the access code.
1:00:10
But why we need to keep the whole process in the memory. You are only capable access exit code.
1:00:19
That's a good that's a good question. Hmm. I actually don't know how to answer that.
1:00:27
I think that the child process resources might also get used up.
1:00:31
Might also be inspected by the parents, but I'm actually unsure on that point, but I suspect that's probably why.
1:00:36
OK. Yeah. OK. My alarm just went off, which is a great time to stop,
1:00:43
so I'm going to give you six minutes now because it's been an hour, and so then we'll start off in six minutes again.
1:00:48
What kind of. I was so excited about that speech.
1:00:59
I thought it was something like that was, I guess, one of the most powerful nation states.
1:01:39
You know, so it's a little bit of what I want to ask you.
1:02:40
I guess that's.
1:03:14
Yes, that's right. Yeah, that's awesome.
1:03:26
Yes, I hope so.
1:03:45
I guess it will be one of those things like that.
1:04:01
Oh, that's so cool.
1:04:32
Yes, that's right.
1:04:53
I mean, it's like we heard so much about taking something I don't want to.
1:05:05
And that's why I'm so careful.
1:06:30
OK, we're going to start again, so as usual, there were a couple of questions during the break.
1:07:30
Let me put the alarm on for the next half hour. So.
1:07:37
Any questions from the break? Yes.
1:07:43
So let's take a look at some of the findings.
1:07:47
Yes. Yeah. I would give it a go.
1:08:00
OK, so the question is about how to interact when one is a parent process and one is a child process and the child process exits.
1:08:06
So let's run this through. So we've got two processes and b so as the parent, B is the child and process B as terminated.
1:08:16
So that means Process B has done an exit. They've gone from running into zombie mode.
1:08:24
Right? How does the parent interact with that zombie?
1:08:28
That's the question. I think so. What the parent does is that parent will probably be in the ready state.
1:08:33
Let's say it gets scheduled. So it's been dispatched into running and then it's going to do a wait.
1:08:38
So the wait would be, for instance, my diagram on the board main.
1:08:44
The main threat is running away. Right. And here are two child threads.
1:08:48
They're doing the business. And then here we set to join.
1:08:52
So you can think of that joint as being a weight because the parent that's the main thread is waiting for T to join its waiting for T to do something.
1:08:56
When T has exited, it turns into a zombie. And at some point the main process goes back into being goes back into being running.
1:09:05
When it hits this line, it's doing weights and it gets blocked. Then the operating system realises that the child has done an exit.
1:09:15
And so the operating system says to the parent notify and so the main can carry on to the next instruction and so on.
1:09:23
Does that make sense? But any other questions? OK.
1:09:31
I think there was one, but I can't recall what it was. OK, go ahead.
1:09:37
So, all right.
1:09:44
That was not an extensive discussion of how processes live, OK?
1:09:49
That was a kind of a very small place. This is why concurrences hot.
1:09:56
And what I want to talk about now is something very related but slightly different, which is a thread, so a process.
1:10:00
These things that we've just been talking about all along can also be turned into or may contain many threads.
1:10:10
And so each thread is, you know, it's part of a process.
1:10:18
It lives inside a process, so has an identifier.
1:10:22
So you are thread number of many threads inside this process.
1:10:26
It itself has a programme counter,
1:10:30
so you have different threads within a process that can be executing some code and having different positions in that code.
1:10:32
It has a memory. And in fact has two versions of memory.
1:10:38
It has local memories. That's memory that's local to that thread, but it also has access to global memory.
1:10:42
That's the memory that's available to the process as a whole. Now,
1:10:48
the difference between a process and a thread in this sense is that whereas we had this discussion early on about processes being
1:10:51
managed by the operating system and the operating systems in charge of how much memory the process gets to see with threads,
1:11:00
it's not up to the operating system anymore. It's now up to the process to manage this resource.
1:11:08
It's up to the process to do what it wants. OK, so you can do you're in charge of that memory.
1:11:13
So if things go wrong, well, too bad it was your fault. Mm-Hmm. But thankfully, that's what the job of that virtual machine is for.
1:11:19
So the Java Virtual Virtual Machine, or JVM, has had some very clever people implementing that for you.
1:11:25
So you don't have to worry about that side of things. So the memory is going to be allocated and shared in a sort of reasonable way.
1:11:31
OK, so that's the idea. And oh, and threads also have a priority within the parents, but that's similar to the processes as well.
1:11:38
So that's that part. So this was the five state diagram four processes which you now know and love.
1:11:47
And this is what thread states look like.
1:11:55
So I want to just go back and forth. It's basically like the five state diagram.
1:11:59
But what's happened is the ready and running states are going to go back and forth a few times,
1:12:03
so they're ready and running state that is getting turned into runnable.
1:12:08
And you'll notice as well that where it said blocks on the bottom left hand side that there are now three different things that could happen.
1:12:12
OK, so let's go through this diagram carefully. You'll notice that I've changed from having lowercase to uppercase names.
1:12:19
The reason I've done that is very pragmatic. These are the enum values that are in the Java documentation and you've got a question.
1:12:26
OK. So this corresponds to the terminology that's in the JVM now.
1:12:36
So this is where I can start saying things that are probably more true than they were a second ago.
1:12:40
OK. So the JVM threads do not get to see whether or not they're ready, awake, ready or running.
1:12:45
So they have no idea whether they're running right now or whether they're ready.
1:12:55
They just have no idea, but they will be marked as runnable right now.
1:12:58
So that's that's as much as they get to see on the block side of things.
1:13:02
There are different kinds of blocks states that have been implemented in the JVM,
1:13:08
so you can either be blocked, which means that you're blocking on a resource.
1:13:13
That's usually because you're blocking on some kind of file that you're waiting for or as we'll see and and a little bit of
1:13:17
time because you've you're waiting for a lock to be unlocked or because you're inside what we call a synchronised body.
1:13:26
We'll talk about that later. Another reason what you might be blocked is a so-called timed waiting time waiting.
1:13:33
Is that a process can be running. It's in the runnable state, and it decides that it wants to sleep for a while.
1:13:40
So, for instance, I've been using my phone and setting alarms.
1:13:47
And if it wasn't quite so fancy, it would just literally wake up in half an hour and go Bing, Bing, Bing Bing, right?
1:13:51
Because it's been woken up from its sleep.
1:13:57
So you have a timed waiting state, and at some point the virtual machine is going to decide it's time to wake you up.
1:13:59
How does it decide that? Well, usually because you've told it how long you want to sleep for.
1:14:06
OK, that's the idea behind this one. And the last thing that you could be waiting for blocks is a so-called waiting and waiting.
1:14:12
Can either happen because you've said white yourself or because you're waiting for something to join, which was like the first example that we have.
1:14:21
OK. And the way that you come out of the waiting state is because either some other processes or some of the thread says to you,
1:14:28
notify or because a commands called notify or message will notify all has been made.
1:14:36
And what notify all does is it finds all of the people the owner, the recipient of.
1:14:43
Look, and it takes them all up and then they can carry on with their lives.
1:14:49
I think that's not 100 percent sure that that'll be enough.
1:14:55
Oh, as heinous as this great one, right?
1:14:59
So you just thought that this is all quite well defined and now I can make things wait and it's all going to be good.
1:15:01
And for instance, here we've got to join. You're not going to carry on processing without being present.
1:15:06
Surely, you can't just have a waiting state for no reason and just wake up.
1:15:14
Actually, there is such a thing as a spurious wake up, which just means you get woken up and nobody knows why.
1:15:18
Right? That actually can and does happen in your operating system.
1:15:25
And it's a great puzzle. Why on earth would you allow this?
1:15:29
It sounds like a stupid idea. You ask somebody to wait and then you've just woken up when the wait condition has not been satisfied.
1:15:34
The reason spurious wake ups occur, I think there was a there was a debate when they first made the specs for these things.
1:15:40
The academics wanted it because they wanted it to be so that when you get woken up,
1:15:49
you should check to see whether or not the conditions you were sleeping on have been satisfied.
1:15:53
If they've not been satisfied, so back to sleep again, we should go back to waiting again.
1:15:57
So it's kind of like a correctness condition. The more pragmatic people said, Well, maybe you could squeeze out some efficiency from this thing.
1:16:01
If we flipped out, we could.
1:16:09
We could implement things where it just so happens that it's easier to not worry about things being definitely in the right state when they come out.
1:16:12
Maybe it's just more efficient for things to wake up. It's kind of like folklore if you look on the internet for white, what people say about this?
1:16:19
It's like people say, Is it true?
1:16:26
Is it possible to really have a spears wake up and you talk about this and have actually found that spirits still exist and this these?
1:16:28
So the moral of this story is concurrency is hard and it's harder still, because even when you think you've understood the model,
1:16:35
actually you still might get a serious wake up and it's still going to behave in a bad way.
1:16:44
So what we're going to see as a result of this wake up is kind of some good practise that needs
1:16:48
to be enforced in particular when we put ourselves to sleep or when we put ourselves to wait.
1:16:54
Usually we're waiting because we're waiting for something to happen for particular variable to be bigger than zero or for,
1:17:00
you know, some resource to finish doing its computation. So you've got to wait for the prince to finish printing before you carry on.
1:17:07
So you go wait. When you get woken up by a notify, you might think a sensible thing to do in your code is to just carry on.
1:17:12
Assuming that the reason you went to sleep or the reason that you're waiting is now done, that file has printed that variable is now bigger than zero.
1:17:19
But actually, what you should do is stick that in a loop and check to see whether that's true or not again.
1:17:27
And if it's still false, go back, go back to waiting. So that's kind of the kind of defensive programming that we're going to have to do.
1:17:32
So it's a very ugly and stupid reason for this kind of programming,
1:17:37
and you will probably look at codes like this in the future and think that looks completely stupid and useless.
1:17:41
Why on earth have you got a wait, followed by another check for things that you've just woken up from doing right?
1:17:47
And the reason is Spears wake up. OK, any questions about this?
1:17:53
No, it's OK. So processes versus threads I have been trying to tell you that might my use of terminology is quite nuanced.
1:18:00
So in reality, the distinction between processes and threads is a little bit more blurry and dependent on implementation of what you're looking at.
1:18:11
But the first approximation, what I said is true just just when you don't play me in a few years time when you like.
1:18:19
But he said that different things. Well, just be careful.
1:18:24
Roughly speaking, a process would be something like units that don't share memory so entirely.
1:18:28
Chrome, Spotify. These are processes, and a thread is going to be something inside that process that allows it to do several things at once.
1:18:32
For example, Jarvis writes that we're gonna be discussing, OK, so that's enough.
1:18:41
Blah blah blah. Let's try and actually write some code. So there are three ways to specify and create threads in Java.
1:18:45
So one is you can extend the class code thread.
1:18:53
Do you know what extending is yet? Yes, he's done such a good job, so so you have the Red Cross,
1:18:57
and if you extend the threat cross, that means that you basically you are a threat yourself.
1:19:06
And what you can do is you can override implementation of the run method.
1:19:12
So the Red Cross has a run method. It doesn't do anything right now.
1:19:16
And what you can do is, you can say, override the run and do what you want.
1:19:20
The second thing that you have is you could implement the interface called runnable.
1:19:24
So, you know about interfaces. Yes. So good.
1:19:28
So you have the runnable interface, and basically that says I do not promise any implementation of this thing so that anybody can just implement it.
1:19:32
You don't have to be related to this thing through irritants. And if you as long as you implement run, you're good to go.
1:19:40
Your thread the last one is called position with threads. Your opposition is.
1:19:45
Some of you maybe some of you don't OK, we'll talk about that in detail.
1:19:51
Roughly speaking, you can pass in a process to the constructor of thread and it will execute that thread or it will execute that process as part of a.
1:19:53
We'll go into detail. So let's look at them one by one.
1:20:01
The first one was extend through code looks like. So we've got a class. This one is called the concurrent counter.
1:20:06
It extends thread. So you've got an axe override, which says that you are actually overriding this thing.
1:20:12
So this is not necessary, but it's good code hygiene. It just tells people that you deliberately intended to override the run method.
1:20:17
And so you can just do what you want in that in order to make use of one of these things,
1:20:23
you would use a concurrent call to counter equals new concurrent counter.
1:20:28
So basically making a new object. It's called counter. It is a card counter, and because it's a concurrent counter, it is also a threat.
1:20:32
That's what the extends does because it's a thread. You can say start.
1:20:40
What Start does is it tells the JVM that it wants to take your process,
1:20:45
spawn it off into a new thread and executes the run commands that you've just done.
1:20:51
OK, and then when it does not run away, it goes and everybody's happy.
1:20:55
Does that make sense? OK, the next one is implement Runnable.
1:20:59
So here's what it looks like. So you've got a class current counter.
1:21:07
It implements runnable, so it's a new class definition.
1:21:11
And one of the things that it implements is the runnable method runnable interface, which means that it has to override the run.
1:21:14
So it's basically the same as what we've just seen, and this time we can do the same thing.
1:21:22
You can take a credit card accounts that are good, and this time we don't have a thread.
1:21:26
So can current counter is not a threat like in the previous example, it is merely something that implements runnable.
1:21:32
So we can't say start to this counter because it's not a threat, but what you can do is you can make a new threat.
1:21:39
Let's call it threat, and what it does is it takes in as a parameter, something that is runnable.
1:21:46
And when you say start to that thread, it takes a look at what's been runnable and it runs that carries on.
1:21:52
OK. So it's not the same as a threat itself, but it can be passed into a thread and executed.
1:21:59
You were a little bit lost. Yeah, let's do that again.
1:22:05
So the difference between these two, so you can extend thread, which means in this version, the concurrent counter is a thread.
1:22:08
So it's not the implements thread is a thread. And so that means that you can do stuff on it, whereas in the next one, it's not a thread.
1:22:19
It's merely influencing runnable, which a priori has nothing to do with thread.
1:22:31
It's just runnable. But it so happens that threads do know how to do things,
1:22:36
do know how to interact with runnable things so you can give a thread something that's runnable and it will know how to start that and run it.
1:22:41
That's the hope that it is confusing.
1:22:48
So you will see people just implementing these things into the styles.
1:22:53
And I think largely one of the reasons for this is that Java is a great big machine.
1:22:58
It's a great big language with lots of different features and does not kind of there's no single way to solve a particular problem.
1:23:05
Some people like to use lots and lots of inheritance, even though these days it tends to be frowned upon.
1:23:13
Some people prefer interfaces,
1:23:17
and it's good to have two ways of doing this in case you have a solution that still needs to be one or the other a particular way.
1:23:19
So that's why you've got these different methodologies. Yeah, yeah.
1:23:26
We. Yeah.
1:23:35
I think that tends to be a move away and towards implementing in spaces these days,
1:23:43
it's going to depend on what other code you have around you, what the expectations are.
1:23:49
So yeah, you could, for instance, have like an array of runnable things.
1:23:53
So sorry. An array of threads or things in common threads. And all you know about them is that you want to run them so you do want whatever.
1:23:58
So in that case, makes sense for you to have a thread,
1:24:03
but it might be that you actually don't really care about that and you want to just have it running, as you know, as a process by.
1:24:06
So maybe you don't really want to pay the price of inheritance or the complications that it brings in.
1:24:11
So use this instead. So there's no kind of correct way.
1:24:15
This is going to be something that you guys will learn about when you start looking at design patterns.
1:24:19
I believe it's going to be next year in civil engineering courses.
1:24:24
So at the moment, I'm giving you the tools, but I'm not really telling you how to use them properly.
1:24:28
OK? So for the time being, just do your best as it works great and then we can turn you into better engineers.
1:24:33
OK. And then last one is compose a threat.
1:24:42
OK, so composition with threat is another solution where it's a little bit more functional in style, and this is a more recent feature as well.
1:24:45
So I think this is only as of Java eight and this one says, OK, so you've got a thread and we're going to make a new thread.
1:24:55
And then we've got this strange notation. Have you seen this notation before? Yes, but basically, we're giving a function here.
1:25:03
So this is saying to the open closed bracket Arrow Cody Brace says I'm creating a function.
1:25:11
This function doesn't need any input except for like unit. And then what is the body of that function is the thing in the dot dot dot.
1:25:18
So this is what it does.
1:25:25
So this is a way of creating a new thread with behaviour without having to go through the difficulties of creating a new class and implementing stuff.
1:25:26
It's a bit more of a lightweight syntax to just say, just just do this.
1:25:34
I don't want to have to think of a new name and make a new file. Add it to my class path, have some tests for it and all the rest of it.
1:25:38
Just the quick and easy way of doing runs, OK?
1:25:44
And then because it's a new thread, you can just read stuff that way.
1:25:49
Right. This is what I'd like to call the painful slide.
1:25:55
So. What we've just done, I hope, is gotten the idea of threads and gotten the idea that there's something to do with concurrency that's complicated,
1:25:59
something to do with shared access to memory is a bit weird, but we don't really understand that yet.
1:26:12
And the reason we do understand is because I've told you nothing about how the JVM stores values and variables.
1:26:18
We don't know why the two threads can both write different values.
1:26:24
Give me some intuitions, but this is what this diagram is. It's to try and explain.
1:26:28
So. Behold, the JVM runtime memory diagram.
1:26:32
It is, again a simplification, but forgive me.
1:26:37
So roughly speaking, you have got so just ignore the fact that we've got multiple threads.
1:26:42
Just pretend this one thread for the time being, OK? You can roughly think of the JVM runtime as being split up into three parts.
1:26:50
There's the method area, there's the heat and there's the current thread or the thread stack.
1:26:58
So the method area is where the definitions of your classes get stored in memory.
1:27:04
So you typed in some code it gets loaded into memory, and what's being stored is basically a whole bunch of different classes.
1:27:08
What's inside each class? So there's the runtime constants pool.
1:27:16
There's methods and there's attributes in the class itself.
1:27:21
OK, so the runtime constant pool will be the sort of static integers and characters and whatnot that might belong to that particular class.
1:27:24
Right? The methods will be literally the code that needs to be executed.
1:27:35
When you run that course, they need to go somewhere that goes here and it's live in memory.
1:27:40
The attributes is like a recording of what attributes does this cross even have?
1:27:45
So when I make a new one of these things, what do I need to put in memory that gets recorded in this place?
1:27:49
So you can think of the method area roughly speaking as being like how Java puts into memory,
1:27:54
the fact that you've written some code and that you will later on be creating instances of that code.
1:28:01
So how does it know how to do it looks up in the method area and it could give that to life and make new objects.
1:28:06
When you make new objects, they go in the heat, and that's where the different instances of a particular object of a particular Costco.
1:28:12
So the heap contains a whole bunch of objects, and they will be like instant stations of the cross that we have.
1:28:18
It also contains things like any grain sensations. You have that kind of thing, all those on the heap.
1:28:27
So you can think of the heap as being like large. There's lots of memory here, there's lots of space for stuff.
1:28:32
What we have now on the right hand side is the thread. So the thread is actually the unit of execution that's going to do lots of work.
1:28:39
By default, there's only one thread,
1:28:45
the main thread and what we did earlier on with the stop command was that to create more of these threads and then we were to get rid of these things,
1:28:47
you wait for the joint to happen again.
1:28:53
So initially, each the main threat has a programme counter that says where inside the methods it is, so which which line number is it running?
1:28:55
And it also has a JVM stack.
1:29:06
So the JVM that contains all of the information that's needed for when it's running a current method,
1:29:10
there's something I forgot to do in this diagram that stuck frame. There could be more than one stack frame.
1:29:18
So we see that there were boxes that fragments inside the Java and stack.
1:29:24
There's actually a whole stack of these and there's a there's every time you enter a method,
1:29:26
you create one more of these things on the stack, the copies out the new information that you need for that method.
1:29:31
So you might have seen something called the Stack Overflow. Basically,
1:29:37
that means that this has run out of memory when you go into new method and then maybe that goes into a new method and it's a new method and so on.
1:29:40
You are adding information onto the stack frame and eventually that may run out.
1:29:47
OK, so recursive loops where you're calling one method coding, another method, coding, another method and so on.
1:29:53
Can be dangerous because you can run out of factory space, which is why in Java,
1:30:00
there's a tendency to use iteration so for loops and while loops rather than recursion.
1:30:05
So in high school, you will recall that there is no such thing as iteration loops while loops.
1:30:10
Everything is recursive and it's all nice and easy.
1:30:15
In Java, if you tried to programme like a functional programmer like Haskell, you're going to get stuck overflows pretty quickly.
1:30:18
So there's a difference in programming style for this, for this physical reason.
1:30:24
OK. What's inside each stack frame? So that means what is inside the context that you need to remember when you enter a method?
1:30:29
Well, you need to keep hold of the variables. That's the variables, the method itself that you have in scope.
1:30:35
The reference is copy through and you have something called the operand stack,
1:30:41
which basically is java's quick and dirty way of implementing like addition and negation
1:30:45
and other easy operands like in a reverse polish notation style that just says like,
1:30:50
I've got something some work to do and these are the options I'm working with right now.
1:30:55
And you have the runtime constant pool reference,
1:30:59
which basically says which runtime constant flow of my pointing to so which constants on my dealing with right now,
1:31:03
which instance, which parts of instances of objects are working with.
1:31:12
So? That's a lot to take in.
1:31:16
Oh, and then there's a thing called the native method stack now that's a very arcane part of it, but it's here for completeness.
1:31:21
This is where Java might want to interact with C and make a wood bound calls to some
1:31:26
underlying native code on your in your in your kernel when your operating system.
1:31:31
And so there's a stack of those operations or methods that it's currently considering.
1:31:35
So that's where everything goes. Now why tell you all of this, right?
1:31:40
The reason I'm telling you this is because the heap and the method area are shared amongst all of the different threads.
1:31:45
So that stuff is the stuff which you can start writing to and everybody gets to see it and everybody's happy.
1:31:53
The threads have their own version of variables inside that stack, right?
1:32:01
Which means that when we looked at that very first example with the C.
1:32:06
A. Counter, that would have been a variable that lived there.
1:32:10
And so that has its own local version of what's going on, which is different to the object in the heap.
1:32:14
That's the instance that we have. And that's where the problem that we had come across, like an hour and a half ago came from.
1:32:20
Right. So it was this particular interaction and right there we go.
1:32:26
So now we finally understood what we did at the beginning of the lecture.
1:32:30
It's taken a long time together, but hopefully I've given you enough pieces of the puzzle to see.
1:32:34
This is complicated. There's a lot going on. Oh my goodness. How are we going to do anything with it, right?
1:32:39
So. Yes.
1:32:43
You don't really need to know about this, but this is so.
1:32:48
The JVM needs to interact with the rest of the kernel.
1:32:54
In other words, the rest of the operating system, the operating system has this thing called the kernel,
1:32:57
which basically lets say a few methods that it provides the programmes that they can do what they want.
1:33:01
So things like, you know, get input from the keyboard or write something to the screen or open up a file, that kind of thing,
1:33:09
or that is implemented usually by calls in C, which are being implemented or backed by the kernel itself.
1:33:19
Right. So even though you've got JVM, it exists in its own little bubble.
1:33:26
It needs to interact with the operating system in some way, and it does that through what we call native methods.
1:33:30
And so somewhere it needs to remember which native methods need to execute it when that's where that gets old.
1:33:36
All right. OK. Anything else? OK.
1:33:42
We're seeing lots of zombie processes, so it's time to do some code. OK, so there is a GitLab repository here.
1:33:48
It's an old repository that Antonio wrote a while back, which we update. And so the course codes have changed, but the repository has remained.
1:33:59
So you can always have a look here for lots of cool examples of the kinds of programmes that we've been talking about.
1:34:07
It's well worth you going away and cloning this and having a look for yourselves, having a play and see what's there.
1:34:14
So basically, all of the examples that we've done today will be implemented and you can step through them and have a little go.
1:34:23
What I want to do now, I think, is just spend a bit of time.
1:34:28
I'm playing with this. So it's again.
1:34:32
Of course, sorry. Yep. GitLab, Dr. Cook Koh 120 concurrency.
1:34:37
OK. So.
1:34:53
Unsurprised my alarm hasn't gone off yet, but two minutes, I think it's three thirty seven.
1:35:00
I'm going to give you a three minute break now because it's a good time to pause and then we'll finish
1:35:06
off the lecture with just a bit of coding so you can have three minutes yourselves to whatever you like.
1:35:12
Okay. You know, I think know it's like a fixed rate for quite some time.
1:35:33
And in the midst of all this Robin Hood complaining about something like one three.
1:36:06
Yes, it's just the same kind of thing. I got some problems this last year.
1:36:29
David, that's a confidence last one of those examples that, oh, I see, we'll talk about that or we just ran into each other.
1:36:37
You said something about that.
1:36:51
So when we do some coding, that's a great time to ask these questions. We're going to go through a lot of data.
1:36:56
Yes, exactly. It's. What?
1:37:01
But. If you don't get that now, I'm a little surprised because I hope it makes sense that.
1:37:25
OK. That's the last of it.
1:38:28
So let's finish off with some live coding and see what we get to. I don't know whether you've heard we get started.
1:38:36
Thanks. OK, so we're going to finish off with just a little bit of playing around with Sanjay just to get a sense of,
1:38:50
you know, how we actually implement some of these ideas. So I wanted to just talk about, Oh, so I've got a race her somewhere.
1:38:57
Somebody raised the hand, I don't know if you'd like to ask the question. Go ahead. OK, maybe didn't.
1:39:09
OK, so what he want to do now is I want to just look at the code of the concurrent council.
1:39:20
And I want us to understand what's going on,
1:39:25
and I want us to make sure that we are convinced that there's a problem in how the different parts interact.
1:39:28
So let's look at. So this I think this code is very simple.
1:39:34
So we've got the the threads being started and then they join an old one.
1:39:39
And the key points to look at is that we're extending the sequential counter aisle.
1:39:43
So let's look at the sequential counter. And I think somebody just commented and said that they're a bit confused about what's going on here.
1:39:47
So why have we got a little variable here? Is it really doing anything?
1:39:55
It looks like we just sort of assigning to it, and maybe that could be a source of the problems that we're getting right because it could be that
1:40:00
we've got our own local variable and this is distinct from the global counter that we have up here.
1:40:05
What's going on? How does this work? So what I'd say about that is that actually this is kind of like this could be changed very easily.
1:40:12
We could say here instead that there's no verbal S.A. instead, we're just going to literally do this right.
1:40:21
So this is going to be similar to what we had before.
1:40:29
Right. It's incrementing that counter and we can see whether or not this thing also fails.
1:40:32
But oh, look, it's still not working, right?
1:40:38
So why is it not working? Looks like we've done everything right.
1:40:43
So that's not to do with the local variable inside run that's going on.
1:40:47
How come we've got this extra instruction? So what we'll say is we haven't got this extra variable that we seem to be having attention on.
1:40:52
Where is the potential happening? The contention is happening literally on the counter variable.
1:40:59
That's why you've got multiple processes accessing the same thing. Why is that?
1:41:04
Because each thread, as you'll recall, has its own stack of variables.
1:41:08
So somebody like that again? So inside here, inside the Japan stack, we've got our own variables sitting here, right?
1:41:14
So these variables are exactly things like that count a variable that we have here.
1:41:21
And so it has each thread has its own copy of that, which it needs to kind of interact with the the main instance and make things coordinate that way.
1:41:26
So that's why there's a problem here. So. OK, as that, I'm kind of conscious that we haven't talked at all about solutions to this problem.
1:41:35
Right. And so all I've done is complaints and giving you a great big model for how this works.
1:41:47
The next lecture is all about fixing this problem and.
1:41:54
I kind of want to go there now, but there's just not quite enough time. Everything there is to show here.
1:42:01
I was I was going to show you things like. Where this repository is and how to clone it.
1:42:10
I think you probably know how to do that already. So I'm not going to do that unless someone is like, please do so.
1:42:15
So I think I'm what I'm going to do is I'm going to just start giving the beginning of the next lecture.
1:42:22
But judging by your faces, you're so tired it's not going to work.
1:42:28
So I'm going to start and then we'll restart at this point next time.
1:42:32
OK, so there's a question final.
1:42:36
Yeah. Let's do it, let's do it.
1:42:46
So I'm going to kind of like we're going to I don't think as much quote to show you because I've already talked through it in kind of detail.
1:42:50
So let's go to the races. I will cover all of this again.
1:42:55
OK. What was the problem that we encountered the beginning, it was the problem of race conditions.
1:43:03
So both the executions of the same input leading to different behaviour.
1:43:10
So I think I showed you that, but every time you run the programme, a different value comes out.
1:43:14
And that's to do with the concurrency and the fact that we can't really tell what's being written when.
1:43:18
OK, so there are a couple of times that I want you to know about.
1:43:24
A race condition is basically when the results of a car programme depends on the specific execution given by the scheduler.
1:43:27
So lots of big words.
1:43:36
But remember, the schedule is the thing in charge of deciding which processes run when, and maybe the result depends on what the schedule decided.
1:43:37
That's a race condition. So oops.
1:43:44
Oops, there's a knock knock joke for those of you.
1:43:50
I've come to learn that not everybody knows what a knock knock turkeys is, so knock knock jokes for those who aren't British, do something like this.
1:43:55
Somebody says, Knock knock, who's there?
1:44:01
And then they also always changes, depending on the joke. So who's there and the doctor doctor who?
1:44:05
No doctor will have to do so.
1:44:14
So the knock knock joke to knock knock race condition is that if you used these drugs, you realise it's good anyway.
1:44:19
So, yeah, it's really great. We have to explain the joke and lots of detail.
1:44:33
It's like a data race is something different.
1:44:39
A data race occurs when two threads access to shared memory allocation, and one of them is a right and the order of the access is not fixed.
1:44:41
OK, so what? What does that mean here?
1:44:49
So is there a database between these two things so we can ask ourselves, Is there a database between C and you?
1:44:53
So we've got two threads. Yes, fine. At least one access is a right.
1:44:59
So are they writing? Yes, they are. Because look, they've got counter equals an update.
1:45:04
OK, so that's a right, and the order of access is not fixed.
1:45:10
In other words, we've got two threads. They've both got their own programme counters, so they could be executing through this at different times.
1:45:14
And so that means that we now have the potential for database. So that's those are the three things that need to just check is their database.
1:45:20
Yes, that could be. So not every race condition is a data race.
1:45:26
So it could be that you've got a race condition so race conditions can occur when there is no shared memory.
1:45:34
So a data race, I said very specifically was about when there's a shared right to memory.
1:45:43
But actually, race conditions are a bigger problem that specify things like when two processes are competing for some resource.
1:45:48
So it could be that they're racing on memory,
1:45:56
but it could also be that the racing on a file system or file or a particular network resource or something else like that.
1:45:59
So that's that's the difference between these two. And the other thing is that not every day race is a race condition.
1:46:04
So it could be that you've got two processes they are both going to execute.
1:46:10
They can both write some information and the order is not determined.
1:46:16
So something strange is going to happen.
1:46:20
But it might be that always the result is the same regardless of what happens, maybe because they always write the value 42.
1:46:22
And so it doesn't really matter that there was a race condition. I'm sorry, it doesn't really matter that there was a data race.
1:46:29
The output is always determined that regardless of the schedule. So again, these are times that need to be nuanced with.
1:46:34
And. I'll just do one more minute. So.
1:46:44
What we want to do is what to try to avoid race conditions. Programming is all about getting as the potential of doing things better and faster.
1:46:50
Even though there's a risk of race conditions. And so the way that we're going to deal with this problem is synchronisation.
1:46:57
And so next time, I'll give you some tools to deal with synchronisation. So let's stop that slow.
1:47:03
They enjoy break. What?
1:47:07