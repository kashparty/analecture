ID: 3ab1f9a2-ac8b-4505-9860-adf800cb5221
Title: idb-topic-11-sql-olap
Category: COMP40007 - Introduction to Databases (Autumn 2021-2022)
Lecturer: Peter McBrien
Date: 08/12/2021
In this topic, we look at the features of Esquivel, which help with analysing large amounts of data.
0:01
First of all, let's define what I mean by that.
0:09
I think it's fair to say that the original purpose of Eskil databases was to handle the basic transactional processing of businesses,
0:13
so doing things like moving money from one branch to another, recording payments at a bank, booking of airline seats and so on.
0:24
And this may be characterised as most of the actions on the database being about reading and writing a few
0:32
rows of information and it being important to be able to execute those reads invites as transactions,
0:39
which are executed as atomic units of work. So this can be regarded as standard day to day processing of information.
0:45
Of course, once databases start to be used for such purposes, the office next step is that the information held in those databases be analysed
0:55
and that led to the development of online analytical processing or overlap.
1:04
And this is about reading many rows quite often hold tables and summarising that
1:10
information to provide management information that allow decisions to be made.
1:15
So this might be contrasted in the branch table,
1:21
but I wanted to sum all the cash figures across the branches to find out the total cash position of the bank,
1:24
rather than trying to update individual rows of the branch table to move cash from one place to another.
1:31
If you've used a squirrel tool before, you might well have used a that feature that's been in Eskimo for a long time called group buying.
1:39
And what this does is take a table as input and allow you to group the information by one or more columns,
1:47
which means you're going to output a row per instance of the group.
1:55
So if I take my move in the table and group by number, I'm going to get one row of output for count, 100, one row of output for 101 and so on.
2:01
That does beg a question, of course. What do you do with the columns you have grouped by?
2:13
Because in the row I'm going to output for, say, a count 100.
2:17
I have three alternatives to the mid three alternatives the amount and so on.
2:21
And the answer is that if you're going to use such a column, you must put it inside to what's called an aggregate function.
2:26
And there are a range of aggregate functions built into the Eskimo standard.
2:33
And this is a topic that many databases provide extensions to a common ability to sum the values in the group count,
2:39
the values in the group, find the average of the values in the group and so on.
2:47
So the key thing to remember about these group buys is that you get one row of output per group, and that's the skill.
2:52
Standard says that you must apply an aggregate function to any column that is not in the group by expression.
3:00
So in the example here, it means any column apart from a note.
3:08
So if I wanted to take my account information and let's suppose not grouped it by the account number,
3:13
I could someday amounts and count the amounts to find the total balance for an account number
3:19
and the number of transactions that have occurred on that account to reach that balance.
3:26
Let's try out a simple quiz question. And in this case, I'm worried about which of these alternatives is not permitted in the school.
3:34
The most popular answer to this was a quite a few people went for answer D.
3:48
The answer is the correct case, and the reason why it's not permitted by the CSIRO is because sea name does not appear in the group expression.
3:54
So we've got an instance of a column that hasn't been grouped by and is not appearing inside the aggregate functions,
4:03
so the C name wouldn't be allowed. D is the opposite.
4:10
I have not done any group by it, but I have put all the attributes inside functions.
4:14
The implied group by four D is to be the whole table, so this would find the average rate across all the national rate.
4:22
Values in the account tables is quite valid to ask you about.
4:30
So normally you will be always using group by an old nun in fat attributes.
4:38
Now some odd extensions to different databases that mean that you can sometimes write
4:44
a query without putting such aggregate expressions of all the noun grouped by fields.
4:49
But the behaviour of such queries is often quite strange, particularly when you're looking at sort of transact school and SQL Server.
4:56
You should remember to choose between bag and set semantics for counts.
5:04
So, for example, if I did select Count Number as active accounts from the movement table because there are nine rows in the movement table,
5:08
I'd get the answer. Nine, because there've been nine instances.
5:16
Number is if I wanted to find the number of active accounts in the database, I'd be wants to count the number of distinct numbers.
5:20
And of course, I'd find five active accounts amongst the movement table because there are five distinct
5:27
values of the number and also null attributes don't count or average or min or max.
5:33
If I say select count right, as the number of rates from the account table will get the answer to because the
5:39
four null values opinions are right in the account table will not be counted.
5:45
I was trying out a couple of quiz questions using Group B over no values.
5:52
And by far the most popular answer here was Dee. And indeed, that is the correct answer here.
6:03
The thing to look out for here is that when I count the movement amounts, I will not be counting the null values.
6:10
So in particular,
6:19
I count 100 here has a null appearing for movement a thousand and 10 and therefore are only counting the free values for the amount that appear.
6:20
Four thousand six thousand two and a thousand.
6:33
And hence I get the answer of the number of transactions being free rather than full.
6:38
That's try a different quiz question. Now notice we're going to be looking at just the movement table by itself and therefore
6:46
be including the ones which have the nose hair appearing in the account number.
6:54
It is rather a split opinion about what the right answer is, but in fact the least popular answer is the correct one.
7:07
I think there are arguments about why all the answers could have a more plausible but ask you,
7:14
well, treats in-group bias rather like he does with the exact expression.
7:20
It treats all the novels as being the same thing.
7:26
A single novel, so to speak. And then we'll take the amounts and we'll sum them up ignoring the male value here.
7:30
So of course,
7:38
that leads me to a total of five hundred and fifty four being the balance for all the account numbers which have now set them at the moment.
7:39
Of course, you might argue that's how the data base know that those numbers are the same.
7:49
Of course it doesn't. And also, how can it say that you can sum up these amounts when he doesn't know one of the values?
7:54
And of course, he doesn't really know the son, so behaviour of null does need to rather.
8:01
So the behaviour of Eskimo and the Examiner does need to some rather strange results when you come to do group by.
8:07
You might think back to our treatment of the relational algebra and note that was no group by operator presented there.
8:21
And in fact, you can extend the relationship to include a Pacific group by operator,
8:29
but that then leads you to the issue about there being a difference between applying select inside and outside of the group.
8:34
And therefore we need to have something extra in Eskimo to allow that distinction to be made.
8:44
And the answer to what you have in Eskimo is to add something cool to having close to this does look at a practical example.
8:50
Let's say I've done a query using that group by on an account number to sum the
8:58
amounts and count the amounts to get the total balances for my different accounts.
9:03
Now that say, I'm only interested at looking at accounts which have a large balance, well, to do that,
9:08
I can't filter the amounts before I sum them because I don't know how many amounts there are and what they're going to add up to.
9:15
So instead, I need to filter the sum of the amounts,
9:23
and I do that by adding after the group by Expression A having close and stating what I want to have as a property of the aggregate amounts.
9:27
So having clauses actually read like where clauses, but they appear after the group by rather than before the group by.
9:37
And they will always involve having aggregate expressions because the point of them is to deal with what the results of the group is.
9:44
The ordering of escalation clauses is, of course, not very straightforward.
9:55
You should recall that the basic slip from where it goes in the order that you do the Cartesian product from clause first,
10:00
then the where clause followed by the select when I have group by effectively has been added to after the workloads that we have from first,
10:07
then were then group by then having and finishing off with the select clause.
10:16
This query gives an example of where this is quite useful to having clause here is protecting the database about the
10:23
situation with the minimum amount might be zero and stopping it returning at the places where the min amount is zero.
10:30
And of course, if that was allowed to occur, I'd have a divide by zero code for certain account numbers where the minimum amount they have is zero.
10:38
OK. Strikes a quiz question using the having closer who introduced.
10:50
Most popular answer here is a. And that is the correct answer.
10:57
The thing to note here is that these two conditions are being done after I've done the group by the where clause is done before I do the group bite.
11:03
So the fact are many interesting amounts being greater than 200 means I will eliminate.
11:13
Apart from the first two and the last free throws from the consideration, and once I've done that,
11:21
it becomes very clear that's only account one to one that has more than one movement
11:28
with an amount greater than 200 and therefore be the only brother that's returned.
11:33
A more recent addition to the Eskdale standard not available on some current products is the politician by and this does something similar,
11:45
but not the same as group by effectively doing the same idea of grouping data together.
11:55
But this time it's still going to allow one rope of output per input row.
12:01
So the grouping here has initially apparently done nothing.
12:07
Of course, the answer is you need to hide something extra to the query in order to do some something useful.
12:12
So if, for example, I took my movement table and wanted to report for each line in the movement table,
12:18
the middle, the number and amounts, I can do so as normal.
12:24
And then I can sum the amounts over the partition by number.
12:28
Do you get the sum of the amounts per account number?
12:33
No. I look at several rows went on doing the sum over partition by number.
12:37
Only look at one row when on the report in the middle. The number and amount.
12:43
And of course, this gives me a sort of hybrid of a normal select and the group PI because the first three
12:48
columns of this example query are being reported per row and the last column is being reported.
12:54
That per group allows you to compare the single road with the aquaponics machine and end up with really quite complex and sophisticated queries.
12:59
And there are a range of different functions you can apply here. All the normal aggregate functions can be applied.
13:10
And this leads on to the notion that there being a relationally complete version of the Skrill
13:17
language where you are allowed to put any real query in the place where a table may be put.
13:22
So for example, I can put select statements in the from clause.
13:31
Here's an example where that's useful. It allows me to do something similar to the idea of comparing individual rows with the total amount.
13:36
At this time, I'm comparing the movement table with the sum of all the amounts across the total movement table and calling that total balance.
13:46
So this sub query will return only one row because it's doing no grouping by say it's going to sum the amounts across
13:56
all the movement rows and effectively give me a comparison between each row in movement and the total amounts.
14:03
And then I can do the expression here where I am comparing the grouping by the account numbers and dividing by the total balance.
14:11
To compare the balance of an individual count with the total balance across all the accounts in the bank ended up with a result, as shown here.
14:20
Who is a six stroke bank based language, so of course, there is no ordering associated with the data,
14:36
but for presentational purposes, it's often useful to present old data in a particular order.
14:44
And the solution to that is to put at the end or ever quiver.
14:50
You have an audible expression and state which rose that you want to produce the part of the what,
14:55
what row or columns or column of columns you want to order your data via.
15:02
Of course, sometimes the order of these things becomes significant.
15:08
Let's take an instance where I have to scientists order by the amount of transactions I've got the biggest transaction first.
15:13
Then the next big us. And so it might make sense that I actually give a ranking number to these amounts to say this is the
15:22
biggest transaction that's occurred in about the next one is the second big and so on to effect the number.
15:30
That and the way I do that is to use another overexpression where I use the rank function and say I want to look over a view,
15:36
a window over the table when ordering the data by amount.
15:48
So this effectively takes the whole movement table as one group,
15:53
it orders it by the amount descending and it gives a ranked number associated with each amount.
15:57
So you see here that the amounts are being numbered in descending order of value.
16:02
The rent function will do the normal ranking concept of giving the same number to two things which are equal,
16:08
if you don't want that, then you will and then you'll skip a number.
16:15
So if no, you've got to number first, you then have a number free where tents rank would have to number first.
16:19
And number two, as I mentioned before, this is a relatively recent addition to databases.
16:25
So for example, if you're running on an old version of Postgres PRETER, version 9.0 is fine.
16:31
This is not supported. This is supported in the head installation in the development that you are using at the moment.
16:37
OK, let's summarise what you say.
16:47
Well, by thinking about what the execution order is of all the different constructs of genuinely select from where Quibi.
16:50
The most popular answer was C, and that is the correct answer.
17:03
So notice you got the basic process of we look at the Cartesian product in the way the phone calls.
17:08
We then filter them, by the way. We can group the data and then filter again using having.
17:14
We then will select which things we want to project out at the end and at the end we do the ordering by.
17:21
And that means the order by clause is the only thing that's able to refer to any aliases you give to the data in the select logs.
17:27
Oh, a few extra things,
17:40
which I should tell you about which you can do just using the standard Eskimo expressions without any extra overlap capabilities.
17:42
And one important concept is the idea to pivot and pivot information.
17:50
Let's give an example where I've been asked to produce a report where I want for
17:57
each bank branch to report its name and the number it has of each type of account.
18:02
Will be easy to run to query where I enjoy between the accounts and the branch table.
18:10
I grouped by the combination of sort code B name and type and reports the number of accounts I find as counting.
18:15
That number might end up with data shown here for the count tables it currently stands.
18:24
And that's good,
18:29
but you might argue isn't presenting information how you'd normally expect it to be present in this type of situation because normally expect
18:30
there to be a single row for each of the branches and then columns saying how many current accounts you've got and how many deposit accounts.
18:38
So if you're required to present your information in that effectively,
18:48
you need to pivot your table around to pivot the quantity across a row based on the time column.
18:51
And that may be done by a simple trick using case statements where I will filter the information
19:01
that applies in a count balloon to particular common such that I'm only counting in this instance,
19:08
the number of rows which meet the particular criteria associated with the column.
19:16
So I ones to have a column for the number of current accounts,
19:22
the number of deposit accounts I've got on each branch I can group by the combination of branch code and B name.
19:26
And then when I'm counting the numbers, if I say I'm only interested in, count them when the time is current, ah,
19:35
end up counting just current accounts for the current column and simply counting the deposit accounts deposit columns.
19:41
So we see the information on the previous slide has now been pivots around to appear one row, and sometimes in such circumstances,
19:49
it might make use to have a sort of default column that saying how many instances do not meet the criteria of the other columns you put in?
19:57
And that's what I've called to other hand, where checking to count the times, where they are not count or deposit.
20:05
And of course, there aren't any of those at the moment. So I end up with zero values for each one of those.
20:12
And you can treat this as a query pattern, so you might have a sum been applied to or any other type of an aggregate function.
20:18
OK, it's enough information now to go on into the worksheet associated with old queries and ask you out.
20:28
And what's more, I recommend that you treat this as a practical exercise and to it connected to the bank branch database.
20:36
It can be useful sometimes to unpick that information. That means taking some columns and turning them into a single column.
20:48
I've got an example here.
20:57
We have unlimited all the columns of the account table, so I end up now with a pool table, which has a column for the key of the table.
20:59
It's no in this case, another column which says what the name of the old column used to be.
21:10
And then a third column, which has the value that used to appear in columns.
21:16
So I see because there were three different values set for account 100, you have no right.
21:21
There are three rows here and full account 101, which had four different values set in different columns.
21:27
I had a right of value added.
21:34
And the advances of this format, which is called a triple format, is it gives the databases a certain amount of flexibility.
21:44
A criticism sometimes levelled at relational databases is that you can end up with tables with many,
21:51
sometimes hundreds of columns, many of which have no values, and that's simply null.
21:58
Value columns waste a small amount of storage on each line, which we need to tap across.
22:04
Tens of thousands or hundreds of thousands of homes in a commercial large scale database can represent a significant amount of information.
22:10
And also adding or removing column using the water table command is a relatively slow operation,
22:19
which can interrupt the function of the database for a few seconds or a few minutes over a large table.
22:25
And the solution to this is to adopt the triple format where you store data in the key property value type format I've shown before.
22:33
You can adopt a performance in relation to database management systems, but this can result in poor performance because you effectively often need to
22:43
join together different rows of the triple format to get the original data back.
22:50
Common Store Relational Database management systems like SAP Hana are deliberately written to make such queries very efficient to execute.
22:56
Or you might adopt a database of specifically designed to store this triple stroke graph format.
23:05
RDF is a triple format and style diagram graph are examples of databases that provide good support for this type of information.
23:12