ID: 52e6d4f8-4c59-4064-a814-ae2d014902e5
Title: 5.2 Travelling salesman problem
Category: COMP40008 - Graphs and Algorithms (Spring 2021-2022)
Lecturer: Iain Phillips
Date: 13/02/2021
Let's now look at the travelling salesman problem in the travelling salesman problem.
0:01
We've got some cities and roads between them, and the travelling salesman wants to find a tour of all the cities with the shortest distance.
0:07
Getting back to the start. So more formally, the travelling salesman problem, Morty SPF Short says, given the complete weighted graph.
0:14
So there is an arc between every pair of nodes.
0:23
Find a way to tour the graph, visiting each node exactly wants and getting back to the start and travelling the shortest possible distance.
0:27
And here is an example, complete way to graph. With five nodes, so we need to get starting, let's say, at one.
0:37
It doesn't matter where we start. We have to get through the other four remaining cities in some order and get back to the start.
0:44
So if we went one, two, three, four, five, then the total distance would be eight plus seven plus six plus two plus three.
0:51
But perhaps we can do better by taking some other route.
0:59
The restriction to complete grass is not that strong because supposing that some arcs were missing from the graph,
1:03
we could just make it complete by adding fictitious arcs with weight.
1:10
That will be high enough that they would never be chosen.
1:15
So if there was no arc from one to two, then I could just give it away like a million or something of that sort.
1:18
And then when we find the shortest path, we wouldn't actually take that route.
1:24
So travelling salesman is clearly related to the Hamiltonians circuit problem.
1:32
We've already seen, which says that we want to get around and Unweighted Grauwe visiting each node exactly once.
1:37
And it's also related to the shortest path problem, which we solved using Dijkstra's algorithm or the or Floyds algorithm.
1:44
So effectively, what we have to find here is a Hamiltonians circuit, which is of minimum weight.
1:53
Well, it's not hard to find a Hamiltonians circuit because we have assumed the graph is complete.
2:00
So any sequence of no's will give us Hamiltonian circuit.
2:04
But if we want to find the shortest Hamiltonian circuit,
2:09
we would have to potentially cheque the N factorial different possible tours of a graph with an node's.
2:12
Well, it turns out that just like Hamiltonians circuit problem.
2:20
Travelling salesman problem is enpi complete and so unlikely to have a or the name your solution.
2:24
And we'll see more about that in the last part of these lectures.
2:30
But you can, in fact, do better than N factorial the naive solution of looking at all possible different tours.
2:36
And we can actually get this down by a better algorithm due to Bellmon Heldon cop to a running time of Bigo of N squared two to the N.
2:43
Well, notice that's still pretty bad because that's worse than exponential.
2:53
But let's have a look at it anyway, because it's an interesting algorithm.
2:58
And it will be another example for us of dynamic programming. So let's suppose that the graph has got nodes number one to N.
3:03
And the idea in this algorithm is that we're going to fix the start node, let's say one could be any node, but I mean, Wandel do.
3:17
And for each x node node, not equal to one and for each subset of possible intermediate nodes.
3:26
S not involving one or X, obviously, because they got to be intermediate nodes and each node can be used at most wants.
3:36
We're going to find and store the minimum cost C. S X of a path from node one to node X using set of intermediate knows precisely s.
3:45
So we're not saying that the intermediate nodes here are a subset of S.
3:56
We're saying that S is exactly the intermediate nodes on this green path from one to X,
3:59
and we're going to find the minimum cost of a path from one to X using those intermediate nodes.
4:06
OK, well, how does that help us with the travelling salesman problem? Well, cause we can start anywhere where the travelling salesman problem,
4:16
let's start at one without loss of generality and let the last known before returning to one B X in this optimal tour that we've got.
4:23
Okay. And then what must be the nodes that we visited between one and X?
4:33
They must be all the nodes apart from Bollen X. But then we can use our see a function that we've built up to compute the least cost
4:39
of such a tour because it's just going to be C of this set of intermediate nodes.
4:48
And the part this will give us the minimum cost of a path from one to X, just using these intermediate nodes.
4:55
That's what C will calculate for us here. Plus, the cost of getting back from X to one again by a direct arc, which is just W, X, Y.
5:03
But we don't know which X what X is, of course. So we just have to minimise over all possible values of X.
5:14
So for each X, we know that this expression here gives us the least cost of a tour of.
5:22
And so just minimise overall values of X and of course, X can take any value apart one.
5:32
So we minimise this expression over all values of X. So that in outline is what the algorithm is going to compute.
5:38
Of course we then need to know how to actually compute this function, see.
5:48
But once we have the function see, then we can easily get the answer just from this expression at the bottom.
5:53
Slide. So how do we calculate see?
5:59
So the idea here and in dynamic programming style is that we're going to calculate C.
6:04
S X by building up these sets.
6:09
S in increasing order of size. So we do sets of size zero.
6:14
There's only one of them, of course, the empty set. Then size one all the way up to N minus two, which is the largest value it can take.
6:20
So base case is easy, as you might imagine. C empty set X is just the weight from one two X because we don't allow any intermediate nodes.
6:28
Now let's assume that we've already computed C.
6:41
S X four sets S of size K and let's say that we're trying to we're looking at a set of size K plus one.
6:44
And so let's consider the last intermediate node, why?
6:55
In a lease cost path from one to X using intermediate nodes.
7:00
S. So this is our lease cost path along the top here in the diagram.
7:04
Why is the last node in that path before we get to X?
7:10
So these other nodes here that are used here, the intermediate nose here must be.
7:14
S minus Y. But now we can compute the minimum cost of this because the minimum cost of this path.
7:18
This whole path along the top must just be weight of WWII X plus what we've already
7:27
computed as the minimum cost of a path from one to Y using intermediate nodes,
7:36
precisely S minus Y. So because we've already computed the C function for this set s minus Y, which has size K.
7:42
So we assume we've already got that value. Well, but then.
7:53
So that's the cost of this route. Where why was there last intermediate node?
7:59
But of course, we don't know which node out of S was the last intermediate node.
8:05
So then we have to minimise over all possible values of why and why can take any value in S.
8:10
So let's just minimise this cost expression over all possible values of Y.
8:17
And that will give us C. S x. So that allows us to compute all the value.
8:23
S this firm will work for any set of size K plus one.
8:32
Given that we've already computed S for all all values, all sets, we've already computed C sorry for all sets of sites.
8:37
K. Well, now we're in a position to write down the pseudocode for the Bellmon held cop algorithm.
8:46
So we input a weighted graph. We choose any node to be the start, doesn't matter which.
8:54
And then we're going to initialise.
9:01
Well, we start by saying that C empty set X for any X part from the start node will just be the weight of the arc from start to X.
9:04
So that does the case for sense of size zero.
9:15
And now we're going to process sets in increasing order of size.
9:20
So I've got a big four loopier going over all subsets.
9:26
But what I mean here is that I'm going to do the sense of size one and then I'm going to do the sets of size two.
9:30
Then this exercise three. So possibly a more detailed version of this algorithm would say for increasing size of the set.
9:38
Let's look at all. Let's iterate over all sets of that size. But I've just expressed it rather abstractly here.
9:47
And then so that's we're trying to compute, obviously see s effects.
9:57
So let's take any X that is not in S and not the start node and then we're going to find C of S of X,
10:03
as we've seen how to do it in the previous slide. So we're just going to minimise over all possible values of Y in S.
10:16
Just go back to remind ourselves this is the expression we're going to use to compute that at the bottom of slide one eight seven.
10:27
So I started off just by setting CFS of X to be equal to infinity.
10:34
And then as we go through the successive values of why we see whether we can do better,
10:40
and if so, we replace CFS of X by these smaller about here that we've computed.
10:45
Obviously, the first time we do that, we're bound to get a finite value.
10:51
And of course, infinity and any EPROM actual implementation would just be some large enough number.
10:56
Okay, so that means now that we can we've got once we've iterated over all X in the
11:02
for loop and overall subsets in increasing order of size in the outer for loop,
11:09
then we have calculated and stored all the values of CSX.
11:14
And now we come to finally compute the actual answer.
11:21
And again, it's a minimisation overall X, which could be the last node in the travelling salesman tour.
11:27
And we are so we just minimise this expression here, which is what we computed a few slides ago.
11:35
When this is the solution at the bottom of slide one eight six, we're just computing that expression, minimised overall all values of X.
11:45
OK, so that is the algorithm. And what about the complexity?
11:56
Well, it's very simple because basically for each subset of nodes, we just do order and squared work with the two for loops.
12:01
So if we look back in here. So for each set here, we've got two in a four loops ranging over nodes, up to end nodes in each case.
12:12
And so that's just order N squared for each subset. But how many subsets are there?
12:24
There are two to the end subsets. And so that gives us the complexity here, which is Bago and squared times two to the N.
12:29
Interestingly, the bellman held Kulp algorithm can also be adapted to solve the Hamiltonian circuit problem, and the complexity is still.
12:40
They go and square too to the end. So I'll leave that as an exercise for you to do.
12:51
Well, just to complete our discussion for the moment on the travelling salesman problem that we've seen,
12:58
that exact solutions will take too long because. Okay, that was an improvement on the N factorial, but it was still worse than exponential.
13:04
But we still want to solve the travelling salesman problem because there are applications in circuit design,
13:14
supermarket delivery routes, etc. And so we need approximate methods.
13:20
And for instance, we could try a so-called greedy algorithm which always chooses the shortest available arc.
13:26
Well, might be better to call this a heuristic rather than an algorithm, because we're not guaranteed to get optimal results here.
13:34
We had a greedy algorithms for minimum spanning tree, like a premise and crossbills algorithm, which did indeed turn out to be correct.
13:41
But in this case, the nearest neighbour heuristic is not guaranteed to give us an optimal solution.
13:50
OK. So let's try nearest neighbour on our example graph. So let's start at one then.
13:58
The nearest neighbour is four. And then the nearest neighbour from that is five.
14:04
And then we can go to two. And then three is is the only possibility.
14:09
And then we go back to one. And the total weight is 19, which is actually quite good.
14:17
We've managed to avoid the eight or nine and the ten, so we've done quite well.
14:24
So that's encouraging. But if you think about it, there's no guarantee that this is going to work because we're rather short sighted.
14:31
We're just going Greeley from Wando to the next. Let's try it on this graph.
14:40
The age difference is that I changed the five into a 500. So we go through the same route as before.
14:46
And then our last arc that we get to will be this one here and then we'll be forced into taking it.
14:53
So once we get to we have to go to three and then we have to come back to one using 500,
14:59
which is obviously the worst possible thing to do on this graph. So clearly, we should avoid that arc.
15:04
But nearest neighbour heuristic when applied naively is forced to choose it on the last step.
15:09
Well, there are obvious. I think you can already see for yourself that there could be ways to improve on
15:16
the heuristic to avoid at least get a better solution on this particular graph.
15:23
And there are also more assumptions we can make about the travelling salesman problem
15:30
and the weighted graph which will help us to get better approximate solutions.
15:35