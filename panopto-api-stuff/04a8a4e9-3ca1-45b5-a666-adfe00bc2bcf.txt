ID: 04a8a4e9-3ca1-45b5-a666-adfe00bc2bcf
Title: Ethics Workshop - 14 December 2021
Category: Ethics
Lecturer: Thomas Lancaster
Date: 14/12/2021
Hi, everyone. Thomas and Blair, Tuesday morning, 14th of December 2000 and 21, which is saying a very dull day there,
0:02
if you've escaped the UK already and maybe slightly better where you are,
0:14
but really, we've just got this time with you to reflect where we're at with the module and to pick up on any questions that you have.
0:19
So hopefully where we're at right now is that yesterday almost all of the groups made their selections with topics.
0:30
We did the allocations, so everyone who made a selection has got a project to work on, which is your starting point.
0:39
Hopefully now you've had a bit of time just to think about this overnight and to talk to your group and to do a bit of background research.
0:48
And so we can pick up on any questions you have about how to approach this or general applications,
0:56
ethics or anything you might want to talk about with Blaine.
1:05
While we have him here today wearing a very nice waistcoat today when he leans back there.
1:07
Yeah, yeah, very impressive. I have anything like that to compare with for that.
1:15
Yeah, so any general questions feel free to post them. Good morning. Thanks everyone who has plus in the the chats as well.
1:21
We have these sessions every day during the week just to help you with where you're at today at 2pm as well.
1:29
You have a session with the Centre for Academic English Bret Harmony there, possibly my favourite name of any member of staff as well for that one.
1:36
I mean, bless your close, but Brett is just slightly more unusual and that combination of names, but very,
1:46
very nice American gentleman who still manages to write in UK English and doesn't confuse any of us with that.
1:53
But Brett says he sent you just a link to blackboard site and there's a quick quiz you'd like it to look at before the the session about writing.
2:00
I think the quiz where you take your 15 minutes or so, but you've got a bit of time, then please do and have a look at that one.
2:09
And I know what happened with last year is he sort of did a bit of preparation to help you in writing a summary.
2:14
And then in January or possibly February, when all the marks are in,
2:21
he also did a feedback session as well about problems people have had with writings that worked quite well,
2:25
but to have a look at that on blackboard, too.
2:31
So I've been managing to make a bit of progress with the topics that we've had a few questions and haven't we not many people posting on it yet,
2:36
which is the ideal place for that.
2:47
So do you post any anything you wanna pick up from the questions? So probably.
2:52
We've got one excellent and interesting ones coming into the chat there, and it was the one I was going to pick on or related area.
2:58
The question is do we need to provide sources? If we were to show some applications of the topic, I think I'd like to just pick up a full name.
3:06
Yeah, a more general area about sources that also supply what makes a good source for these kind of questions.
3:15
Would you go about finding information? It very much depends on the topic of some of the topics will be controversial with the general public.
3:27
Some of the topics will become controversial in the tech world.
3:38
But maybe if I run through an example for the engineers at Sussex last year, I said, who has the right to repair?
3:43
And one? And there's a lot of interesting ways you can develop that topic.
3:54
The right to repair is enshrined in law, and it's mainly been a push in in the US.
3:59
And I wanted them to discuss people repairing their own airliners and people repairing their own cars and safety issues and so on,
4:07
and the need for legislation to ensure standards and so on.
4:17
But the students, for the most part, took it as an excuse to say bad things about Apple.
4:20
And now, whilst I'm prepared to admit that Apple is not the best player in the right to repair market,
4:27
venting your spleen because you hate Apple is not a good answer, but a good answer would take far more reliable academic sources.
4:35
So again, if it's an up to date technical issue, you have to take some of the claims,
4:48
particularly of Silicon Valley insiders, with a little bit of of a pinch of salt.
4:55
What would really impress me in the marketing is if you were sensitive to the notion of a conflict of interest.
5:03
And there's a good example. If you look at my lecture on the London Ambulance Service,
5:11
where I say quite explicitly that all the accounts I got to read of this particularly poor piece of
5:17
software were written by competing companies who thought they should have been given the contract.
5:24
And these people obviously have an interest in criticising what happened.
5:30
They're not impartial judges. And this is interest in the sense of disinterest or having a stake in its interest in that particular sense,
5:37
rather than being the opposite of being caught by.
5:50
So I mean, you've got to work on those two unfortunately very different meanings of the
5:54
word interest in English to understand the notion of a conflict of interest.
5:59
So if you suspect that any of your sources have some reason some vested interest in making it plain,
6:05
then you know you impress me by picking up on that because it's often very hard to pick up conflicts of interest.
6:13
I've already said I don't like Wikipedia for personal reasons.
6:20
So I really don't want to see Wikipedia as a reference by all means use Wikipedia to explore and get links.
6:26
And then, of course, you know, there are respected journals.
6:33
So in the medical field, you know, The Lancet, BMJ British medical journal would be respected sources,
6:39
whether or not I could put it now, which is the internal publication of books in the same category.
6:48
I don't know. I mean, obviously, VCs would like me to do that.
6:57
BRICS wants to see itself as the equivalent of the British Medical Association.
7:00
But again, at least at least one person in the audience challenged membership of BRICS yesterday.
7:07
So I'm not. I don't particularly want to defend BRICS.
7:15
Maybe I'll have a conflict of interest there. I don't know that I'm actually being particularly helpful here, but.
7:21
I mean, in a way, you must decide, right, but I'm not particularly keen to see angry articles from the Sun or from someone who really can't
7:32
check up on some bulletin board or discord are much more interested in established journals.
7:46
But that's just a personal thing. Come on. Yeah. No sex play, no.
7:58
And yeah, BCS membership is a question. I was just going to put the champ.
8:01
I'll say it. It's the kind of question to take to Tony rather than to do a.
8:05
So that one of our boys, we should be pushing. So ABC's membership.
8:10
So students at Imperial's there, but it doesn't serve you, doesn't change whether you should have ethics on the course.
8:14
So maybe what is one other way to just look at this as we do have a screen would be for me too.
8:23
Would it be me to share my screen? And I did a bit of this, I think, in one of the videos, but to take one of the topics that wasn't chosen.
8:30
And so I thought, this is one of my favourite topics which nobody has chosen.
8:38
There are proctoring systems for online exams biased against some users and just do a quick search to see what
8:45
appears there and play you have you have control of the room if anyone appears while I am demoing as well,
8:54
I'm letting in the room so that people are prepared.
9:03
Yeah, people are appearing about quarters the way in and I can see other questions about this in the chat.
9:07
So if I'm just mentioning creature window there, then?
9:13
Right? So if we were to say such a proctoring just in general and what kind of things will be fined?
9:20
So proctoring as in visualisation, that's the American term, just in case that's so as anyone,
9:27
you'll find lots of links to services who was selling this.
9:33
And I do have to know a bit by this area because my research field is about academic integrity,
9:38
which is a different spelling of AI or a different way of putting it.
9:43
But essentially, it generally means you take an online exam.
9:47
There's at least one camera pointed at you all the way through, and if you look away from your screen,
9:50
then you're considered you're looking at notes or talking to somebody for that.
9:56
And so there are lots of potential sources here, and you do come up with with news type sources there.
10:01
And I can look at these straight away and say,
10:09
probably the daily cougar dot com is not going to be the most reputable type source just based on its choice of name,
10:11
but that one times higher education for this kind of topic is going to be a reputable source
10:18
because I happen to know that's the main UK news publication about higher education,
10:24
probably the world's last one of the world's largest ones as well. So but that is part of that blog.
10:31
So we could look at that. Unfortunately, we have to be logged in to read the source.
10:38
I think you're entitled to free access as an imperial student.
10:42
I do have an account, but I'm not going to try to remember log in details now to get that one.
10:45
That then you get things like NBC News for this one.
10:51
And clearly, this is going to be a negative view of this remote testing is failing the students forced to undergo it,
10:58
then I want to get a really huge bit of wasted screen at the top, although it's probably an advert that was missing.
11:05
And I'm not going to read through all this one there, but somebody going into labour while they were taking an exam there.
11:13
And I would say NBC reasonably reputable compared to, say, Fox News or or someone like that.
11:21
But we've got somebody here who said on Tik Tok they were falsely accused of cheating.
11:29
That could be something interesting to talk about as background in a presentation or even to
11:34
show a very short Tik Tok video with the benefit of TikTok videos being 30 seconds or under.
11:41
But that one that this is quite critical article Muslim woman who was forced out of a test in August posing a hair who's wearing a hijab?
11:48
That sounds quite controversial without reading the story about that one.
11:59
And calls to ban this now. So you could read through through this, and you'd get some reasons why people think this isn't ethical there.
12:03
I mean, what else do we see? So here, quite interestingly, we have a link to Springer dot com.
12:13
Now I happen to know that Springer dot com is going to be an academic, so it's going to be a journal paper.
12:18
So if we were to look at this, then this would be kind of academic source you would often use to support a project here.
12:25
Now, I don't know how high, how good this paper is without reading it.
12:34
But Springer is generally a reputable journal publisher as they go.
12:39
And this is a 2021 so recent article reviewing an eye catching system.
12:45
So this would be necessary to see if they're any useful points here that could back up the talk and be considered quite a decent quality reference.
12:50
So what they've done is they've done a literature review of 43 papers.
12:59
In other words, they've read 43 papers in this area, and they've picked out some of the main points from these two papers here.
13:02
And. So this looks quite useful diagram that might be something that would be possibly
13:11
handy to reproduce the the type of online proctoring systems are out there.
13:18
And you notice it splits them into three categories ones that are alive.
13:24
There's a human involved ones where they record people and then review them afterwards and then ones where there's just an automated or AI system,
13:27
which watches the video. And so it does things like I mentioned, we're looking away from the screen, so the focus would be on the automated section.
13:37
Presumably, this is much cheaper than a human, but probably more prone to mistakes.
13:46
So you could find out criticisms, et cetera, of how they work areas like gaze tracking,
13:51
which is going to be a very much a computer interest area of interest to computer scientists as well.
13:57
A machine learning the other error you can look at without reading everything is these references at the end.
14:03
So these are the sources that a researcher from this paper.
14:10
So if any of these look like they might be useful for you, they could be interesting to include.
14:13
So you might include short quotes. You might just include a summary of the information or whatever might be relevant.
14:19
So that's another possible place you could go. But you look through these there, try and find things that are interesting.
14:27
About these. And I mean, the other area which intrigues me might would be something like bias because.
14:38
And so I happen to know straight away the main story is going to come up because students of colour are getting flagged to their teachers.
14:47
So in other words, the complaint here is that the A.I. systems have been usually trained on, possibly on white faces,
14:55
or they are more likely to to flag potential academic misconduct for, as he says, his students of colour.
15:05
So that is an area which could be considered very, ethically biased, very unfair.
15:13
And you might pick up on their potentially other biases in this process that you might find as well.
15:20
And there may also be people who have looked to remove those biases from the system.
15:25
So those are areas you could think about. But again, now there's a whole other side to this.
15:29
If you're trying to present a balanced view which may surprise you, that I can tell you happens at Imperial,
15:37
where we have been running remote tests and remote exams over the past 18 months
15:45
or so on has been a big push on some of our on edge and perhaps the before then,
15:51
with students saying Why aren't we using online proctoring and why aren't we requiring students to be filmed all the way through their exams?
15:57
Because students at Imperial worried about other people who are cheating? So I'm.
16:05
So you do get both sides of things you might pick up on the other.
16:11
So you can find the popular sources to add flavour to the academic sources.
16:15
The other thing you can do is just do the search straight away from Google Scholar will probably find similar sources that one that came up.
16:20
But there are various other ones you can look up here that might be worth reading as well.
16:29
This one is a preprint, so it may not have been properly peer reviewed yet on our vics or all that have never
16:33
been answered that we saw this one systematic review looks at lots of different papers.
16:42
And yeah, and you can look through various other ones quite often.
16:48
The more recent ones for a topic like this, which perhaps relate to COVID are going to be particularly useful for this.
16:52
But again, let's just out of interest, add the term bias and we get much the same thing.
16:59
But even if you've chosen a very recent topic where there's not really an academic way of looking at this, then you may find related areas.
17:06
So like, for instance, I just type A. is this paper is about social bias in algorithms is not related,
17:15
particularly to proctoring, although presumably it's got proctoring as an example in there.
17:22
But it is something you could use to support a more general, more general topic.
17:26
Whether it's in the academic source. You could find related professional areas for this, and I guess it's always worth trying the ethics as well.
17:32
Which way it's already we know it's come up in that preprint and to see what you get that legal implications related area,
17:42
you're going to study legal in your second year and a lot more detail.
17:50
We don't really look into legal issues in the the first year, but again, it might be something you want to draw upon.
17:54
So just a, you know, just a few ideas for starting points.
18:00
The data is all out there and you're going to be using Google Scholar or perhaps library systems quite
18:04
heavily during your course because we are a research university as as I'm sure you've picked up.
18:09
So that's just some some thoughts from me for that one.
18:16
And I've sort of skipped over a lot of questions that have come in.
18:22
For that, I so the related question, I never and said, do we need to provide sources if to show applications of the topic?
18:26
I think you can. You can have a combination of sources, then you can have the very formal ones.
18:34
You can have some popular ones, but it's good. It's good to avoid ones with a huge amount of bias, if you can.
18:39
But if you know that bias because particular news services are very biased, then you can just pick up on that.
18:45
For that, you can have a certain amount of your own opinion. Your own opinion doesn't need a source, but that's fine.
18:51
I think you applications. I think it is good to support your work with sources as far as you can,
18:59
but you won't always be able to get a perfect source for every single situation that
19:04
depends on which position a perspective should we take when approaching the project,
19:11
a software developer, a policy maker, et cetera for that.
19:15
So I think you can take you can take any of those.
19:19
We are interested in the position of people in this field.
19:24
So the professional position to pick out that professional view is going to involve often more than one type of more than one actor in this situation.
19:30
So it could be a company, there could be somebody standing to profit from this.
19:41
It could be a user of a system.
19:46
It could be a student from your viewpoint because you're allowed to bring in your unique perspective into some of these ideas there.
19:48
It could be the professional bodies bearing in mind the professional body, maybe the BCS.
19:55
But I mean, I've just looked at a structure in the BCS is not going to be the professional body responsible for any proctoring.
20:00
This might be more of an educational organisation.
20:08
It may be a student union would have a view about this as well, that there may be views of students,
20:11
maybe use of stuff so the different people you could bring in. So it's whatever is relevant for that and then try and give a bit of a balanced view.
20:18
There is always this, this wider ethical question that that some of these questions involve software.
20:27
Is it ethical to be a programmer for this software if the software is misused?
20:34
And that's, I think, one for you to think about. You don't need to give an answer now. A very interesting area of ethical debate.
20:40
A few questions about writing an abstract, important skill. Please attend the session from the Centre for Academic English later on.
20:47
They're going to show you some abstracts. I think they've already put some up on Blackboard.
20:56
They're going to go through some examples of these for that that.
21:00
The question is just come to me about the introduction to the ethics topic and the conclusion for this.
21:09
So strong conclusions are going to give some form of of answer to your question or at least to perhaps sum up where this field needs to go.
21:17
The worst possible type of conclusion that we see in a presentation is when the video just ends and
21:30
you've no idea it's coming to an end because nobody has sort of foreshadowed the end point a video.
21:36
So one way it works quite nicely in videos,
21:42
presentations and even in written documents is to provide some kind of question at the start of some talking point,
21:45
which can come back to at the end of the presentation, or sometimes even give it quotes.
21:53
And to then say, is this quote still valid at the end of the presentation or can you improve upon it?
21:59
But you? You do.
22:05
What is something like an open loop at the start of the presentation and then you close that loop at the end of the presentation for that?
22:06
So, so some of the topics you can very easily phrase as a question.
22:13
Some of them you you maybe don't use a question is the best way of doing that so that we talked a bit about news agencies.
22:17
And are they trustworthy? It is a bit of a judgement. You can quite often look up a source and see what people say.
22:25
So when you saw me looking at those journals,
22:34
I happen to know straightaway that Springer is one of the the best known companies for publishing academic papers.
22:36
But if you didn't know that, you could do search for the name of the journal or the name of the company and see
22:44
what comes back because there are some less reputable journals publish anything they.
22:50
And so they're not generally good sources. People pay to be published in them because from an academic point of view, you quite often get promoted,
22:57
particularly in countries outside the UK, based on a number of publications.
23:05
And so the easier the publications are for you to get the the more valuable they offer you financially for that one.
23:10
There are a lot of unprofessional issues, and how are you going to show professional issues in your in your presentations?
23:20
So please do watch plays lectures about this where he's covered this there, but we're we're very interested in you.
23:32
Bring in your own ideas for this is actually phrased quite generically that marking
23:41
criteria because we want to reward you for putting the effort in and for doing well.
23:45
This isn't one of these modules where we're determined to get everyone on the really low market
23:51
to try to look for ways to fail you anything like that that really isn't the idea about this.
23:54
We want you to explore the the topic and have the opportunity to learn about things, but we've got decision frameworks, got decision trees there.
23:59
Got the diode Boetius methodological diode may be relevant in some cases,
24:11
you may find the best ethical approach is not a competing one at all, but a different one.
24:17
You can look up as well for that one, any other, any other good ideas to share about that one blade.
24:23
Just well, we're looking at it. I know you've posted a few things now I'm having to type in the URL of the article because presumably
24:28
people don't want to watch videos of me may get it from a slide and cut and paste didn't work.
24:38
It's good stuff, train or it will be when they get it to work. The ethical hype and the leaders decision tree.
24:47
I feel for you too. Yeah, just riffing off what Thomas just said.
24:57
Feel free to impress me if you want to develop your own methodology.
25:03
Good, because something I often say is particularly in the I.T. ethics field.
25:08
Some of the people have gone before. You have really not been very impressive.
25:19
I don't want to name any names or take on anybody, but putting profits above people, putting profit before people.
25:22
And then you even put that phrase into a search engine.
25:31
You might find some recent articles and a whistle blower putting profit before people is probably wrong.
25:35
You make your own decision about That's how I feel. It's wrong.
25:43
And some of your predecessors have clearly done that.
25:47
So I used to have a lecture called You Must Do Better if you simply if you simply decide to follow the standards of the industry that's gone before,
25:50
then you may end up doing some really quite bad things.
26:04
So, as I say, feel free to impress me.
26:09
Feel free. And of course, you're not having your arm twisted to make a profit or justify yourself to shareholders in this exercise.
26:13
It's very easy for a group of five or six students to say we would be a much better.
26:22
Feel free to do that. That's that's what we're looking for, really feel free to say these people were slipshod or they didn't.
26:31
We would have done better. That's the sort of thinking we're trying to encourage.
26:40
Yeah, thanks, Blake. That sounds a bit preachy, but the honest truth is, you know,
26:46
a lot of things have gone wrong and that the only chance of everything being made better is you by.
26:52
Yeah, yeah. No, you and I mean, you've done such a lot of work in this area as well,
27:01
and you give a lot of guest lectures and we haven't had you do a full one hour lecture this year for the module.
27:06
But if people are interested in a lot of recordings of your talks available online anyway for people,
27:13
I know there's this mix that some people prefer videos, some something for reading.
27:19
Luckily, you can find about these things everywhere for that.
27:23
And I mean, the other thing is whether there's a lot of frameworks now for A.I. ethics,
27:28
artificial intelligence, ethics out there, them a variable quality.
27:33
But for some topics, you might find it better to think about one of those.
27:37
What we're not thinking about, in my personal opinion,
27:45
is you might look at ethics and you you might suddenly think of this from the view of philosophy or something like that.
27:48
I just I think generally it's less ideal to approach it from from that direction for that.
27:56
So consequentialist theory and things like that, but I don't tend to be that applicable to what we're doing, but they do exist for that.
28:04
Yeah. All right. So the introduction introduced the main ethical arguments, the presentation,
28:13
as well as any technical information about the technologies involved that I've been doing it.
28:18
Doing a strong introduction is a bit of an art form, and again, there's not a one size fits all solution.
28:24
So one thing for you to think about is all the information you want to juggle around all the points you
28:31
want to make and then reordering them so they will fit neatly within 15 minutes and involve everyone.
28:35
So I think a strong introduction is something that hits you straight away about understanding what the problem is and why it's important,
28:41
but not necessarily how it's solved. So to me that the worst introduction is somebody who says, Hello, we are team four.
28:50
I am this person. I'm this person, I'm this person on this person. We are going to tell you about this topic.
28:57
The structure of our presentation is going to be first. This person is going to say this, then this person is going to say this.
29:02
It's just too slow for me in the modern world for presentation. There may be people out there who completely disagree with me about this,
29:07
but you you can hit people with very early on a great visual representation, a diaphragm,
29:13
a picture,
29:19
an illustration of why this is important to me and just help people to pick things up by watching and learning is what gets people interested.
29:20
So think of TV programmes and I, they always have a bit of a do you watch a documentary,
29:29
have a little bit of a trailer at the start and they have a quote from some
29:34
prominent expert is going to be featured in there just to get you watching.
29:38
And then they go into the introduction proper and then they come back to the expert later on.
29:42
So that kind of format can work quite well. And so if you've ever seen play on TV, then that may be where you've seen him.
29:47
Yeah. All right.
29:55
So I was just telling me earlier before we came on on air to use a completely bad phrase about being bought pizza by the BBC was a sign.
29:58
It does happen. So professional consideration.
30:09
Now we're in something that operates in that quite generously there, but relate to professional criteria,
30:14
relate to frameworks, relate perhaps to professional body requirements as well.
30:22
For that and and we'll also think of it as I think about your know about things covered in professional issues,
30:27
videos, if they're appropriate for that one. There.
30:35
Yes, so you go ahead, I'm just I'm just I'm just checking, I've not missed anything.
30:42
I've mentioned books a lot and know I'm I am an ethics expert for banks, so I have to declare a conflict of interest.
30:48
And also, books accredit your degrees.
30:58
They're engaged in a fight to professionalise the profession in Britain, which they've had some partial successes.
31:02
So if you want to work, you know it in Britain, you can't exactly ignore risks.
31:10
I mean, I'm happy to have more detailed discussion about whether or not you should join and how they can help you.
31:16
But but if you if you're never going to work in Britain or, you know, even in Europe because they're greedy about capturing your too.
31:21
But good luck with that, guys. But then maybe you could decide to use some other professional code.
31:30
If if the example you've chosen has very little to do with computing,
31:38
then you know you might want to choose aeronautical engineers or aerospace engineers or more general engineering code.
31:43
There are plenty of codes available, and certainly if you're looking at I is no end of codes, although I'm going to play.
31:52
My was first published the Code for Air in 1988, which really is a long time ago, and there are codes about robotics.
32:00
I mentioned BBC One that I was involved with, but a number of countries, particularly if you're going to work at the other side of the world,
32:12
it's worth noting that Japan and South Korea have far more enthusiasm for robots using various jobs than the West does.
32:24
For example, I don't know about China,
32:37
but I would imagine that China's pretty heavily involved in this and maybe has a lead in certain types of air technology.
32:41
I don't get invited to speak there, and I don't really know.
32:53
But if you were planning to to work in any of those countries and the, you know, anywhere in East Asia,
32:57
then it might be worth looking at a very different code from BCS because it might be that European attitudes just don't apply.
33:06
Be slightly careful about making a video saying, you know,
33:16
you believe we're wrong about this because because you're British, because that's not, you know, that's not a good start.
33:22
But I certainly don't want to insist that the only code is BCS and the only methodologies diodes, because that that's far from the case.
33:30
And a lot of these problems are global problems. I'm different, but different perspectives from all over the world are clearly relevant as well.
33:42
That's my personal view amongst them. I think I'm wrong about that, but I feel very strongly that we need to search for global solutions.
33:52
So feel free to hit me with a very different code.
34:02
Yeah, thanks for that and your point in the chat. I just mention names of people watching the video.
34:10
You've said in some cases the word shareholders is used in these codes,
34:14
but it's probably better to think of it as stakeholders, and I completely agree with that.
34:19
Their shareholders implies just the very business way of doing things.
34:23
Yeah. In fact, that's that's a very US perspective to put shareholders in such a prominent position.
34:30
I'm not a commercial organisation and I might not think shareholders come top in every case, but in fact, I honestly don't.
34:44
I think there's a lot more people involved in these decisions.
34:54
I don't, for example, think that it's ethical to pollute the world or contribute to global warming simply because it gives you more profits.
35:01
I think that's unethical because there are more stakeholders than just your shareholders involved in such decisions.
35:09
Feel free to disagree with me, but but be sensitive to the fact that the the reference,
35:17
the URL that I've posted takes you to a code that only mentions shareholders.
35:23
And if you just cut and paste that email thing, maybe you haven't read it.
35:30
Yeah, great. So I'm going to give you something to tear apart now that I've just quickly done in the background and just share my screen again.
35:39
That so I was just thinking based on what we looked at earlier about potential potential sources for the eye watering system about how I
35:51
might structure a presentation around this and try and cover a lot of the different areas involved here and make it interesting presentation.
36:03
But I mean, this is this has been written in two minutes in the background while everyone has been talking.
36:14
So it is it is far from perfect there.
36:18
I mean, the first thing I would do would be just to give it a much more catchy title than that because the title is not good there.
36:22
But how I would start this off, I would start it off, I think, with a very catchy,
36:29
shocking story, and it would probably be the bias against people of colour would go in there.
36:35
And that would be a good place for a media example or a picture of a perhaps a a page of a newspaper showing that story.
36:43
Or if somebody has been talking about how the system was biased against them by presenting that.
36:53
So you're introducing the topic in a very dramatic way and talking about this in the background.
36:59
And the advantage of this particular topic is hopefully is quite easy for people to pick up.
37:06
If it's very technical, you might need a bit more information then.
37:11
I think if I was doing a nice video rather than a live presentation, what I would probably do would be to just share my screen,
37:15
just share the screen showing that there were about 50 competing companies selling this kind of technology just to demonstrate the massive business.
37:22
And I might get a quote from somewhere to go.
37:31
Alongside that saying the air string industry is worth 10 billion pounds a year or something.
37:35
I mean, I've no idea if it is.
37:42
That is just a number off the top of my head, but some things are very supportive there to show why this is a major problem.
37:43
Then I think you need the academic sources,
37:52
so I like that review paper we looked at very quickly and the diagram splitting different types of brokering services up,
37:54
but it's just showing the bringing in this that it is a real problem because at least 20 people have published papers looking at this area as well.
38:01
And just a quick reminder is to put the source of the paper in the future of the slide.
38:10
The reason we don't put it at the very end of the slides are because if people are watching your video and you just say this is because no one,
38:15
then people don't know what source no one is until your video ends, and it's not terribly useful.
38:23
So we put that in there. But again, you can make this nice and visual,
38:28
and that helps with the video because this is because it's a diagram or your own version of the diagram if you don't want to directly copy from it.
38:32
And I think then that is a good point to look at other potential biases in our proctoring because I've mentioned one of them,
38:41
but the other ones are the ethical concerns to go in there and just to include that.
38:47
So we've talked a bit about professional areas, code of practise, perhaps, and you might look at the BCS code.
38:56
You might look at other ethical codes in there, such as an eye one.
39:04
I have that relate quite nicely because it's being very much a problem that might have been educational codes that you can relate this to there.
39:08
As we as I was rambling earlier on, I mentioned about that the there are other perspectives.
39:17
So I suspect by this point of a presentation, if you follow this rough structure, the new would be lots of negative views.
39:23
So be good idea to bring in some slightly more positive viewpoints as well, perhaps some student perspectives.
39:31
And it may be that you find a good quote,
39:38
a line that students saying they are concerned about if universities don't stop of the students cheating than their degrees, the devalued.
39:40
So you could perhaps bring in something which prevents the other viewpoint and perhaps some of the other
39:48
bit other stakeholder perspectives as well to just relate back to what we've just been saying to.
39:55
I think then there's a good opportunity for you to get a bit of your opinion and to round all of this up and you're unique you as a student,
40:03
particularly because this example is very much related to students as well.
40:09
And then I might do as a close to make this rather than a traditional presentation.
40:14
But so this is this is probably slightly different to the presentation structures.
40:20
You're all taught at school about how to do this because I don't think they'll work in every situation.
40:24
What I would do would be I would probably relate this back to the shocking story at the start,
40:30
because then everything has a bit of a loop to it and perhaps mention how that if it's true and you find this in your
40:36
research with some sources that companies are taking on board these biases and they are making changes to their practises,
40:44
or they have changed their training datasets to make them fairer or whatever might be appropriate there.
40:51
So that's my perspective. I have the benefit.
40:57
I would never give a presentation in this style.
41:01
I don't think because I present just fine if an audience as opposed to trying to meet the criteria for this ethics assignment there.
41:04
And I may have my own personal view about this, which I would present as well.
41:13
But I think in terms of meeting the criteria for this assignment, that is the type of structure which I would I would come up with for this.
41:17
So I mean is open to a starting point that you would then pull around and change and work out who in the
41:27
group would present what and how you would make it interesting how you would make it nice and visual.
41:35
Obviously, this is this is just a screen. It's not it's not hugely visual and exciting,
41:40
but lots of opportunities to use pictures and this kind of talk and you play any thoughts on that, anything else you would add?
41:45
I know it's not directly to your research or anything, but you, you know a bit about this as well.
41:54
I, you triggered off some strong thoughts about I.
41:59
I'd really like to share with the students that it's important, especially it's a lot of the A.I. related topics.
42:03
This is a live issue. It's not like the government haven't noticed that we need to fix that.
42:13
Yes, it's very important. But nonetheless, I would say, in fact, I say in public talks, data is not unbiased.
42:22
All datasets are biased. That's a bit of an exaggeration because, you know,
42:32
if you if you did it data on redshift of stars in the in the visible light spectrum, it's unlikely that there'd be any bias in that.
42:37
But there's clearly a lot of bias in datasets that relate to him, that relate to human beings.
42:49
The clearest case is it turns out that facial recognition is much better at recognising white male faces like mine than any others.
42:58
But what's so interesting about that? Well, both whiteness and maleness are minorities on this planet, right?
43:09
So it's a select minority of faces. Obviously, something has gone wrong and things continue to go wrong where they are.
43:16
And I'll give you a hint of one thing that goes wrong by giving you an example to think about.
43:25
Suppose we said that instead of me looking at the videos and awarding marks, we would have an AI system do it.
43:29
And of course, with current machine learning techniques, we would train that AI system on previous student performance.
43:39
And soon we had a really big data set and it could really discriminate well and
43:48
give an exact percentage based on the percentage that students gave in the past.
43:53
Well, that might work, but it would be incredibly conservative.
43:59
It would be basically telling you do more of the do what's always been done and you might remember.
44:03
I really hope you remember, but you probably don't. You might remember that I said exactly the opposite.
44:11
I said, You must do better. Feel free to impress me.
44:16
And that you couldn't say to a modern day AI system, you could only say today, our system is this like a previous good student work.
44:21
And that is a serious problem if you replace human judgement with AI in a number of situations.
44:31
I'll leave you to decide which situations.
44:38
It's a problem because quite frankly, it doesn't matter what I think you'll be the people taking the decisions.
44:40
But I hope you can see there is this ethical consideration and simply saying, Oh,
44:46
no AI system would be cheaper, quicker and better misses an important point.
44:51
But is that enough of a rant I could give you more of a rant and trust me, I give the politicians a hard time on this one, too.
44:58
One of the the obvious reason why I is biased is if I walk into an AI lab, what do I see?
45:05
What type of faces do I see? I'll let you decide that. Tell you another thing you don't see in an eye Bible.
45:12
That's great, as it's clearly a very select group of people actually doing the technical work.
45:17
And that's one of the my personal reason for thinking this bias.
45:25
That's that's the main reason I think they have a narrow perspective on life.
45:29
But there you are. I've said it. Yeah.
45:33
No thanks. I know very, very true there. So I just quickly answer the question about references on slides as well.
45:38
So here, for example, is just this a paper we looked at earlier?
45:49
And if you were to click on this site button and Google Scholar said it will normally give you the references,
45:54
we use Vancouver format within our department there, which traditionally is a number format.
46:01
But what I would do is I would copy the reference.
46:06
I would check it makes sense because there's no guarantee Google Scholar gets these references exactly correct.
46:09
But for the for the purpose of this will assume it is. And then I've just quickly set up in PowerPoint.
46:15
I would just put the reference myself here in the footer in.
46:22
Something like that now, I suspect, without checking the exact format that probably wants to be in italics for that.
46:30
But. And if, for instance, you did want to put the number there like you for actually source one, then.
46:37
Something like that that is. That's how I would put the reference at the bottom, I don't think that is a very neat slide.
46:51
Incidentally, you can do much better than not just by starting off with a nice template and you might do things like put that,
47:00
put a quote and put that in a in a speech bubble or something to make it look better.
47:08
I wouldn't say if you can avoid it.
47:14
Stick with this very traditional PowerPoint type type look, because it's quite boring and not great for online, but that essentially is Hollywood.
47:16
That's where I put the reference probably at the bottom of the slide in a in a footer.
47:26
You might do it slightly smaller than I've done as well. That's just for the purpose of example.
47:30
So you can see it. But bear in mind when it's an online video and it's going to be compressed, you don't want your text too small, either that.
47:34
And then just the other little quick thought. Well, we're talking about videos is if you're going to be on the screen, like at the moment,
47:43
I'm probably in your top right hand corner, but I can't directly see this then.
47:50
Make sure you leave an appropriate space on the screen or if you're doing something more sophisticated,
47:54
like I do sometimes with a green screen, so I might appear down here in this section.
48:00
Then again, leave space for here, whatever it might be. All these things are quite possible as well there.
48:04
So that's a. A few thoughts there.
48:12
All right. Questions to the I would be scanning your slides for references that's probably relating back to Blaze Point, isn't it?
48:16
But but yeah, I mean, it kind of.
48:28
I mean, I mentioned in the chat, what's the finish in a few minutes, but A.I. systems are marking essays.
48:31
They've been around for at least 20 years that I've known about them.
48:38
They've just really come into strong use in the in the past few years there.
48:42
So they're fairly they're much more recent. But a lot of the A.I. systems are essays.
48:50
They look for keywords and they they say other people run essays about this thing.
48:54
I've covered these points of use these terms so well.
48:59
Well, essentially, it would do a quick count to see if this latest students use similar kind of terms there.
49:02
And they they do some superficial checking about writing style.
49:08
We can work out things like does this person use short sentences or long sentences for that?
49:11
No, we are not using an AI for marking you or presentations just to avoid that.
49:18
The play is very much a real person, even though some of the deepfake technology can be very good now.
49:24
I think this is ble here who is with us at the other end that is not is not outsourcing we could think of is interesting.
49:30
I'm sure it's not that many years before we can do this, but a moment this is both of us here in person for you answering these questions there.
49:40
Can can you do a references page instead of writing the reference to the bottom of the page?
49:51
No. The when you can do whatever you want, I mean, do I recommend you do it?
49:58
No, and the reason I don't recommend you do it is because you're going to be giving this presentation there
50:04
and we're going to be watching this video and when you get to say slide three and there is a reference,
50:11
then you've put a number there and we have no idea when you're presenting slide three what the reference is for.
50:17
If you don't have the references until Slide 27 because we can't, we're not going to be skipping backwards and forwards and trying to work things out.
50:26
So this is a I mean, this is a mistake I see quite often in more professional type conference presentations as well.
50:36
And I see lectures doing this, but it's really not useful because you're watching something and it's alive.
50:43
And it's not like a written book where you can skip over 20 pages and see the reference list you're stuck with.
50:51
What is at that point in the presentation? So, I mean, it's very much my opinion.
50:58
You'll find other people disagree with me, but I think you should have the references where they're being used for that.
51:02
And. And you don't want to have more than probably more than two references on the slide in general.
51:10
You may occasionally have three, most of the time you only have one another for video presentations.
51:18
Quite often people say don't have too many slides in presentations. But if it's a video and if it's online, you have to keep people's attention.
51:25
And so quite often you might actually decide it's better to have one to have slides with one point on
51:33
them and go through them faster than to try and fit 10 points on the slide and go through them slowly.
51:40
But that, again, is one of my opinions about keeping people's attention.
51:46
Now, clearly, this is a Q&A session is slightly different to if we were doing this as a online lecture.
51:50
And again, you'll probably find many people present Imperial who do things completely differently.
51:57
That's why I like to do some demos and to try things out, and they don't always work because it keeps people engaged for that.
52:02
Thanks. And discussion in the chat to humans of greater immunity to bias than I am.
52:12
Please put his view that that air is less biased than humans.
52:20
I think I would generally agree with them because humans are incredibly biased people, but they may be biased in different ways.
52:24
The I the problem is if it's a machine which is biased, then people get very opinionated about it.
52:31
If it's a human bias, then we might give people the benefit of the doubt.
52:39
Or we might just not pick up on it because quite often people surround themselves with other people whose views are like this.
52:44
But a lot of interesting stuff online about that one.
52:51
Quite wide discussion, really. So much of this comes down to just psychology as well.
52:55
I mean, even that's down to some of the things I say about presenting is about psychology. Really?
53:04
So and we should really have finished it into the IRA,
53:11
but I know you're probably not rushing off to another class today, quite the same, but any any less urgent questions.
53:14
Otherwise, the session later on with Bret is going to focus on the summary.
53:21
I will be there in the background. I'm going to let Bret and his team present that.
53:26
So it isn't really for general questions about the assignment as a whole, but very much about the written side of things.
53:30
And we will be on it. And we also have a another support session tomorrow when I think by tomorrow,
53:36
it's a good idea to know what sources you're using to have them all planned out and have a structure planned out for your presentation.
53:44
And then really, I think you've got a day of filming and potentially editing and and a day of writing and handling everything in.
53:52
So the time does go quite quickly. But that's a rough time plan of where I think you're at this to get everything done within a week.
54:01
So. So this been useful for you.
54:11
Hope you picked up a few ideas that were useful in this module and this assignment and also potentially for things you do later on there.
54:17
I'm may closing with wisdom. No, I'm busy talking about our biosphere.
54:24
Well, I think it's important to remember that air is biased and there's there's a myth that has been a myth of
54:34
computer impartiality that's been believed both inside and outside the I.T. industry from the beginning.
54:41
Now, if we let a computer decide it'll be impartial and neutral in 2021, we know that just isn't true.
54:49
And I think the Amazon Air Recruitment Programme is as good a proof of that as
54:56
you could want because no one told this programme to be biased against women.
55:03
You know, the people who wrote the code maybe couldn't have foreseen that it would be, but it worked.
55:09
How about bias for itself? And it was. It was a key word bias.
55:14
So if I'd submitted a CV and I happened to put on it that I'd given a talk at a girls school last year, well,
55:19
probably the year before which, you know, I had to just that very word girls would be enough to get my CV rejected.
55:26
That was how strong the bias was. And again, you know, even the Amazon tech team decided they couldn't fix this,
55:33
that they just had to throw it away and that that should be a lesson for everyone.
55:41
Chris, using air, you really need to check and check for developing biases.
55:47
And I'm the one that I said, you know, if you train on previous data which you which you're pretty much committed to doing,
55:55
then you're instantly saying to your programme, Give me more of the same.
56:03
Don't change. Keep giving me more like that. And a lot of situations, that's not what you want.
56:08
You need to think really quite carefully about that, particularly in an academic situation.
56:13
I put it to you that, you know, you don't want more of the same.
56:19
You're looking for gradual improvement. I can suggest an article on whether or not the world is getting better if you're interested.
56:23
Yeah, thanks. Thanks. I mean, fascinating. I mean, feel free to either post the article online or just to bring that up tomorrow.
56:33
We are going to we are going to stop at this point.
56:41
But I mean, if you are interested in air sex and making sure that systems are fairly designed to have a bit of a focus on that later in your degree,
56:47
there are lots of jobs there because it's something companies and the wider population are incredibly concerned about, right?
56:54
You're a very technical. Jobs aren't there as well about getting the right data sets and processes?
57:00
Yeah, that even the government have noticed this problem.
57:06
So it must be pretty obvious by now. Yeah.
57:11
And then that final question, the chat is how far should you focus on computing?
57:14
How far should you focus on ethics? Definitely much more ethics. The most of ethics.
57:18
We just want to make sure.
57:22
You mentioned computing as relevant, so there is a computing application to everything, all the this technology involved and everything.
57:24
If you use computing in a wide sense for that, well, the only thing we want to avoid is just to end up saying,
57:31
you're doing a purely business ethics presentation, which can happen if you're not really careful about this.
57:36
But we don't want you to go into huge amounts of details about about technical side of things.
57:41
It might be relevant, in some cases to say, Oh, there was an exploit of a system and just in a high level.
57:49
This is the technical process that we use that's quite relevant, but we want to keep things nice and nice and open here.
57:54
You will be doing a very technical presentations throughout your course in other areas,
58:01
so you can keep this one nice and light and entertaining and and try things out without too much risk of failure.
58:04
You can also assume that I'm fairly tech savvy.
58:13
I may be an ethicist, but I did have to write a compiler once for a masters in artificial intelligence.
58:17
You can assume I know what firmware means, how 5G works, you know what malware means, what a denial of service attack is, and things like that.
58:25
You don't have to go into gory detail explaining these technical terms.
58:37
I mean, if it's if it's a very obscure piece of technology for sure, explain it.
58:42
But you don't need to treat me as someone who's naive about the technology.
58:47
Yeah, no, that's right. But what I'm thinking is, let's say this is a hack, and someone has posted the 500 lines of code using this hack online.
58:53
And we don't expect you to go through line by line and to tell us what this line does or anything that would be quite a quite boring presentation.
59:01
So try and move that to one level up. But I think we're all quite able to cope with with technology in computing terms and everything like that.
59:08
Great. Well, in that case, we will we will stop there for the morning.
59:18
Have a look at the materials that Brett has put up on centre academic English as well.
59:23
He sent me a reminder just to make sure that people have spent at least.
59:28
I think you could spend 20 minutes looking at those before the session this afternoon, but you just have a quick look.
59:33
I haven't gone through this year's version to see exactly how long it takes if anybody has and it takes a lot longer.
59:39
Feel free to post in the chat and let us know, but have a quick look at those.
59:45
Otherwise, then have a look in your group and work out what you're going to present, what your structure is, what the sources are.
59:49
Because as the main questions, I think at this stage you should be answering. Right.
59:55
So thanks everyone.
59:59